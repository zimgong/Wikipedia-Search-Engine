{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(torch.nn.Module):\n",
    "    ''' A simple neural network that predicts a rating for a user and item'''\n",
    "    \n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create user embeddings: These are the latent factors for users \n",
    "        # that capture their preferences in which types of items they prefer.\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors)\n",
    "\n",
    "        # Create item embeddings: These are the latent factors for items \n",
    "        # that reflect what they are at an implicit level\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        # Multiply the user and item embeddings to predict the score\n",
    "        return (self.user_factors(user)*self.item_factors(item)).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data from Canvas or from https://grouplens.org/datasets/movielens/100k/ \n",
    "#\n",
    "# From the README:\n",
    "#\n",
    "# MovieLens data sets were collected by the GroupLens Research Project\n",
    "# at the University of Minnesota.\n",
    "# \n",
    "# This data set consists of:\n",
    "#        * 100,000 ratings (1-5) from 943 users on 1682 movies. \n",
    "#        * Each user has rated at least 20 movies. \n",
    "#        * Simple demographic info for the users (age, gender, occupation, zip)\n",
    "\n",
    "training_user_item_rating_tuples = []\n",
    "users = set()\n",
    "items = set()\n",
    "with open('ml-100k/ua.base', 'rt') as f:\n",
    "    for line in f:\n",
    "        cols = line[:-1].split()\n",
    "        user = int(cols[0]) - 1\n",
    "        item = int(cols[1]) - 1\n",
    "        # The rating is 1 to 5, but let's rescale to [0,1]\n",
    "        rating = (int(cols[2])-1) / 4.0\n",
    "        training_user_item_rating_tuples.append((user, item, rating))\n",
    "        users.add(user)\n",
    "        items.add(item)\n",
    "        \n",
    "test_user_item_rating_tuples = []\n",
    "with open('ml-100k/ua.test', 'rt') as f:\n",
    "    for line in f:\n",
    "        cols = line[:-1].split()\n",
    "        user = int(cols[0]) - 1\n",
    "        item = int(cols[1]) - 1\n",
    "        # The rating is 1 to 5, but let's rescale to [0,1]\n",
    "        rating = (int(cols[2])-1) / 4.0\n",
    "        test_user_item_rating_tuples.append((user, item, rating))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233, 482, 1.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_user_item_rating_tuples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(233, 482, 1.0),\n",
       " (233, 126, 0.75),\n",
       " (233, 225, 0.25),\n",
       " (233, 602, 0.75),\n",
       " (233, 523, 0.5),\n",
       " (233, 44, 0.75),\n",
       " (233, 284, 0.75),\n",
       " (233, 178, 0.5),\n",
       " (233, 132, 0.5),\n",
       " (233, 191, 0.5),\n",
       " (233, 147, 0.5),\n",
       " (233, 299, 0.5),\n",
       " (233, 866, 0.75),\n",
       " (233, 1447, 0.5),\n",
       " (233, 366, 0.75),\n",
       " (233, 47, 0.25),\n",
       " (233, 1453, 0.5),\n",
       " (233, 645, 0.5),\n",
       " (233, 184, 0.5),\n",
       " (233, 418, 0.75),\n",
       " (233, 627, 0.25),\n",
       " (233, 95, 0.25),\n",
       " (233, 1368, 0.5),\n",
       " (233, 1169, 0.0),\n",
       " (233, 81, 0.5),\n",
       " (233, 969, 0.75),\n",
       " (233, 218, 0.25),\n",
       " (233, 13, 0.5),\n",
       " (233, 241, 0.75),\n",
       " (233, 300, 0.5),\n",
       " (233, 1197, 0.5),\n",
       " (233, 600, 0.5),\n",
       " (233, 11, 0.0),\n",
       " (233, 505, 0.75),\n",
       " (233, 988, 0.25),\n",
       " (233, 1199, 0.5),\n",
       " (233, 233, 0.75),\n",
       " (233, 287, 0.5),\n",
       " (233, 171, 0.5),\n",
       " (233, 646, 0.5),\n",
       " (233, 415, 0.75),\n",
       " (233, 217, 0.25),\n",
       " (233, 693, 0.5),\n",
       " (233, 1284, 0.5),\n",
       " (233, 1459, 0.5),\n",
       " (233, 655, 0.75),\n",
       " (233, 1446, 0.5),\n",
       " (233, 1119, 0.5),\n",
       " (233, 426, 0.75),\n",
       " (233, 515, 0.5),\n",
       " (233, 873, 0.0),\n",
       " (233, 312, 0.75),\n",
       " (233, 380, 0.5),\n",
       " (233, 232, 0.25),\n",
       " (233, 1038, 0.5),\n",
       " (233, 1455, 0.75),\n",
       " (233, 316, 0.25),\n",
       " (233, 155, 0.25),\n",
       " (233, 101, 0.25),\n",
       " (233, 847, 0.5),\n",
       " (233, 618, 0.25),\n",
       " (233, 723, 0.75),\n",
       " (233, 1, 0.25),\n",
       " (233, 502, 0.25),\n",
       " (233, 1120, 1.0),\n",
       " (233, 1043, 0.25),\n",
       " (233, 518, 1.0),\n",
       " (233, 731, 0.25),\n",
       " (233, 516, 0.5),\n",
       " (233, 264, 0.5),\n",
       " (233, 629, 0.25),\n",
       " (233, 613, 0.5),\n",
       " (233, 164, 1.0),\n",
       " (233, 392, 0.25),\n",
       " (233, 12, 0.5),\n",
       " (233, 764, 0.5),\n",
       " (233, 633, 0.75),\n",
       " (233, 228, 0.75),\n",
       " (233, 844, 0.5),\n",
       " (233, 730, 0.25),\n",
       " (233, 49, 0.75),\n",
       " (233, 1049, 0.5),\n",
       " (233, 548, 0.5),\n",
       " (233, 444, 0.25),\n",
       " (233, 708, 0.75),\n",
       " (233, 685, 0.5),\n",
       " (233, 499, 0.5),\n",
       " (233, 483, 1.0),\n",
       " (233, 565, 0.25),\n",
       " (233, 464, 0.25),\n",
       " (233, 220, 0.25),\n",
       " (233, 167, 0.5),\n",
       " (233, 1074, 0.5),\n",
       " (233, 588, 0.5),\n",
       " (233, 501, 0.75),\n",
       " (233, 282, 0.5),\n",
       " (233, 486, 0.5),\n",
       " (233, 481, 0.75),\n",
       " (233, 150, 0.5),\n",
       " (233, 512, 1.0),\n",
       " (233, 701, 0.25),\n",
       " (233, 492, 0.5),\n",
       " (233, 433, 0.5),\n",
       " (233, 570, 0.25),\n",
       " (233, 194, 0.25),\n",
       " (233, 156, 0.25),\n",
       " (233, 189, 0.5),\n",
       " (233, 272, 0.5),\n",
       " (233, 641, 0.5),\n",
       " (233, 503, 0.75),\n",
       " (233, 215, 0.5),\n",
       " (233, 462, 0.75),\n",
       " (233, 1002, 0.25),\n",
       " (233, 1396, 0.75),\n",
       " (233, 123, 0.75),\n",
       " (233, 871, 0.25),\n",
       " (233, 520, 0.5),\n",
       " (233, 1125, 0.75),\n",
       " (233, 791, 0.75),\n",
       " (233, 1454, 0.25),\n",
       " (233, 748, 0.5),\n",
       " (233, 608, 0.5),\n",
       " (233, 22, 0.75),\n",
       " (233, 500, 0.75),\n",
       " (233, 495, 0.75),\n",
       " (233, 647, 0.5),\n",
       " (233, 491, 0.5),\n",
       " (233, 1171, 0.5),\n",
       " (233, 182, 0.75),\n",
       " (233, 922, 0.75),\n",
       " (233, 1268, 0.5),\n",
       " (233, 65, 0.5),\n",
       " (233, 43, 0.5),\n",
       " (233, 660, 1.0),\n",
       " (233, 886, 0.5),\n",
       " (233, 413, 0.75),\n",
       " (233, 525, 0.5),\n",
       " (233, 223, 0.75),\n",
       " (233, 94, 0.5),\n",
       " (233, 1148, 0.5),\n",
       " (233, 497, 1.0),\n",
       " (233, 172, 0.5),\n",
       " (233, 780, 0.25),\n",
       " (233, 136, 0.5),\n",
       " (233, 545, 0.0),\n",
       " (233, 92, 0.5),\n",
       " (233, 327, 0.25),\n",
       " (233, 557, 0.75),\n",
       " (233, 169, 1.0),\n",
       " (233, 1020, 0.75),\n",
       " (233, 650, 0.75),\n",
       " (233, 80, 0.5),\n",
       " (233, 435, 0.5),\n",
       " (233, 527, 0.75),\n",
       " (233, 318, 0.5),\n",
       " (233, 726, 0.5),\n",
       " (233, 630, 0.5),\n",
       " (233, 604, 0.5),\n",
       " (233, 237, 0.5),\n",
       " (233, 192, 0.75),\n",
       " (233, 711, 0.25),\n",
       " (233, 146, 0.5),\n",
       " (233, 621, 0.25),\n",
       " (233, 480, 1.0),\n",
       " (233, 841, 0.75),\n",
       " (233, 290, 0.5),\n",
       " (233, 846, 0.75),\n",
       " (233, 276, 0.5),\n",
       " (233, 88, 0.5),\n",
       " (233, 51, 0.75),\n",
       " (233, 955, 0.5),\n",
       " (233, 1100, 0.5),\n",
       " (233, 769, 0.75),\n",
       " (233, 928, 0.0),\n",
       " (233, 648, 0.5),\n",
       " (233, 805, 0.25),\n",
       " (233, 227, 0.5),\n",
       " (233, 781, 0.5),\n",
       " (233, 950, 0.0),\n",
       " (233, 303, 0.5),\n",
       " (233, 78, 0.5),\n",
       " (233, 46, 0.25),\n",
       " (233, 496, 0.75),\n",
       " (233, 174, 0.25),\n",
       " (233, 504, 0.75),\n",
       " (233, 551, 0.25),\n",
       " (233, 843, 0.25),\n",
       " (233, 190, 0.75),\n",
       " (233, 842, 0.25),\n",
       " (233, 979, 0.25),\n",
       " (233, 609, 0.75),\n",
       " (233, 674, 0.75),\n",
       " (233, 63, 0.75),\n",
       " (233, 522, 0.75),\n",
       " (233, 430, 0.5),\n",
       " (233, 203, 0.25),\n",
       " (233, 1202, 0.75),\n",
       " (233, 556, 0.0),\n",
       " (233, 1329, 0.5),\n",
       " (233, 195, 0.5),\n",
       " (233, 490, 0.75),\n",
       " (233, 206, 0.25),\n",
       " (233, 197, 0.5),\n",
       " (233, 927, 0.25),\n",
       " (233, 1444, 0.75),\n",
       " (233, 489, 0.75),\n",
       " (233, 615, 0.25),\n",
       " (233, 1019, 0.75),\n",
       " (233, 1220, 0.75),\n",
       " (233, 479, 0.75),\n",
       " (233, 872, 0.5),\n",
       " (233, 661, 0.5),\n",
       " (233, 1458, 0.5),\n",
       " (233, 652, 0.5),\n",
       " (233, 524, 0.75),\n",
       " (233, 165, 1.0),\n",
       " (233, 603, 1.0),\n",
       " (233, 139, 0.25),\n",
       " (233, 110, 0.5),\n",
       " (233, 198, 1.0),\n",
       " (233, 153, 0.5),\n",
       " (233, 212, 0.5),\n",
       " (233, 506, 0.75),\n",
       " (233, 321, 0.25),\n",
       " (233, 704, 1.0),\n",
       " (233, 941, 0.5),\n",
       " (233, 10, 0.25),\n",
       " (233, 151, 0.75),\n",
       " (233, 744, 0.75),\n",
       " (233, 21, 0.75),\n",
       " (233, 849, 0.25),\n",
       " (233, 862, 1.0),\n",
       " (233, 526, 0.5),\n",
       " (233, 235, 0.5),\n",
       " (233, 1099, 0.25),\n",
       " (233, 612, 0.75),\n",
       " (233, 96, 0.25),\n",
       " (233, 450, 0.5),\n",
       " (233, 400, 0.25),\n",
       " (233, 958, 0.25),\n",
       " (233, 306, 0.25),\n",
       " (233, 698, 0.5),\n",
       " (233, 692, 0.25),\n",
       " (233, 283, 0.5),\n",
       " (233, 427, 0.75),\n",
       " (233, 240, 0.25),\n",
       " (233, 1457, 0.75),\n",
       " (233, 85, 0.25),\n",
       " (233, 118, 0.5),\n",
       " (233, 411, 0.25),\n",
       " (233, 1063, 0.75),\n",
       " (233, 738, 0.5),\n",
       " (233, 750, 0.25),\n",
       " (233, 656, 0.75),\n",
       " (233, 133, 1.0),\n",
       " (233, 938, 0.25),\n",
       " (233, 494, 0.75),\n",
       " (233, 926, 0.75),\n",
       " (233, 746, 0.5),\n",
       " (233, 1456, 0.5),\n",
       " (233, 672, 0.75),\n",
       " (233, 180, 0.5),\n",
       " (233, 19, 0.75),\n",
       " (233, 39, 0.25),\n",
       " (233, 193, 1.0),\n",
       " (233, 357, 0.0),\n",
       " (233, 29, 0.75),\n",
       " (233, 654, 0.5),\n",
       " (233, 659, 0.75),\n",
       " (233, 1449, 0.5),\n",
       " (233, 610, 1.0),\n",
       " (233, 384, 0.25),\n",
       " (233, 143, 0.5),\n",
       " (233, 493, 0.75),\n",
       " (233, 69, 0.5),\n",
       " (233, 370, 0.5),\n",
       " (233, 403, 0.75),\n",
       " (233, 628, 0.75),\n",
       " (233, 590, 0.5),\n",
       " (233, 470, 0.5),\n",
       " (233, 614, 1.0),\n",
       " (233, 286, 0.5),\n",
       " (233, 163, 0.5),\n",
       " (233, 1132, 0.5),\n",
       " (233, 208, 0.75),\n",
       " (233, 473, 0.75),\n",
       " (233, 422, 0.75),\n",
       " (233, 428, 0.75),\n",
       " (233, 446, 0.5),\n",
       " (233, 1168, 0.75),\n",
       " (233, 983, 0.25),\n",
       " (233, 607, 0.5),\n",
       " (233, 90, 1.0),\n",
       " (233, 487, 0.75),\n",
       " (233, 877, 0.25),\n",
       " (233, 211, 0.25),\n",
       " (233, 4, 0.5),\n",
       " (233, 75, 0.25),\n",
       " (233, 173, 0.5),\n",
       " (233, 510, 1.0),\n",
       " (233, 131, 0.75),\n",
       " (233, 1062, 0.5),\n",
       " (233, 142, 0.5),\n",
       " (233, 595, 0.25),\n",
       " (233, 3, 0.75),\n",
       " (233, 420, 0.0),\n",
       " (233, 71, 0.5),\n",
       " (233, 275, 0.5),\n",
       " (233, 1047, 0.5),\n",
       " (233, 920, 0.75),\n",
       " (233, 214, 0.5),\n",
       " (233, 465, 0.75),\n",
       " (233, 691, 0.5),\n",
       " (233, 476, 0.0),\n",
       " (233, 105, 0.75),\n",
       " (233, 98, 1.0),\n",
       " (233, 519, 0.75),\n",
       " (233, 1297, 0.5),\n",
       " (233, 962, 0.5),\n",
       " (233, 653, 1.0),\n",
       " (233, 152, 0.5),\n",
       " (233, 472, 1.0),\n",
       " (233, 529, 0.75),\n",
       " (233, 291, 0.75),\n",
       " (233, 258, 0.25),\n",
       " (233, 658, 0.5),\n",
       " (233, 634, 0.25),\n",
       " (233, 53, 0.25),\n",
       " (233, 662, 0.75),\n",
       " (233, 176, 0.5),\n",
       " (233, 631, 0.25),\n",
       " (233, 1204, 0.0),\n",
       " (233, 55, 0.5),\n",
       " (233, 1034, 0.5),\n",
       " (233, 14, 0.5),\n",
       " (233, 279, 0.5),\n",
       " (233, 1050, 0.25),\n",
       " (233, 784, 0.5),\n",
       " (233, 606, 0.75),\n",
       " (233, 924, 0.25),\n",
       " (233, 432, 0.25),\n",
       " (233, 402, 0.0),\n",
       " (233, 429, 0.75),\n",
       " (233, 221, 0.5),\n",
       " (233, 640, 0.75),\n",
       " (233, 207, 0.75),\n",
       " (233, 124, 0.5),\n",
       " (233, 635, 0.5),\n",
       " (233, 637, 0.75),\n",
       " (233, 68, 0.75),\n",
       " (233, 201, 0.5),\n",
       " (233, 1122, 0.5),\n",
       " (233, 1077, 0.25),\n",
       " (233, 160, 0.5),\n",
       " (233, 1009, 0.25),\n",
       " (233, 76, 0.5),\n",
       " (233, 1451, 0.75),\n",
       " (233, 179, 0.5),\n",
       " (233, 315, 0.75),\n",
       " (233, 130, 0.5),\n",
       " (233, 278, 0.5),\n",
       " (233, 477, 0.5),\n",
       " (233, 242, 0.0),\n",
       " (233, 257, 0.25),\n",
       " (233, 835, 0.75),\n",
       " (233, 15, 0.25),\n",
       " (233, 1014, 0.25),\n",
       " (233, 1448, 0.75),\n",
       " (233, 478, 1.0),\n",
       " (233, 236, 0.5),\n",
       " (233, 1203, 0.5),\n",
       " (233, 854, 0.5),\n",
       " (233, 115, 0.25),\n",
       " (233, 87, 0.5),\n",
       " (233, 204, 0.5),\n",
       " (233, 949, 0.25),\n",
       " (233, 99, 0.75),\n",
       " (233, 267, 0.25),\n",
       " (233, 181, 0.5),\n",
       " (233, 222, 0.5),\n",
       " (233, 624, 0.5),\n",
       " (233, 514, 1.0),\n",
       " (233, 434, 0.5),\n",
       " (233, 616, 0.5),\n",
       " (233, 1399, 0.5),\n",
       " (233, 498, 0.75),\n",
       " (233, 834, 0.5),\n",
       " (233, 485, 0.5),\n",
       " (233, 417, 0.5),\n",
       " (233, 97, 0.75),\n",
       " (233, 1010, 0.5),\n",
       " (233, 273, 0.5),\n",
       " (233, 530, 0.5),\n",
       " (233, 159, 0.25),\n",
       " (233, 9, 0.5),\n",
       " (233, 210, 0.5),\n",
       " (233, 0, 0.5),\n",
       " (233, 185, 0.5),\n",
       " (233, 134, 0.75),\n",
       " (233, 1167, 0.25),\n",
       " (233, 285, 0.5),\n",
       " (233, 617, 0.5),\n",
       " (233, 488, 0.5),\n",
       " (233, 141, 0.25),\n",
       " (233, 965, 0.75),\n",
       " (233, 177, 1.0),\n",
       " (233, 27, 0.75),\n",
       " (233, 442, 0.5),\n",
       " (233, 416, 0.5),\n",
       " (233, 1460, 0.25),\n",
       " (233, 31, 0.5),\n",
       " (233, 605, 1.0),\n",
       " (233, 1185, 0.75),\n",
       " (233, 964, 0.5),\n",
       " (233, 356, 0.75),\n",
       " (233, 377, 0.75),\n",
       " (233, 471, 0.25),\n",
       " (233, 162, 0.5),\n",
       " (233, 734, 0.5),\n",
       " (233, 86, 0.5),\n",
       " (233, 288, 0.75),\n",
       " (233, 670, 0.5),\n",
       " (233, 175, 0.5),\n",
       " (233, 135, 0.75),\n",
       " (233, 622, 0.25),\n",
       " (233, 20, 0.5),\n",
       " (233, 70, 0.5),\n",
       " (233, 187, 0.25),\n",
       " (233, 196, 1.0),\n",
       " (233, 581, 0.75),\n",
       " (233, 963, 0.75),\n",
       " (233, 807, 0.25),\n",
       " (233, 8, 0.5),\n",
       " (233, 30, 0.75),\n",
       " (233, 583, 0.5),\n",
       " (233, 7, 1.0),\n",
       " (233, 463, 0.75),\n",
       " (233, 1452, 0.25),\n",
       " (233, 944, 0.5),\n",
       " (233, 649, 0.5),\n",
       " (233, 84, 0.25),\n",
       " (233, 469, 0.25),\n",
       " (233, 745, 0.25),\n",
       " (233, 161, 0.5),\n",
       " (233, 1445, 0.5),\n",
       " (233, 461, 0.75),\n",
       " (233, 293, 0.5),\n",
       " (233, 836, 0.5),\n",
       " (233, 199, 1.0),\n",
       " (233, 289, 0.5),\n",
       " (233, 1184, 0.5),\n",
       " (233, 431, 0.75),\n",
       " (233, 328, 0.25),\n",
       " (233, 72, 0.25),\n",
       " (233, 6, 0.25),\n",
       " (233, 549, 0.25),\n",
       " (233, 587, 0.5),\n",
       " (233, 320, 0.25),\n",
       " (233, 129, 0.0),\n",
       " (233, 1262, 0.5),\n",
       " (233, 209, 0.5),\n",
       " (233, 767, 0.25),\n",
       " (233, 116, 0.25),\n",
       " (233, 601, 0.75),\n",
       " (233, 484, 0.5),\n",
       " (233, 388, 0.5),\n",
       " (233, 831, 0.25),\n",
       " (233, 1462, 1.0),\n",
       " (233, 509, 0.75),\n",
       " (233, 24, 0.5)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x  in training_user_item_rating_tuples if x[0]==233]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374434275f364c40870cb4c0f31b2ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=90570.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# We'll create a factorization model with 20-dimensinal latent factors for users and items\n",
    "model = MatrixFactorization(943, 1682, n_factors=3)\n",
    "\n",
    "# Use Mean Squared Error (MSE) loss to decide how wrong our predictions are\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# This is stochastic gradient descent\n",
    "optimizer = torch.optim.SGD(model.parameters(),\n",
    "                            lr=1e-6)\n",
    "\n",
    "num_epochs=1\n",
    "\n",
    "# Tell pytorch we're going to train the model\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    random.shuffle(training_user_item_rating_tuples)\n",
    "\n",
    "    for user, item, rating in tqdm(training_user_item_rating_tuples):\n",
    "        optimizer.zero_grad()    \n",
    "\n",
    "        # Get user, item and rating data and put them in a pytorch Tensor object\n",
    "        rating = Variable(torch.FloatTensor([rating]))\n",
    "        user = Variable(torch.LongTensor([user]))\n",
    "        item = Variable(torch.LongTensor([item]))\n",
    "\n",
    "        # Predict the rating. Note that this is *implicitly* calling .forward(user, item)\n",
    "        # The notation seems weird at first, but this was adopt to remind everyone\n",
    "        # that nerural network are themselves _functions_ over their inputs!\n",
    "        prediction = model(user, item)\n",
    "\n",
    "        # The loss function (defined above) figures out how wrong the prediction was\n",
    "        loss = loss_fn(prediction, rating)\n",
    "\n",
    "        # Backpropagate the error in the loss through the network \n",
    "        # to figure out what needs to change\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights in the network using our particular optimizer\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5623, -0.3431, -0.1746]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.user_factors(torch.LongTensor([233]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2111, -1.3357, -0.9328]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.item_factors(torch.LongTensor([482]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7398], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.user_factors(torch.LongTensor([233])) \n",
    " * model.item_factors(torch.LongTensor([482]))).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell pytorch we're going to evaluate, so don't try to learn\n",
    "model.eval()\n",
    "\n",
    "pred_ratings = []\n",
    "gold_ratings = []\n",
    "for user, item, rating in tqdm(test_user_item_rating_tuples):\n",
    "\n",
    "    # Get user and item and put them in a pytorch Tensor object\n",
    "    user = Variable(torch.LongTensor([user]))\n",
    "    item = Variable(torch.LongTensor([item]))\n",
    "\n",
    "    # Predict the score again\n",
    "    prediction = model(user, item)\n",
    "    \n",
    "    # Get the value as a python float object\n",
    "    prediction = prediction.detach().numpy()[0]\n",
    "    \n",
    "    pred_ratings.append(prediction)\n",
    "    gold_ratings.append(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(gold_ratings, pred_ratings, squared=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
