{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d15fed5-2e86-408f-89bc-dfbde0453c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zim/.virtualenvs/SI650/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder, SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98cd1c37-fd53-4841-ad23-e09e89301146",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How many people live in Berlin?'\n",
    "docs = ['Berlin has a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.',\n",
    "        'Germany\\'a capital has a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.',\n",
    "        'New York City is famous for the Metropolitan Museum of Art.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1283bcf6-503a-4719-bf98-0b353c4c88d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 840/840 [00:00<00:00, 1.50MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 428M/428M [00:15<00:00, 27.5MB/s] \n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 541/541 [00:00<00:00, 1.05MB/s]\n",
      "Downloading (…)tencepiece.bpe.model: 100%|██████████| 5.07M/5.07M [00:00<00:00, 25.9MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 9.10M/9.10M [00:00<00:00, 23.6MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 150/150 [00:00<00:00, 276kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Cross encoders take two inputs to compare them (e.g., a query an document)\n",
    "\n",
    "# We get the model from https://huggingface.co/cross-encoder/msmarco-MiniLM-L6-en-de-v1 \n",
    "# All of these models get specified by a string name, also shown at the top of the page.\n",
    "# The sentence_tranformers package builds on top of the huggingface library which provides\n",
    "# a bunch of pretrained models for us to use.\n",
    "cross_encoder_model = CrossEncoder('cross-encoder/msmarco-MiniLM-L6-en-de-v1', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aded2593-683c-4b2a-9328-56373d93c68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pairs of inputs for the model\n",
    "pairs = [(query, doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db0d3081-e3fc-4469-b1b4-6023d13ac5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.022886,  8.658829, -9.72064 ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A cross-encoder takes a pair (tuple[str,str]) as input\n",
    "scores = cross_encoder_model.predict(pairs)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20f6277-015e-417a-a74a-ae6a08f04c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bi-encoder takes one input (str) and turns it into a vector.\n",
    "# Then, we have to compare those vectors with dot product to estimate\n",
    "# their relevance (at least in the IR setting)\n",
    "\n",
    "# This model obtained from https://huggingface.co/sentence-transformers/msmarco-MiniLM-L12-cos-v5\n",
    "biencoder_model = SentenceTransformer('sentence-transformers/msmarco-MiniLM-L12-cos-v5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd48bc93-c807-4c77-8b16-c77393b8b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode query and documents. Note that we can encode the list of documents all at once!\n",
    "# We don't have to encode them one at a time. \n",
    "#\n",
    "# encode() has many useful arguments you should check out if you want to use a bi-encoder in practice\n",
    "query_emb = biencoder_model.encode(query)\n",
    "doc_emb = biencoder_model.encode(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8660e5-c16f-45bf-9985-12f597734edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(doc_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d15f756-14b4-4b43-b7e7-169d6c26e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See that the document embeddings are a matrix, with one row per document\n",
    "doc_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167c3595-3883-48f7-a2af-169de781a2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute dot score (unnormalized cosine similarity!) between query and all document embeddings.\n",
    "# These scores are our measure of relevance\n",
    "#\n",
    "# NOTE: this dot_score() is going to return a pytorch Tensor object. We'll want to \n",
    "# move this to a numpy representation which we can get with cpu() and then we'll\n",
    "# convert it to a list of values\n",
    "scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dd8b36-b349-4501-853d-b3783b62a772",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's actually print the ranking\n",
    "\n",
    "# Combine docs & scores\n",
    "doc_score_pairs = list(zip(docs, scores))\n",
    "\n",
    "# Sort by decreasing score\n",
    "doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Output passages & scores\n",
    "for doc, score in doc_score_pairs:\n",
    "    print(score, doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
