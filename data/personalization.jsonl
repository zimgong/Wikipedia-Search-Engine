{"user_id": 1, "seed_docs": [{"docid": 18933234, "title": "Emacs", "text": "Emacs , originally named EMACS (an acronym for \"Editor MACroS\"), is a family of text editors that are characterized by their extensibility. The manual for the most widely used variant, GNU Emacs, describes it as \"the extensible, customizable, self-documenting, real-time display editor\". Development of the first Emacs began in the mid-1970s, and work on its direct descendant, GNU Emacs, continues actively; the latest version is 28.2, released in September 2022.\nEmacs has over 10,000 built-in commands and its user interface allows the user to combine these commands into macros to automate work. Implementations of Emacs typically feature a dialect of the Lisp programming language, allowing users and developers to write new commands and applications for the editor. Extensions have been written to, among other things, manage files, remote access, e-mail, outlines, multimedia, Git integration, and RSS feeds, as well as implementations of \"ELIZA\", \"Pong\", \"Conway's Life\", \"Snake\", \"Dunnet\", and \"Tetris\".\nThe original EMACS was written in 1976 by David A. Moon and Guy L. Steele Jr. as a set of Editor MACroS for the TECO editor. It was inspired by the ideas of the TECO-macro editors TECMAC and TMACS.\nThe most popular, and most ported, version of Emacs is GNU Emacs, which was created by Richard Stallman for the GNU Project. XEmacs is a variant that branched from GNU Emacs in 1991. GNU Emacs and XEmacs use similar Lisp dialects and are, for the most part, compatible with each other. XEmacs development is inactive.\nEmacs is, along with vi, one of the two main contenders in the traditional editor wars of Unix culture. Emacs is among the oldest free and open source projects still under development.\nHistory.\nEmacs development began during the 1970s at the MIT AI Lab, whose PDP-6 and PDP-10 computers used the Incompatible Timesharing System (ITS) operating system that featured a default line editor known as Tape Editor and Corrector (TECO). Unlike most modern text editors, TECO used separate modes in which the user would either add text, edit existing text, or display the document. One could not place characters directly into a document by typing them into TECO, but would instead enter a character ('i') in the TECO command language telling it to switch to input mode, enter the required characters, during which time the edited text was not displayed on the screen, and finally enter a character () to switch the editor back to command mode. (A similar technique was used to allow overtyping.) This behavior is similar to that of the program ed.\nBy the 1970s, TECO was already an old program, initially released in 1962. Richard Stallman visited the Stanford AI Lab in 1976 and saw the lab's \"E\" editor, written by Fred Wright. He was impressed by the editor's intuitive WYSIWYG (What You See Is What You Get) behavior, which has since become the default behavior of most modern text editors. He returned to MIT where Carl Mikkelsen, a hacker at the AI Lab, had added to TECO a combined display/editing mode called \"Control-R\" that allowed the screen display to be updated each time the user entered a keystroke. Stallman reimplemented this mode to run efficiently and then added a macro feature to the TECO display-editing mode that allowed the user to redefine any keystroke to run a TECO program.\nE had another feature that TECO lacked: random-access editing. TECO was a page-sequential editor that was designed for editing paper tape on the PDP-1 at a time when computer memory was generally small due to cost, and it was a feature of TECO that allowed editing on only one page at a time sequentially in the order of the pages in the file. Instead of adopting E's approach of structuring the file for page-random access on disk, Stallman modified TECO to handle large buffers more efficiently and changed its file-management method to read, edit, and write the entire file as a single buffer. Almost all modern editors use this approach.\nThe new version of TECO quickly became popular at the AI Lab and soon accumulated a large collection of custom macros whose names often ended in \"MAC\" or \"MACS\", which stood for \"macro\". Two years later, Guy Steele took on the project of unifying the diverse macros into a single set. Steele and Stallman's finished implementation included facilities for extending and documenting the new macro set. The resulting system was called EMACS, which stood for \"Editing MACroS\" or, alternatively, \"E with MACroS\". Stallman picked the name Emacs \"because  was not in use as an abbreviation on ITS at the time.\" An apocryphal hacker koan alleges that the program was named after \"Emack & Bolio's\", a popular Boston ice cream store. The first operational EMACS system existed in late 1976.\nStallman saw a problem in too much customization and \"de facto\" forking and set certain conditions for usage. He later wrote:\nThe original Emacs, like TECO, ran only on the PDP-10 running ITS. Its behavior was sufficiently different from that of TECO that it could be considered a text editor in its own right, and it quickly became the standard editing program on ITS. Mike McMahon ported Emacs from ITS to the TENEX and TOPS-20 operating systems. Other contributors to early versions of Emacs include Kent Pitman, Earl Killian, and Eugene Ciccarelli. By 1979, Emacs was the main editor used in MIT's AI lab and its Laboratory for Computer Science.\nImplementations.\nEarly implementations.\nIn the following years, programmers wrote a variety of Emacs-like editors for other computer systems. These included EINE (\"EINE Is Not EMACS\") and ZWEI (\"ZWEI Was EINE Initially\"), which were written for the Lisp machine by Mike McMahon and Daniel Weinreb, and Sine (\"Sine Is Not Eine\"), which was written by Owen Theodore Anderson. Weinreb's EINE was the first Emacs written in Lisp. In 1978, Bernard Greenberg wrote Multics Emacs almost entirely in Multics Lisp at Honeywell's Cambridge Information Systems Lab. Multics Emacs was later maintained by Richard Soley, who went on to develop the NILE Emacs-like editor for the NIL Project, and by Barry Margolin. Many versions of Emacs, including GNU Emacs, would later adopt Lisp as an extension language.\nJames Gosling, who would later invent NeWS and the Java programming language, wrote Gosling Emacs in 1981. The first Emacs-like editor to run on Unix, Gosling Emacs was written in C and used Mocklisp, a language with Lisp-like syntax, as an extension language.\nEarly Ads for Computer Corporation of America's \"CCA EMACS\" (Steve Zimmerman). appeared in 1984. 1985 comparisons to GNU Emacs, when it came out, mentioned free vs. $2,400.\nGNU Emacs.\nRichard Stallman began work on GNU Emacs in 1984 to produce a free software alternative to the proprietary Gosling Emacs. GNU Emacs was initially based on Gosling Emacs, but Stallman's replacement of its Mocklisp interpreter with a true Lisp interpreter required that nearly all of its code be rewritten. This became the first program released by the nascent GNU Project. GNU Emacs is written in C and provides Emacs Lisp, also implemented in C, as an extension language. Version 13, the first public release, was made on March 20, 1985. The first widely distributed version of GNU Emacs was version 15.34, released later in 1985. Early versions of GNU Emacs were numbered as \"1.x.x\", with the initial digit denoting the version of the C core. The \"1\" was dropped after version 1.12, as it was thought that the major number would never change, and thus the numbering skipped from \"1\" to \"13\". In September 2014, it was announced on the GNU emacs-devel mailing list that GNU Emacs would adopt a rapid release strategy and version numbers would increment more quickly in the future.\nGNU Emacs offered more features than Gosling Emacs, in particular a full-featured Lisp as its extension language, and soon replaced Gosling Emacs as the \"de facto\" Unix Emacs editor. Markus Hess exploited a security flaw in GNU Emacs' email subsystem in his 1986 cracking spree in which he gained superuser access to Unix computers.\nMost of GNU Emacs functionality is implemented through a scripting language called Emacs Lisp. Because about 70% of GNU Emacs is written in the Emacs Lisp extension language, one only needs to port the C core which implements the Emacs Lisp interpreter. This makes porting Emacs to a new platform considerably less difficult than porting an equivalent project consisting of native code only.\nGNU Emacs development was relatively closed until 1999 and was used as an example of the \"Cathedral\" development style in \"The Cathedral and the Bazaar\". The project has since adopted a public development mailing list and anonymous CVS access. Development took place in a single CVS trunk until 2008 and was then switched to the Bazaar DVCS. On November 11, 2014, development was moved to Git.\nRichard Stallman has remained the principal maintainer of GNU Emacs, but he has stepped back from the role at times. Stefan Monnier and Chong Yidong were maintainers from 2008 to 2015. John Wiegley was named maintainer in 2015 after a meeting with Stallman at MIT. As of early 2014, GNU Emacs has had 579 individual committers throughout its history.\nXEmacs.\nLucid Emacs, based on an early alpha version of GNU Emacs 19, was developed beginning in 1991 by Jamie Zawinski and others at Lucid Inc. One of the best-known early forks in free software development occurred when the codebases of the two Emacs versions diverged and the separate development teams ceased efforts to merge them back into a single program. Lucid Emacs has since been renamed XEmacs. Its development is currently inactive, with the most recent stable version 21.4.22 released in January 2009 (while a beta was released in 2013), while GNU Emacs has implemented many formerly XEmacs-only features.\nOther forks of GNU Emacs.\nOther notable forks include:\nVarious Emacs editors.\nIn the past, projects aimed at producing small versions of Emacs proliferated. GNU Emacs was initially targeted at computers with a 32-bit flat address space and at least 1\u00a0MiB of RAM. Such computers were high end workstations and minicomputers in the 1980s, and this left a need for smaller reimplementations that would run on common personal computer hardware. Today's computers have more than enough power and capacity to eliminate these restrictions, but small clones have more recently been designed to fit on software installation disks or for use on less capable hardware.\nOther projects aim to implement Emacs in a different dialect of Lisp or a different programming language altogether. Although not all are still actively maintained, these clones include:\nFeatures.\nEmacs is primarily a text editor and is designed for manipulating pieces of text, although it is capable of formatting and printing documents like a word processor by interfacing with external programs such as LaTeX, Ghostscript or a web browser. Emacs provides commands to manipulate and differentially display semantic units of text such as words, sentences, paragraphs and source code constructs such as functions. It also features \"keyboard macros\" for performing user-defined batches of editing commands.\nGNU Emacs is a \"real-time display\" editor, as its edits are displayed onscreen as they occur. This is standard behavior for modern text editors but EMACS was among the earliest to implement this. The alternative is having to issue a distinct command to display text, (e.g. before or after modifying it). This was common in earlier (or merely simpler) line and context editors, such as QED (BTS, CTSS, Multics), ed (Unix), ED (CP/M), and Edlin (DOS).\nGeneral architecture.\nAlmost all of the functionality in Emacs, including basic editing operations such as the insertion of characters into a file, is achieved through functions written in a dialect of the Lisp programming language. The dialect used in GNU Emacs is known as Emacs Lisp (Elisp), and was developed expressly to port Emacs to GNU and Unix. The Emacs Lisp layer sits atop a stable core of basic services and platform abstraction written in the C programming language, which enables GNU Emacs to be ported to a wide variety of operating systems and architectures without modifying the implementation semantics of the Lisp system where most of the editor lives. In this Lisp environment, variables and functions can be modified with no need to rebuild or restart Emacs, with even newly redefined versions of core editor features being asynchronously compiled and loaded into the live environment to replace existing definitions. Modern GNU Emacs features both bytecode and native code compilation for Emacs Lisp.\nAll configuration is stored in variables, classes, and data structures, and changed by simply updating these live. The use of a Lisp dialect in this case is a key advantage, as Lisp syntax consists of so-called symbolic expressions (or sexprs), which can act as both evaluatable code expressions and as a data serialisation format akin to, but simpler and more general than, well known ones such as XML, JSON, and YAML. In this way there is little difference in practice between customising existing features and writing new ones, both of which are accomplished in the same basic way. This is operatively different from most modern extensible editors, for instance such as VS Code, in which separate languages are used to implement the interface and functions of the editor and encode its user-defined configuration and options. The goal of Emacs' open design is to transparently expose Emacs' internals to the Emacs user during normal use in the same way that they would be exposed to the Emacs developer working on the git tree, and to collapse as much as possible of the distinction between using Emacs and programming Emacs, while still providing a stable, practical, and responsive editing environment for novice users.\nInteractive data.\nThe main text editing data structure is the \"buffer\", a memory region containing data (usually text) with associated attributes. The most important of these are:\n\"Modes\", in particular, are an important concept in Emacs, providing a mechanism to disaggregate Emacs' functionality into sets of behaviours and keybinds relevant to specific buffers' data. \"Major modes\" provide a general package of functions and commands relevant to a buffer's data and the way users might be interacting with it (e.g. editing source code in a specific language, editing hex, viewing the filesystem, interacting with git, etc.), and \"minor modes\" define subsidiary collections of functionality applicable across many major modes (such as codice_1). Minor modes can be toggled on or off both locally to each buffer as well as globally across all buffers, while major modes can only be toggled per-buffer. Any other data relevant to a buffer but not bundled into a mode can be handled by simply focussing that buffer and live modifying the relevant data directly.\nAny interaction with the editor (like key presses or clicking a mouse button) is realized by evaluating Emacs Lisp code, typically a \"command\", which is a function explicitly designed for interactive use. Keys can be arbitrarily redefined and commands can also be accessed by name; some commands evaluate arbitrary Emacs Lisp code provided by the user in various ways (e.g. a family of codice_2 functions, operating on the codice_3, codice_4, or individual codice_5). Even the simplest user inputs (such a printable characters) are effectuated as Emacs Lisp functions, such as the codice_6 , bound by default to most keyboard keys in a typical text editing buffer, which parameterises itself with the locale-defined character associated with the key used to call it. \nFor example, pressing the key in a buffer that accepts text input evaluates the code , which inserts one copy of the character constant codice_7 \"at point\". The codice_8, in this case, is determined by what Emacs terms the \"universal argument\": all Emacs command code accepts a numeric value which, in its simplest usage, indicates repetition of an action, but in more complex cases (where repetition doesn't make sense) can yield other behaviours. These arguments may be supplied via command prefices, such as , or more compactly , which expands to . When no prefix is supplied, the universal argument is codice_8: every command implicitly runs once, but may be called multiply, or in a different way, when supplied with such a prefix. Such arguments may also be non-positive where it makes sense for them to be so - it is up to the function accepting the argument to determine, according to its own semantics, what a given number means to it. One common usage is for functions to perform actions in reverse simply by checking the sign of the univeral argument, such as a sort command which sorts in obverse by default and in reverse when called with a negative argument, using the absolute value of its argument as the sorting key (e.g. codice_10 sorting in reverse by column index (or delimiter) 7), or undo/redo, which are simply negatives of each other (traversing forward and backward through a recursive history of diffs by some number of steps at a time).\nCommand language.\nBecause of its relatively large vocabulary of commands, Emacs features a long-established \"command language\", to concisely express the keystrokes necessary to perform an action. This command language recognises the following shift and modifier keys: , , , , , and . Not all of these may be present on an IBM-style keyboard, though they can usually be configured as desired. These are represented in command language as the respective prefices: codice_11, codice_12, codice_13, codice_14, codice_15, and codice_16. Keys whose names are only printable with more than one character are enclosed in angle brackets. Thus, a keyboard shortcut such as (check dependent formulas and calculate all cells in all open workbooks in Excel) would be rendered in Emacs command language as codice_17, while an Emacs command like (incremental file search by filename-matching regexp), would be expressed as codice_18. Command language is also used to express the actions needed to invoke commands with no assigned shortcut: for example, the command codice_19 (which initialises a buffer in memory for temporary text storage and manipulation), when invoked by the user, will be reported back as codice_20, with Emacs scanning the namespace of contextually available commands to return the shortest sequence of keystrokes which uniquely lexicate it.\nDynamic display.\nBecause Emacs predates modern standard terminology for graphical user interfaces, it uses somewhat divergent names for familiar interface elements. Buffers, the data that Emacs users interact with, are displayed to the user inside \"windows\", which are tiled portions of the terminal screen or the GUI window, which Emacs refers to as \"frames\"; in modern terminology, an Emacs \"frame\" would be a window and an Emacs \"window\" would be a split. Depending on configuration, windows can include their own scroll bars, line numbers, sometimes a 'header line' typically to ease navigation, and a \"mode line\" at the bottom (usually displaying buffer name, the active modes and point position of the buffer among others). The bottom of every frame is used for output messages (then called 'echo area') and text input for commands (then called 'minibuffer').\nIn general, Emacs display elements (windows, frames, etc.) do not belong to any specific data or process. Buffers are not associated with windows, and multiple windows can be opened onto the same buffer, for example to track different parts of a long text side-by-side without scrolling back and forth, and multiple buffers can share the same text, for example to take advantage of different major modes in a mixed-language file. Similarly, Emacs instances are not associated with particular frames, and multiple frames can be opened displaying a single running Emacs process, e.g. a frame per screen in a multi-monitor setup, or a terminal frame connected via ssh from a remote system and a graphical frame displaying the same Emacs process via the local system's monitor. Just as buffers don't require windows, running Emacs processes do not require any frames, and one common usage pattern is to deploy Emacs as an \"editing server\": running it as a headless daemon and connecting to it via a frame-spawning client. This server can then be made available in any situation where an editor is required, simply by declaring the client program to be the user's codice_21 or codice_22 variable. Such a server continues to run in the background, managing any child processes, accumulating stdin from open pipes, ports, or fifos, performing periodic or pre-programmed actions, remembering buffer undo history, saved text snippets, command history, and other user state between editing sessions. In this mode of operation, Emacs overlaps the functionality of programs like screen and tmux.\nBecause of this separation of display concerns from editing functionality, Emacs can display roughly similarly on any device more complex than a dumb terminal, including providing typical graphical WIMP elements on sufficiently featureful text terminals - though graphical frames are the preferred mode of display, providing a strict superset of the features of text terminal frames.\nSelf-documenting.\nThe first Emacs contained a \"help\" library that included documentation for every command, variable and internal function. Because of this, Emacs proponents described the software as \"self-documenting\" in that it presents the user with information on its normal features and its current state. Each function includes a documentation string that is displayed to the user on request, a practice that subsequently spread to programming languages including Lisp, Java, Perl, and Python. This help system can take users to the actual code for each function, whether from a built-in library or an added third-party library.\nEmacs also has a built-in tutorial. Emacs displays instructions for performing simple editing commands and invoking the tutorial when it is launched with no file to edit. The tutorial is by Stuart Cracraft and Richard Stallman.\nCulture.\nChurch of Emacs.\nThe \"Church of Emacs\", formed by Richard Stallman, is a parody religion created for Emacs users. While it refers to vi as the \"editor of the beast\" (vi-vi-vi being 6-6-6 in Roman numerals), it does not oppose the use of vi; rather, it calls it proprietary software anathema. (\"Using a free version of vi is not a sin but a penance.\") The Church of Emacs has its own newsgroup, , that has posts purporting to support this parody religion. Supporters of vi have created an opposing \"Cult of vi\".\nStallman has jokingly referred to himself as \"St I\u200aGNU\u200acius\", a saint in the Church of Emacs.\nEmacs pinky.\nThere is folklore attributing a repetitive strain injury colloquially called \"Emacs pinky\" to Emacs' strong dependence on modifier keys, although there have not been any studies done to show Emacs causes more such problems than other keyboard-heavy computer programs.\nUsers have addressed this through various approaches. Some users recommend simply using the two Control keys on typical PC keyboards like Shift keys while touch typing to avoid overly straining the left pinky, a proper use of the keyboard will reduce the RSI. Software-side methods include:\nHardware solutions include special keyboards such as Kinesis's Contoured Keyboard, which places the modifier keys where they can easily be operated by the thumb, or the Microsoft Natural keyboard, whose large modifier keys are placed symmetrically on both sides of the keyboard and can be pressed with the palm of the hand. Foot pedals can also be used.\nThe \"Emacs pinky\" is a relatively recent development. The Space-cadet keyboard on which Emacs was developed had oversized Control keys that were adjacent to the space bar and were easy to reach with the thumb.\nTerminology.\nThe word \"emacs\" is sometimes pluralized as \"emacsen\", by phonetic analogy with boxen and VAXen, referring to different varieties of Emacs.", "categories": ["Category:1970s in computing", "Category:1976 software", "Category:All articles lacking reliable references", "Category:All articles with unsourced statements", "Category:Articles lacking reliable references from January 2021", "Category:Articles lacking reliable references from July 2019", "Category:Articles with short description", "Category:Articles with unsourced statements from January 2011", "Category:Articles with unsourced statements from November 2022", "Category:Commons category link from Wikidata"]}, {"docid": 273993, "title": "Stack (abstract data type)", "text": "In computer science, a stack is an abstract data type that serves as a collection of elements, with two main operations:\nAdditionally, a peek operation can, without modifying the stack, return the value of the last element added. Calling this structure a \"stack\" is by analogy to a set of physical items stacked one atop another, such as a stack of plates. \nThe order in which an element added to or removed from a stack is described as last in, first out, referred to by the acronym LIFO. As with a stack of physical objects, this structure makes it easy to take an item off the top of the stack, but accessing a datum deeper in the stack may require taking off multiple other items first.\nConsidered as a linear data structure, or more abstractly a sequential collection, the push and pop operations occur only at one end of the structure, referred to as the \"top\" of the stack. This data structure makes it possible to implement a stack as a singly linked list and as a pointer to the top element. A stack may be implemented to have a bounded capacity. If the stack is full and does not contain enough space to accept another element, the stack is in a state of stack overflow.\nA stack is needed to implement depth-first search.\nHistory.\nStacks entered the computer science literature in 1946, when Alan M. Turing used the terms \"bury\" and \"unbury\" as a means of calling and returning from subroutines. Subroutines had already been implemented in Konrad Zuse's Z4 in 1945.\nKlaus Samelson and Friedrich L. Bauer of Technical University Munich proposed the idea of a stack in 1955 and filed a patent in 1957. In March 1988, by which time Samelson was deceased, Bauer received the IEEE Computer Pioneer Award for the invention of the stack principle. Similar concepts were developed, independently, by Charles Leonard Hamblin in the first half of 1954 and by in 1958.\nStacks are often described using the analogy of a spring-loaded stack of plates in a cafeteria. Clean plates are placed on top of the stack, pushing down any already there. When a plate is removed from the stack, the one below it pops up to become the new top plate.\nNon-essential operations.\nIn many implementations, a stack has more operations than the essential \"push\" and \"pop\" operations. An example of a non-essential operation is \"top of stack\", or \"peek\", which observes the top element without removing it from the stack. This could be done with a \"pop\" followed by a \"push\" to return the same data to the stack, so it is not considered an essential operation. If the stack is empty, an underflow condition will occur upon execution of either the \"stack top\" or \"pop\" operations. Additionally, many implementations provide a check if the stack is empty and one that returns its size.\nSoftware stacks.\nImplementation.\nA stack can be easily implemented either through an array or a linked list, as stacks are just special cases of lists. What identifies the data structure as a stack, in either case, is not the implementation but the interface: the user is only allowed to pop or push items onto the array or linked list, with few other helper operations. The following will demonstrate both implementations, using pseudocode.\nArray.\nAn array can be used to implement a (bounded) stack, as follows. The first element, usually at the zero offset, is the bottom, resulting in codice_1 being the first element pushed onto the stack and the last element popped off. The program must keep track of the size (length) of the stack, using a variable \"top\" that records the number of items pushed so far, therefore pointing to the place in the array where the next element is to be inserted (assuming a zero-based index convention). Thus, the stack itself can be effectively implemented as a three-element structure:\n structure stack:\n maxsize : integer\n top : integer\n items : array of item\n procedure initialize(stk : stack, size : integer):\n stk.items \u2190 new array of \"size\" items, initially empty\n stk.maxsize \u2190 size\n stk.top \u2190 0\nThe \"push\" operation adds an element and increments the \"top\" index, after checking for overflow:\n procedure push(stk : stack, x : item):\n if stk.top = stk.maxsize:\n report overflow error\n else:\n stk.items[stk.top] \u2190 x\n stk.top \u2190 stk.top + 1\nSimilarly, \"pop\" decrements the \"top\" index after checking for underflow, and returns the item that was previously the top one:\n procedure pop(stk : stack):\n if stk.top = 0:\n report underflow error\n else:\n stk.top \u2190 stk.top \u2212 1\n r \u2190 stk.items[stk.top]\n return r\nUsing a dynamic array, it is possible to implement a stack that can grow or shrink as much as needed. The size of the stack is simply the size of the dynamic array, which is a very efficient implementation of a stack since adding items to or removing items from the end of a dynamic array requires amortized O(1) time.\nLinked list.\nAnother option for implementing stacks is to use a singly linked list. A stack is then a pointer to the \"head\" of the list, with perhaps a counter to keep track of the size of the list:\n structure frame:\n data : item\n next : frame or nil\n structure stack:\n head : frame or nil\n size : integer\n procedure initialize(stk : stack):\n stk.head \u2190 nil\n stk.size \u2190 0\nPushing and popping items happens at the head of the list; overflow is not possible in this implementation (unless memory is exhausted):\n procedure push(stk : stack, x : item):\n newhead \u2190 new frame\n newhead.data \u2190 x\n newhead.next \u2190 stk.head\n stk.head \u2190 newhead\n stk.size \u2190 stk.size + 1\n procedure pop(stk : stack):\n if stk.head = nil:\n report underflow error\n r \u2190 stk.head.data\n stk.head \u2190 stk.head.next\n stk.size \u2190 stk.size - 1\n return r\nStacks and programming languages.\nSome languages, such as Perl, LISP, JavaScript and Python, make the stack operations push and pop available on their standard list/array types. Some languages, notably those in the Forth family (including PostScript), are designed around language-defined stacks that are directly visible to and manipulated by the programmer.\nThe following is an example of manipulating a stack in Common Lisp (\" is the Lisp interpreter's prompt; lines not starting with \" are the interpreter's responses to expressions):\n> (setf stack (list 'a 'b 'c)) ;; set the variable \"stack\"\n> (pop stack) ;; get top (leftmost) element, should modify the stack\nA\n> stack ;; check the value of stack\n> (push 'new stack) ;; push a new top onto the stack\nSeveral of the C++ Standard Library container types have and operations with LIFO semantics; additionally, the template class adapts existing containers to provide a restricted API with only push/pop operations. PHP has an SplStack class. Java's library contains a class that is a specialization of . Following is an example program in Java language, using that class.\nimport java.util.Stack;\nclass StackDemo {\n public static void main(String[]args) {\n Stack stack = new Stack();\n stack.push(\"A\"); // Insert \"A\" in the stack\n stack.push(\"B\"); // Insert \"B\" in the stack\n stack.push(\"C\"); // Insert \"C\" in the stack\n stack.push(\"D\"); // Insert \"D\" in the stack\n System.out.println(stack.peek()); // Prints the top of the stack (\"D\")\n stack.pop(); // removing the top (\"D\")\n stack.pop(); // removing the next top (\"C\")\nHardware stack.\nA common use of stacks at the architecture level is as a means of allocating and accessing memory.\nBasic architecture of a stack.\nA typical stack is an area of computer memory with a fixed origin and a variable size. Initially the size of the stack is zero. A \"stack pointer,\" usually in the form of a hardware register, points to the most recently referenced location on the stack; when the stack has a size of zero, the stack pointer points to the origin of the stack.\nThe two operations applicable to all stacks are:\nThere are many variations on the basic principle of stack operations. Every stack has a fixed location, in memory, at which it begins. As data items are added to the stack, the stack pointer is displaced to indicate the current extent of the stack, which expands away from the origin.\nStack pointers may point to the origin of a stack or to a limited range of addresses either above or below the origin (depending on the direction in which the stack grows); however, the stack pointer cannot cross the origin of the stack. In other words, if the origin of the stack is at address 1000 and the stack grows downwards (towards addresses 999, 998, and so on), the stack pointer must never be incremented beyond 1000 (to 1001, 1002, etc.). If a pop operation on the stack causes the stack pointer to move past the origin of the stack, a \"stack underflow\" occurs. If a push operation causes the stack pointer to increment or decrement beyond the maximum extent of the stack, a \"stack overflow\" occurs.\nSome environments that rely heavily on stacks may provide additional operations, for example:\nStacks are often visualized growing from the bottom up (like real-world stacks). They may also be visualized growing from left to right, so that \"topmost\" becomes \"rightmost\", or even growing from top to bottom. The important feature is that the bottom of the stack is in a fixed position. The illustration in this section is an example of a top-to-bottom growth visualization: the top (28) is the stack \"bottom\", since the stack \"top\" (9) is where items are pushed or popped from.\nA \"right rotate\" will move the first element to the third position, the second to the first and the third to the second. Here are two equivalent visualizations of this process:\n apple banana\n banana ===right rotate==> cucumber\n cucumber apple\n cucumber apple\n banana ===left rotate==> cucumber\n apple banana\nA stack is usually represented in computers by a block of memory cells, with the \"bottom\" at a fixed location, and the stack pointer holding the address of the current \"top\" cell in the stack. The top and bottom terminology are used irrespective of whether the stack actually grows towards lower memory addresses or towards higher memory addresses.\nPushing an item on to the stack adjusts the stack pointer by the size of the item (either decrementing or incrementing, depending on the direction in which the stack grows in memory), pointing it to the next cell, and copies the new top item to the stack area. Depending again on the exact implementation, at the end of a push operation, the stack pointer may point to the next unused location in the stack, or it may point to the topmost item in the stack. If the stack points to the current topmost item, the stack pointer will be updated before a new item is pushed onto the stack; if it points to the next available location in the stack, it will be updated \"after\" the new item is pushed onto the stack.\nPopping the stack is simply the inverse of pushing. The topmost item in the stack is removed and the stack pointer is updated, in the opposite order of that used in the push operation.\nStack in main memory.\nMany CISC-type CPU designs, including the x86, Z80 and 6502, have a dedicated register for use as the call stack stack pointer with dedicated call, return, push, and pop instructions that implicitly update the dedicated register, thus increasing code density. Some CISC processors, like the PDP-11 and the 68000, also have special addressing modes for implementation of stacks, typically with a semi-dedicated stack pointer as well (such as A7 in the 68000). In contrast, most RISC CPU designs do not have dedicated stack instructions and therefore most, if not all, registers may be used as stack pointers as needed.\nStack in registers or dedicated memory.\nSome machines use a stack for arithmetic and logical operations; operands are pushed onto the stack, and arithmetic and logical operations act on the top one or more items on the stack, popping them off the stack and pushing the result onto the stack. Machines that function in this fashion are called stack machines.\nA number of mainframes and minicomputers were stack machines, the most famous being the Burroughs large systems. Other examples include the CISC HP 3000 machines and the CISC machines from Tandem Computers.\nThe x87 floating point architecture is an example of a set of registers organised as a stack where direct access to individual registers (relative to the current top) is also possible.\nHaving the top-of-stack as an implicit argument allows for a small machine code footprint with a good usage of bus bandwidth and code caches, but it also prevents some types of optimizations possible on processors permitting random access to the register file for all (two or three) operands. A stack structure also makes superscalar implementations with register renaming (for speculative execution) somewhat more complex to implement, although it is still feasible, as exemplified by modern x87 implementations.\nSun SPARC, AMD Am29000, and Intel i960 are all examples of architectures using register windows within a register-stack as another strategy to avoid the use of slow main memory for function arguments and return values.\nThere are also a number of small microprocessors that implements a stack directly in hardware and some microcontrollers have a fixed-depth stack that is not directly accessible. Examples are the PIC microcontrollers, the Computer Cowboys MuP21, the Harris RTX line, and the Novix NC4016. Many stack-based microprocessors were used to implement the programming language Forth at the microcode level.\nApplications of stacks.\nExpression evaluation and syntax parsing.\nCalculators employing reverse Polish notation use a stack structure to hold values. Expressions can be represented in prefix, postfix or infix notations and conversion from one form to another may be accomplished using a stack. Many compilers use a stack for parsing the syntax of expressions, program blocks etc. before translating into low-level code. Most programming languages are context-free languages, allowing them to be parsed with stack-based machines.\nBacktracking.\nAnother important application of stacks is backtracking. Consider a simple example of finding the correct path in a maze. There are a series of points, from the starting point to the destination. We start from one point. To reach the final destination, there are several paths. Suppose we choose a random path. After following a certain path, we realise that the path we have chosen is wrong. So we need to find a way by which we can return to the beginning of that path. This can be done with the use of stacks. With the help of stacks, we remember the point where we have reached. This is done by pushing that point into the stack. In case we end up on the wrong path, we can pop the last point from the stack and thus return to the last point and continue our quest to find the right path. This is called backtracking.\nThe prototypical example of a backtracking algorithm is depth-first search, which finds all vertices of a graph that can be reached from a specified starting vertex. Other applications of backtracking involve searching through spaces that represent potential solutions to an optimization problem. Branch and bound is a technique for performing such backtracking searches without exhaustively searching all of the potential solutions in such a space.\nCompile-time memory management.\nA number of programming languages are stack-oriented, meaning they define most basic operations (adding two numbers, printing a character) as taking their arguments from the stack, and placing any return values back on the stack. For example, PostScript has a return stack and an operand stack, and also has a graphics state stack and a dictionary stack. Many virtual machines are also stack-oriented, including the p-code machine and the Java Virtual Machine.\nAlmost all calling conventionsthe ways in which subroutines receive their parameters and return resultsuse a special stack (the \"call stack\") to hold information about procedure/function calling and nesting in order to switch to the context of the called function and restore to the caller function when the calling finishes. The functions follow a runtime protocol between caller and callee to save arguments and return value on the stack. Stacks are an important way of supporting nested or recursive function calls. This type of stack is used implicitly by the compiler to support CALL and RETURN statements (or their equivalents) and is not manipulated directly by the programmer.\nSome programming languages use the stack to store data that is local to a procedure. Space for local data items is allocated from the stack when the procedure is entered, and is deallocated when the procedure exits. The C programming language is typically implemented in this way. Using the same stack for both data and procedure calls has important security implications (see below) of which a programmer must be aware in order to avoid introducing serious security bugs into a program.\nEfficient algorithms.\nSeveral algorithms use a stack (separate from the usual function call stack of most programming languages) as the principal data structure with which they organize their information. These include:\nSecurity.\nSome computing environments use stacks in ways that may make them vulnerable to security breaches and attacks. Programmers working in such environments must take special care to avoid the pitfalls of these implementations.\nFor example, some programming languages use a common stack to store both data local to a called procedure and the linking information that allows the procedure to return to its caller. This means that the program moves data into and out of the same stack that contains critical return addresses for the procedure calls. If data is moved to the wrong location on the stack, or an oversized data item is moved to a stack location that is not large enough to contain it, return information for procedure calls may be corrupted, causing the program to fail.\nMalicious parties may attempt a stack smashing attack that takes advantage of this type of implementation by providing oversized data input to a program that does not check the length of input. Such a program may copy the data in its entirety to a location on the stack, and in so doing it may change the return addresses for procedures that have called it. An attacker can experiment to find a specific type of data that can be provided to such a program such that the return address of the current procedure is reset to point to an area within the stack itself (and within the data provided by the attacker), which in turn contains instructions that carry out unauthorized operations.\nThis type of attack is a variation on the buffer overflow attack and is an extremely frequent source of security breaches in software, mainly because some of the most popular compilers use a shared stack for both data and procedure calls, and do not verify the length of data items. Frequently, programmers do not write code to verify the size of data items, either, and when an oversized or undersized data item is copied to the stack, a security breach may occur.", "categories": ["Category:Abstract data types", "Category:Articles containing German-language text", "Category:Articles with GND identifiers", "Category:Articles with example pseudocode", "Category:Articles with short description", "Category:CS1: long volume value", "Category:CS1 German-language sources (de)", "Category:CS1 location test", "Category:Commons category link is on Wikidata", "Category:Short description matches Wikidata"]}, {"docid": 1228060, "title": "Internet privacy", "text": "Internet privacy involves the right or mandate of personal privacy concerning the storing, re-purposing, provision to third parties, and displaying of information pertaining to oneself via Internet. Internet privacy is a subset of data privacy. Privacy concerns have been articulated from the beginnings of large-scale computer sharing and especially relate to mass surveillance enabled by the emergence of computer technologies.\nPrivacy can entail either personally identifiable information (PII) or non-PII information such as a site visitor's behavior on a website. PII refers to any information that can be used to identify an individual. For example, age and physical address alone could identify who an individual is without explicitly disclosing their name, as these two factors are unique enough to identify a specific person typically. Other forms of PII may soon include GPS tracking data used by apps, as the daily commute and routine information can be enough to identify an individual.\nIt has been suggested that the \"appeal of online services is to broadcast personal information on purpose.\" On the other hand, in his essay \"The Value of Privacy\", security expert Bruce Schneier says, \"Privacy protects us from abuses by those in power, even if we're doing nothing wrong at the time of surveillance.\"\nLevels of privacy.\nInternet and digital privacy are viewed differently from traditional expectations of privacy. Internet privacy is primarily concerned with protecting user information. Law Professor Jerry Kang explains that the term privacy expresses space, decision, and information. In terms of space, individuals have an expectation that their physical spaces (e.g. homes, cars) not be intruded. Information privacy is in regards to the collection of user information from a variety of sources.\nIn the United States, the 1997 Information Infrastructure Task Force (IITF) created under President Clinton defined information privacy as \"an individual's claim to control the terms under which personal information \u2014 information identifiable to the individual \u2014 is acquired, disclosed, and used.\" At the end of the 1990s, with the rise of the internet, it became clear that governments, companies, and other organizations would need to abide by new rules to protect individuals' privacy. With the rise of the internet and mobile networks internet privacy is a daily concern for users.\nPeople with only a casual concern for Internet privacy need not achieve total anonymity. Internet users may protect their privacy through controlled disclosure of personal information. The revelation of IP addresses, non-personally-identifiable profiling, and similar information might become acceptable trade-offs for the convenience that users could otherwise lose using the workarounds needed to suppress such details rigorously. On the other hand, some people desire much stronger privacy. In that case, they may try to achieve \"Internet anonymity\" to ensure privacy \u2014 use of the Internet without giving any third parties the ability to link the Internet activities to personally-identifiable information of the Internet user. In order to keep their information private, people need to be careful with what they submit to and look at online. When filling out forms and buying merchandise, information is tracked and because it was not private, some companies send Internet users spam and advertising on similar products.\nThere are also several governmental organizations that protect an individual's privacy and anonymity on the Internet, to a point. In an article presented by the FTC, in October 2011, a number of pointers were brought to attention that helps an individual internet user avoid possible identity theft and other cyber-attacks. Preventing or limiting the usage of Social Security numbers online, being wary and respectful of emails including spam messages, being mindful of personal financial details, creating and managing strong passwords, and intelligent web-browsing behaviors are recommended, among others.\nPosting things on the Internet can be harmful or expose people to malicious attacks. Some information posted on the Internet persists for decades, depending on the terms of service, and privacy policies of particular services offered online. This can include comments written on blogs, pictures, and websites, such as Facebook and Twitter. Once it is posted, anyone can potentially find it and access it. Some employers may research a potential employee by searching online for the details of their online behaviors, possibly affecting the outcome of the success of the candidate.\nRisks of Internet privacy.\nCompanies are hired to track which websites people visit and then use the information, for instance by sending advertising based on one's web browsing history. There are many ways in which people can divulge their personal information, for instance by use of \"social media\" and by sending bank and credit card information to various websites. Moreover, directly observed behavior, such as browsing logs, search queries, or contents of a Facebook profile can be automatically processed to infer potentially more intrusive details about an individual, such as sexual orientation, political and religious views, race, substance use, intelligence, and personality.\nThose concerned about Internet privacy often cite a number of \"privacy risks\" \u2014 events that can compromise privacy \u2014 which may be encountered through online activities. These range from the gathering of statistics on users to more malicious acts such as the spreading of spyware and the exploitation of various forms of bugs (software faults).\nSeveral social networking websites try to protect the personal information of their subscribers, as well as provide a warning through a privacy and terms agreement. For example, privacy settings on Facebook are available to all registered users: they can block certain individuals from seeing their profile, they can choose their \"friends\", and they can limit who has access to their pictures and videos. Privacy settings are also available on other social networking websites such as Google Plus and Twitter. The user can apply such settings when providing personal information on the Internet. The Electronic Frontier Foundation has created a set of guides so that users may more easily use these privacy settings and Zebra Crossing: an easy-to-use digital safety checklist is a volunteer-maintained online resource.\nIn late 2007, Facebook launched the Beacon program in which user rental records were released to the public for friends to see. Many people were enraged by this breach of privacy, and the \"Lane v. Facebook, Inc.\" case ensued.\nChildren and adolescents often use the Internet (including social media) in ways that risk their privacy; a cause for growing concern among parents. Young people also may not realize that all their information and browsing can and may be tracked while visiting a particular site and that it is up to them to protect their own privacy. For example, on Twitter, threats include shortened links that may lead to potentially harmful websites or content. Email threats include email scams and attachments that persuade users to install malware and disclose personal information. On Torrent sites, threats include malware hiding in video, music, and software downloads. When using a smartphone, threats include geolocation, meaning that one's phone can detect where one's location and post it online for all to see. Users can protect themselves by updating virus protection, using security settings, downloading patches, installing a firewall, screening email, shutting down spyware, controlling cookies, using encryption, fending off browser hijackers, and blocking pop-ups.\nHowever, most people have little idea how to go about doing these things. Many businesses hire professionals to take care of these issues, but most individuals can only do their best to educate themselves.\nIn 1998, the Federal Trade Commission in the US considered the lack of privacy for children on the internet and created the Children Online Privacy Protection Act (COPPA). COPPA limits the options which gather information from children and created warning labels if potential harmful information or content was presented. In 2000, the Children's Internet Protection Act (CIPA) was developed to implement Internet safety policies. Policies required taking technology protection measures that can filter or block children's Internet access to pictures that are harmful to them. Schools and libraries need to follow these requirements in order to receive discounts from E-rate program. These laws, awareness campaigns, parental and adult supervision strategies, and Internet filters can all help to make the Internet safer for children around the world.\nThe privacy concerns of Internet users pose a serious challenge (Dunkan, 1996; Till, 1997). Owing to the advancement in technology, access to the internet has become easier to use from any device at any time. However, the increase of access from multiple sources increases the number of access points for an attack. In an online survey, approximately seven out of ten individuals responded that what worries them most is their privacy over the Internet, rather than over the mail or phone. Internet privacy is slowly but surely becoming a threat, as a person's personal data may slip into the wrong hands if passed around through the Web.\nInternet protocol (IP) addresses.\nAll websites receive and many track the IP address of a visitor's computer. Companies match data over time to associate the name, address, and other information to the IP address. There is ambiguity about how private IP addresses are. The Court of Justice of the European Union has ruled they need to be treated as personally identifiable information if the website tracking them, or a third party like a service provider, knows the name or street address of the IP address holder, which would be true for static IP addresses, not for dynamic addresses.\nCalifornia regulations say IP addresses need to be treated as personal information if the business itself, not a third party, can link them to name and street address.\nAn Alberta court ruled that police can obtain the IP addresses and the names and addresses associated with them without a search warrant; the Calgary, Alberta police found IP addresses that initiated online crimes. The service provider gave police the names and addresses associated with those IP addresses.\nHTTP cookies.\nAn HTTP cookie is data stored on a user's computer that assists in automated access to websites or web features, or other state information required in complex web sites. It may also be used for user-tracking by storing special usage history data in a cookie, and such cookies \u2014 for example, those used by Google Analytics \u2014 are called \"tracking cookies\". Cookies are a common concern in the field of Internet privacy. Although website developers most commonly use cookies for legitimate technical purposes, cases of abuse occur. In 2009, two researchers noted that social networking profiles could be connected to cookies, allowing the social networking profile to be connected to browsing habits.\nIn the past, websites have not generally made the user explicitly aware of the storing of cookies, however tracking cookies and especially \"third-party tracking cookies\" are commonly used as ways to compile long-term records of individuals' browsing histories \u2014 a privacy concern that prompted European and US lawmakers to take action in 2011. Cookies can also have implications for computer forensics. In past years, most computer users were not completely aware of cookies, but users have become conscious of possible detrimental effects of Internet cookies: a recent study done has shown that 58% of users have deleted cookies from their computer at least once, and that 39% of users delete cookies from their computer every month. Since cookies are advertisers' main way of targeting potential customers, and some customers are deleting cookies, some advertisers started to use persistent Flash cookies and zombie cookies, but modern browsers and anti-malware software can now block or detect and remove such cookies.\nThe original developers of cookies intended that only the website that originally distributed cookies to users could retrieve them, therefore returning only data already possessed by the website. However, in practice programmers can circumvent this restriction. Possible consequences include:\nCookies do have benefits. One is that for websites that one frequently visits that require a password, cookies may allow a user to not have to sign in every time. A cookie can also track one's preferences to show them websites that might interest them. Cookies make more websites free to use without any type of payment. Some of these benefits are also seen as negative. For example, one of the most common ways of theft is hackers taking one's username and password that a cookie saves. While many sites are free, they sell their space to advertisers. These ads, which are personalized to one's likes, can sometimes freeze one's computer or cause annoyance. Cookies are mostly harmless except for third-party cookies. These cookies are not made by the website itself but by web banner advertising companies. These third-party cookies are dangerous because they take the same information that regular cookies do, such as browsing habits and frequently visited websites, but then they share this information with other companies.\nCookies are often associated with pop-up windows because these windows are often, but not always, tailored to a person's preferences. These windows are an irritation because the close button may be strategically hidden in an unlikely part of the screen. In the worst cases, these pop-up ads can take over the screen and while one tries to close them, they can take one to another unwanted website.\nCookies are seen so negatively because they are not understood and go unnoticed while someone is simply surfing the internet. The idea that every move one makes while on the internet is being watched, would frighten most users.\nSome users choose to disable cookies in their web browsers. Such an action can reduce some privacy risks but may severely limit or prevent the functionality of many websites. All significant web browsers have this disabling ability built-in, with no external program required. As an alternative, users may frequently delete any stored cookies. Some browsers (such as Mozilla Firefox and Opera) offer the option to clear cookies automatically whenever the user closes the browser. A third option involves allowing cookies in general but preventing their abuse. There are also a host of wrapper applications that will redirect cookies and cache data to some other location. Concerns exist that the privacy benefits of deleting cookies have been over-stated.\nThe process of \"profiling\" (also known as \"tracking\") assembles and analyzes several events, each attributable to a single originating entity, in order to gain information (especially patterns of activity) relating to the originating entity. Some organizations engage in the profiling of people's web browsing, collecting the URLs of sites visited. The resulting profiles can potentially link with information that personally identifies the individual who did the browsing.\nSome web-oriented marketing-research organizations may use this practice legitimately, for example: in order to construct profiles of \"typical internet users\". Such profiles, which describe average trends of large groups of internet users rather than of actual individuals, can then prove useful for market analysis. Although the aggregate data does not constitute a privacy violation, some people believe that the initial profiling does.\nProfiling becomes a more contentious privacy issue when data-matching associates the profile of an individual with personally-identifiable information of the individual. This is why Google, the dominant ad platform, who uses cookies to allow marketers to track people has announced plans to \"kill the cookie.\"\nGovernments and organizations may set up honeypot websites \u2013 featuring controversial topics \u2013 with the purpose of attracting and tracking unwary people. This constitutes a potential danger for individuals.\nFlash cookies.\nWhen some users choose to disable HTTP cookies to reduce privacy risks as noted, new types of cookies were invented: since cookies are advertisers' main way of targeting potential customers, and some customers were deleting cookies, some advertisers started to use persistent Flash cookies and zombie cookies. In a 2009 study, Flash cookies were found to be a popular mechanism for storing data on the top 100 most visited sites. Another 2011 study of social media found that, \"Of the top 100 web sites, 31 had at least one overlap between HTTP and Flash cookies.\" However, modern browsers and anti-malware software can now block or detect and remove such cookies.\nFlash cookies, also known as local shared objects, work the same ways as normal cookies and are used by the Adobe Flash Player to store information at the user's computer. They exhibit a similar privacy risk as normal cookies, but are not as easily blocked, meaning that the option in most browsers to not accept cookies does not affect Flash cookies. One way to view and control them is with browser extensions or add-ons.\nFlash cookies are unlike HTTP cookies in a sense that they are not transferred from the client back to the server. Web browsers read and write these cookies and can track any data by web usage.\nAlthough browsers such as Internet Explorer 8 and Firefox 3 have added a \"Privacy Browsing\" setting, they still allow Flash cookies to track the user and operate fully. However, the Flash player browser plugin can be disabled or uninstalled, and Flash cookies can be disabled on a per-site or global basis. Adobe's Flash and (PDF) Reader are not the only browser plugins whose past security defects have allowed spyware or malware to be installed: there have also been problems with Oracle's Java.\nEvercookies.\nEvercookies, created by Samy Kamkar, are JavaScript-based applications which produce cookies in a web browser that actively \"resist\" deletion by redundantly copying themselves in different forms on the user's machine (e.g., Flash Local Shared Objects, various HTML5 storage mechanisms, window.name caching, etc.), and resurrecting copies that are missing or expired. Evercookie accomplishes this by storing the cookie data in several types of storage mechanisms that are available on the local browser. It has the ability to store cookies in over ten types of storage mechanisms so that once they are on one's computer they will never be gone. Additionally, if evercookie has found the user has removed any of the types of cookies in question, it recreates them using each mechanism available. Evercookies are one type of zombie cookie. However, modern browsers and anti-malware software can now block or detect and remove such cookies.\nAnti-fraud uses.\nSome anti-fraud companies have realized the potential of evercookies to protect against and catch cyber criminals. These companies already hide small files in several places on the perpetrator's computer but hackers can usually easily get rid of these. The advantage to evercookies is that they resist deletion and can rebuild themselves.\nAdvertising uses.\nThere is controversy over where the line should be drawn on the use of this technology. Cookies store unique identifiers on a person's computer that are used to predict what one wants. Many advertisement companies want to use this technology to track what their customers are looking at online. This is known as online behavioral advertising which allows advertisers to keep track of the consumer's website visits to personalize and target advertisements. Ever-cookies enable advertisers to continue to track a customer regardless of whether their cookies are deleted or not. Some companies are already using this technology but the ethics are still being widely debated.\nCriticism.\nAnonymizer \"nevercookies\" are part of a free Firefox plugin that protects against evercookies. This plugin extends Firefox's private browsing mode so that users will be completely protected from ever-cookies. Never-cookies eliminate the entire manual deletion process while keeping the cookies users want like browsing history and saved account information.\nDevice fingerprinting.\nA \"device fingerprint\" is information collected about the software and hardware of a remote computing device for the purpose of identifying individual devices even when persistent cookies (and also zombie cookies) cannot be read or stored in the browser, the client IP address is hidden, and even if one switches to another browser on the same device.\nThis may allow a service provider to detect and prevent identity theft and credit card fraud, but also to compile long-term records of individuals' browsing histories even when they're attempting to avoid tracking, raising a major concern for internet privacy advocates.\nThird Party Requests.\nThird Party Requests are HTTP data connections from client devices to addresses in the web which are different from the website the user is currently surfing on. Many alternative tracking technologies to cookies are based on third party requests. Their importance has increased during the last years and even accelerated after Mozilla (2019), Apple (2020), and Google (2022) have announced to block third party cookies by default. Third requests may be used for embedding external content (e.g. advertisements) or for loading external resources and functions (e.g. images, icons, fonts, captchas, JQuery resources and many others). Dependent on the type of resource loaded, such requests may enable third parties to execute a device fingerprint or place any other kind of marketing tag. Irrespective of the intention, such requests do often disclose information that may be sensitive, and they can be used for tracking either directly or in combination with other personally identifiable information . Most of the requests disclose referrer details that reveal the full URL of the actually visited website. In addition to the referrer URL further information may be transmitted by the use of other request methods such as HTTP POST. Since 2018 Mozilla partially mitigates the risk of third party requests by cutting the referrer information when using the private browsing mode. However, personal information may still be revealed to the requested address in other areas of the HTTP-header.\nPhotographs on the Internet.\nToday many people have digital cameras and post their photographs online, for example street photography practitioners do so for artistic purposes and social documentary photography practitioners do so to document people in everyday life. The people depicted in these photos might not want them to appear on the Internet. Police arrest photos, considered public record in many jurisdictions, are often posted on the Internet by online mug shot publishing sites.\nSome organizations attempt to respond to this privacy-related concern. For example, the 2005 Wikimania conference required that photographers have the prior permission of the people in their pictures, albeit this made it impossible for photographers to practice candid photography and doing the same in a public place would violate the photographers' free speech rights. Some people wore a \"no photos\" tag to indicate they would prefer not to have their photo taken .\nThe \"Harvard Law Review\" published a short piece called \"In The Face of Danger: Facial Recognition and Privacy Law\", much of it explaining how \"privacy law, in its current form, is of no help to those unwillingly tagged.\" Any individual can be unwillingly tagged in a photo and displayed in a manner that might violate them personally in some way, and by the time Facebook gets to taking down the photo, many people will have already had the chance to view, share, or distribute it. Furthermore, traditional tort law does not protect people who are captured by a photograph in public because this is not counted as an invasion of privacy. The extensive Facebook privacy policy covers these concerns and much more. For example, the policy states that they reserve the right to disclose member information or share photos with companies, lawyers, courts, government entities, etc. if they feel it absolutely necessary. The policy also informs users that profile pictures are mainly to help friends connect to each other. However, these, as well as other pictures, can allow other people to invade a person's privacy by finding out information that can be used to track and locate a certain individual. In an article featured in ABC News, it was stated that two teams of scientists found out that Hollywood stars could be giving up information about their private whereabouts very easily through pictures uploaded to the internet. Moreover, it was found that pictures taken by some phones and tablets including iPhones automatically attach the latitude and longitude of the picture taken through metadata unless this function is manually disabled.\nFace recognition technology can be used to gain access to a person's private data, according to a new study. Researchers at Carnegie Mellon University combined image scanning, cloud computing and public profiles from social network sites to identify individuals in the offline world. Data captured even included a user's social security number. Experts have warned of the privacy risks faced by the increased merging of online and offline identities. The researchers have also developed an 'augmented reality' mobile app that can display personal data over a person's image captured on a smartphone screen. Since these technologies are widely available, users' future identities may become exposed to anyone with a smartphone and an internet connection. Researchers believe this could force a reconsideration of future attitudes to privacy.\nGoogle Street View.\nGoogle Street View, released in the U.S. in 2007, is currently the subject of an ongoing debate about possible infringement on individual privacy. In an article entitled \"Privacy, Reconsidered: New Representations, Data Practices, and the Geoweb\", Sarah Elwood and Agnieszka Leszczynski (2011) argue that Google Street View \"facilitate[s] identification and disclosure with more immediacy and less abstraction.\" The medium through which Street View disseminates information, the photograph, is very immediate in the sense that it can potentially provide direct information and evidence about a person's whereabouts, activities, and private property. Moreover, the technology's disclosure of information about a person is less abstract in the sense that, if photographed, a person is represented on Street View in a virtual replication of his or her own real-life appearance. In other words, the technology removes abstractions of a person's appearance or that of his or her personal belongings \u2013 there is an immediate disclosure of the person and object, as they visually exist in real life. Although Street View began to blur license plates and people's faces in 2008, the technology is faulty and does not entirely ensure against accidental disclosure of identity and private property.\nElwood and Leszczynski note that \"many of the concerns leveled at Street View stem from situations where its photograph-like images were treated as definitive evidence of an individual's involvement in particular activities.\" In one instance, Ruedi Noser, a Swiss politician, barely avoided public scandal when he was photographed in 2009 on Google Street View walking with a woman who was not his wife \u2013 the woman was actually his secretary. Similar situations occur when Street View provides high-resolution photographs \u2013 and photographs hypothetically offer compelling objective evidence. But as the case of the Swiss politician illustrates, even supposedly compelling photographic evidence is sometimes subject to gross misinterpretation. This example further suggests that Google Street View may provide opportunities for privacy infringement and harassment through public dissemination of the photographs. Google Street View does, however, blur or remove photographs of individuals and private property from image frames if the individuals request further blurring and/or removal of the images. This request can be submitted, for review, through the \"report a problem\" button that is located on the bottom left-hand side of every image window on Google Street View, however, Google has made attempts to report a problem difficult by disabling the \"Why are you reporting the street view\" icon.\nSearch engines.\nSearch engines have the ability to track a user's searches. Personal information can be revealed through searches by the user's computer, account, or IP address being linked to the search terms used. Search engines have claimed a necessity to retain such information in order to provide better services, protect against security pressure, and protect against fraud.\nA search engine takes all of its users and assigns each one a specific ID number. Those in control of the database often keep records of where on the internet each member has traveled to. AOL's system is one example. AOL has a database 21 million members deep, each with their own specific ID number. The way that AOLSearch is set up, however, allows for AOL to keep records of all the websites visited by any given member. Even though the true identity of the user is not known, a full profile of a member can be made just by using the information stored by AOLSearch. By keeping records of what people query through AOL Search, the company is able to learn a great deal about them without knowing their names.\nSearch engines also are able to retain user information, such as location and time spent using the search engine, for up to ninety days. Most search engine operators use the data to get a sense of which needs must be met in certain areas of their field. People working in the legal field are also allowed to use information collected from these search engine websites. The Google search engine is given as an example of a search engine that retains the information entered for a period of three-fourths of a year before it becomes obsolete for public usage. Yahoo! follows in the footsteps of Google in the sense that it also deletes user information after a period of ninety days. Other search engines such as Ask! search engine has promoted a tool of \"AskEraser\" which essentially takes away personal information when requested.\nSome changes made to internet search engines included that of Google's search engine. Beginning in 2009, Google began to run a new system where the Google search became personalized. The item that is searched and the results that are shown remembers previous information that pertains to the individual. Google search engine not only seeks what is searched but also strives to allow the user to feel like the search engine recognizes their interests. This is achieved by using online advertising. A system that Google uses to filter advertisements and search results that might interest the user is by having a ranking system that tests relevancy that includes observation of the behavior users exude while searching on Google. Another function of search engines is the predictability of location. Search engines are able to predict where one's location is currently by locating IP Addresses and geographical locations.\nGoogle had publicly stated on January 24, 2012, that its privacy policy will once again be altered. This new policy would change the following for its users: (1) the privacy policy would become shorter and easier to comprehend and (2) the information that users provide would be used in more ways than it is presently being used. The goal of Google is to make users\u2019 experiences better than they currently are.\nThis new privacy policy is planned to come into effect on March 1, 2012. Peter Fleischer, the Global Privacy Counselor for Google, has explained that if a person is logged into his/her Google account, and only if he/she is logged in, information will be gathered from multiple Google services in which he/she has used in order to be more accommodating. Google's new privacy policy will combine all data used on Google's search engines (i.e., YouTube and Gmail) in order to work along the lines of a person's interests. A person, in effect, will be able to find what he/she wants at a more efficient rate because all searched information during times of login will help to narrow down new search results.\nGoogle's privacy policy explains what information they collect and why they collect it, how they use the information, and how to access and update information. Google will collect information to better service its users such as their language, which ads they find useful or people that are important to them online. Google announces they will use this information to provide, maintain, protect Google and its users. The information Google uses will give users more relevant search results and advertisements. The new privacy policy explains that Google can use shared information on one service in other Google services from people who have a Google account and are logged in. Google will treat a user as a single user across all of their products. Google claims the new privacy policy will benefit its users by being simpler. Google will, for example, be able to correct the spelling of a user's friend's name in a Google search or notify a user they are late based on their calendar and current location. Even though Google is updating their privacy policy, its core privacy guidelines will not change. For example, Google does not sell personal information or share it externally.\nUsers and public officials have raised many concerns regarding Google's new privacy policy. The main concern/issue involves the sharing of data from multiple sources. Because this policy gathers all information and data searched from multiple engines when logged into Google, and uses it to help assist users, privacy becomes an important element. Public officials and Google account users are worried about online safety because of all this information being gathered from multiple sources.\nSome users do not like the overlapping privacy policy, wishing to keep the service of Google separate. The update to Google's privacy policy has alarmed both public and private sectors. The European Union has asked Google to delay the onset of the new privacy policy in order to ensure that it does not violate E.U. law. This move is in accordance with objections to decreasing online privacy raised in other foreign nations where surveillance is more heavily scrutinized. Canada and Germany have both held investigations into the legality of both Facebook, against respective privacy acts, in 2010. The new privacy policy only heightens unresolved concerns regarding user privacy.\nAn additional feature of concern to the new Google privacy policy is the nature of the policy. One must accept all features or delete existing Google accounts. The update will affect the Google+ social network, therefore making Google+\u2019s settings uncustomizable, unlike other customizable social networking sites. Customizing the privacy settings of a social network is a key tactic that many feel is necessary for social networking sites. This update in the system has some Google+ users wary of continuing service. Additionally, some fear the sharing of data amongst Google services could lead to revelations of identities. Many using pseudonyms are concerned about this possibility, and defend the role of pseudonyms in literature and history.\nSome solutions to being able to protect user privacy on the internet can include programs such as \"Rapleaf\" which is a website that has a search engine that allows users to make all of one's search information and personal information private. Other websites that also give this option to their users are Facebook and Amazon.\nPrivacy focused search engines/browsers.\nSearch engines such as Startpage.com, Disconnect.me and Scroogle (defunct since 2012) anonymize Google searches. Some of the most notable Privacy-focused search-engines are:\nPrivacy issues of social networking sites.\nThe advent of the Web 2.0 has caused social profiling and is a growing concern for internet privacy. Web 2.0 is the system that facilitates participatory information sharing and collaboration on the internet, in social networking media websites like Facebook, Instagram, Twitter, and MySpace. These social networking sites have seen a boom in their popularity starting from the late 2000s. Through these websites, many people are giving their personal information out on the internet.\nIt has been a topic of discussion of who is held accountable for the collection and distribution of personal information. Some blame social networks, because they are responsible for storing the information and data, while others blame the users who put their information on these sites. This relates to the ever-present issue of how society regards social media sites. There is a growing number of people that are discovering the risks of putting their personal information online and trusting a website to keep it private. Yet in a recent study, researchers found that young people are taking measures to keep their posted information on Facebook private to some degree. Examples of such actions include managing their privacy settings so that certain content can be visible to \"Only Friends\" and ignoring Facebook friend requests from strangers.\nIn 2013 a class action lawsuit was filed against Facebook alleging the company scanned user messages for web links, translating them to \u201clikes\u201d on the user's Facebook profile. Data lifted from the private messages was then used for targeted advertising, the plaintiffs claimed. \"Facebook's practice of scanning the content of these messages violates the federal Electronic Communications Privacy Act (ECPA also referred to as the Wiretap Act), as well as California's Invasion of Privacy Act (CIPA), and section 17200 of California's Business and Professions Code,\" the plaintiffs said. This shows that once information is online it is no longer completely private. It is an increasing risk because younger people are having easier internet access than ever before, therefore they put themselves in a position where it is all too easy for them to upload information, but they may not have the caution to consider how difficult it can be to take that information down once it has been out in the open. This is becoming a bigger issue now that so much of society interacts online which was not the case fifteen years ago. In addition, because of the quickly evolving digital media arena, people's interpretation of privacy is evolving as well, and it is important to consider that when interacting online. New forms of social networking and digital media such as Instagram and Snapchat may call for new guidelines regarding privacy. What makes this difficult is the wide range of opinions surrounding the topic, so it is left mainly up to individual judgement to respect other people's online privacy in some circumstances.\nPrivacy issues of medical applications.\nWith the rise of technology focused applications, there has been a rise of medical apps available to users on smart devices. In a survey of 29 migraine management specific applications, researcher Mia T. Minen (et al.) discovered 76% had clear privacy policies, with 55% of the apps stated using the user data from these giving data to third parties for the use of advertising. The concerns raised discusses the applications without accessible privacy policies, and even more so - applications that are not properly adhering to the Health Insurance Portability and Accountability Act (HIPAA) are in need of proper regulation, as these apps store medical data with identifiable information on a user.\nInternet service providers.\nInternet users obtain internet access through an internet service provider (ISP). All data transmitted to and from users must pass through the ISP. Thus, an ISP has the potential to observe users' activities on the internet. ISPs can breach personal information such as transaction history, search history, and social media profiles of users. Hackers could use this opportunity to hack ISP and obtain sensitive information of victims.\nHowever, ISPs are usually prohibited from participating in such activities due to legal, ethical, business, or technical reasons.\nNormally ISPs do collect at least \"some\" information about the consumers using their services. From a privacy standpoint, ISPs would ideally collect only as much information as they require in order to provide internet connectivity (IP address, billing information if applicable, etc.).\nWhich information an ISP collects, what it does with that information, and whether it informs its consumers, pose significant privacy issues. Beyond the usage of collected information typical of third parties, ISPs sometimes state that they will make their information available to government authorities upon request. In the US and other countries, such a request does not necessarily require a warrant.\nAn ISP cannot know the contents of properly encrypted data passing between its consumers and the internet. For encrypting web traffic, https has become the most popular and best-supported standard. Even if users encrypt the data, the ISP still knows the IP addresses of the sender and of the recipient. (However, see the IP addresses section for workarounds.)\nAn Anonymizer such as I2P \u2013 The Anonymous Network or Tor can be used for accessing web services without them knowing one's IP address and without one's ISP knowing what the services are that one accesses. Additional software has been developed that may provide more secure and anonymous alternatives to other applications. For example, Bitmessage can be used as an alternative for email and Cryptocat as an alternative for online chat. On the other hand, in addition to End-to-End encryption software, there are web services such as Qlink which provide privacy through a novel security protocol which does not require installing any software.\nWhile signing up for internet services, each computer contains a unique IP, Internet Protocol address. This particular address will not give away private or personal information, however, a weak link could potentially reveal information from one's ISP.\nGeneral concerns regarding internet user privacy have become enough of a concern for a UN agency to issue a report on the dangers of identity fraud. In 2007, the Council of Europe held its first annual Data Protection Day on January 28, which has since evolved into the annual Data Privacy Day.\nT-Mobile USA does not store any information on web browsing. Verizon Wireless keeps a record of the websites a subscriber visits for up to a year. Virgin Mobile keeps text messages for three months. Verizon keeps text messages for three to five days. None of the other carriers keep texts of messages at all, but they keep a record of who texted who for over a year. AT&T Mobility keeps for five to seven years a record of who text messages who and the date and time, but not the content of the messages. Virgin Mobile keeps that data for two to three months.\nHTML5.\nHTML5 is the latest version of Hypertext Markup Language specification. HTML defines how user agents, such as web browsers, are to present websites based upon their underlying code. This new web standard changes the way that users are affected by the internet and their privacy on the internet. HTML5 expands the number of methods given to a website to store information locally on a client as well as the amount of data that can be stored. As such, privacy risks are increased. For instance, merely erasing cookies may not be enough to remove potential tracking methods since data could be mirrored in web storage, another means of keeping information in a user's web browser. There are so many sources of data storage that it is challenging for web browsers to present sensible privacy settings. As the power of web standards increases, so do potential misuses.\nHTML5 also expands access to user media, potentially granting access to a computer's microphone or webcam, a capability previously only possible through the use of plug-ins like Flash. It is also possible to find a user's geographical location using the geolocation API. With this expanded access comes increased potential for abuse as well as more vectors for attackers. If a malicious site was able to gain access to a user's media, it could potentially use recordings to uncover sensitive information thought to be unexposed. However, the World Wide Web Consortium, responsible for many web standards, feels that the increased capabilities of the web platform outweigh potential privacy concerns. They state that by documenting new capabilities in an open standardization process, rather than through closed source plug-ins made by companies, it is easier to spot flaws in specifications and cultivate expert advice.\nBesides elevating privacy concerns, HTML5 also adds a few tools to enhance user privacy. A mechanism is defined whereby user agents can share blacklists of domains that should not be allowed to access web storage. Content Security Policy is a proposed standard whereby sites may assign privileges to different domains, enforcing harsh limitations on JavaScript use to mitigate cross-site scripting attacks. HTML5 also adds HTML templating and a standard HTML parser which replaces the various parsers of web browser vendors. These new features formalize previously inconsistent implementations, reducing the number of vulnerabilities though not eliminating them entirely.\nBig data.\nBig data is generally defined as the rapid accumulation and compiling of massive amounts of information that is being exchanged over digital communication systems. The volume of data is large (often exceeding exabytes), cannot be handled by conventional computer processors, and is instead stored on large server-system databases. This information is assessed by analytic scientists using software programs, which paraphrase this information into multi-layered user trends and demographics. This information is collected from all around the internet, such as by popular services like Facebook, Google, Apple, Spotify or GPS systems.\nBig data provides companies with the ability to:\nReduction of risks to Internet privacy.\n\"Inc.\" magazine reports that the Internet's biggest corporations have hoarded Internet users' personal data and sold it for large financial profits.\nPrivate mobile messaging.\nThe magazine reports on a band of startup companies that are demanding privacy and aiming to overhaul the social-media business. Popular privacy-focused mobile messaging apps include Wickr, Wire, and Signal, which provide peer-to-peer encryption and give the user the capacity to control what message information is retained on the other end.\nProtection through information overflow.\nAccording to Nicklas Lundblad, another perspective on privacy protection is the assumption that the quickly growing amount of information produced will be beneficial. The reasons for this are that the costs for the surveillance will raise and that there is more noise, noise being understood as anything that interferes the process of a receiver trying to extract private data from a sender.\nIn this noise society, the collective expectation of privacy will increase, but the individual expectation of privacy will decrease. In other words, not everyone can be analyzed in detail, but one individual can be. Also, in order to stay unobserved, it can hence be better to blend in with the others than trying to use for example encryption technologies and similar methods. Technologies for this can be called Jante-technologies after the Law of Jante, which states that you are nobody special. This view offers new challenges and perspectives for the privacy discussion.\nPublic views.\nWhile internet privacy is widely acknowledged as the top consideration in any online interaction, as evinced by the public outcry over SOPA/CISPA, public understanding of online privacy policies is actually being negatively affected by the current trends regarding online privacy statements. Users have a tendency to skim internet privacy policies for information regarding the distribution of personal information only, and the more legalistic the policies appear, the less likely users are to even read the information. Coupling this with the increasingly exhaustive license agreements companies require consumers to agree to before using their product, consumers are reading less about their rights.\nFurthermore, if the user has already done business with a company, or is previously familiar with a product, they have a tendency to not read the privacy policies that the company has posted. As internet companies become more established, their policies may change, but their clients will be less likely to inform themselves of the change. This tendency is interesting because as consumers become more acquainted with the internet they are also more likely to be interested in online privacy. Finally, consumers have been found to avoid reading the privacy policies if the policies are not in a simple format, and even perceive these policies to be irrelevant. The less readily available terms and conditions are, the less likely the public is to inform themselves of their rights regarding the service they are using.\nConcerns of internet privacy and real-life implications.\nWhile dealing with the issue of internet privacy, one must first be concerned with not only the technological implications such as damaged property, corrupted files, and the like, but also with the potential for implications on their real lives. One such implication, which is rather commonly viewed as being one of the most daunting fears risks of the internet, is the potential for identity theft. Although it is a typical belief that larger companies and enterprises are the usual focus of identity thefts, rather than individuals, recent reports seem to show a trend opposing this belief. Specifically, it was found in a 2007 \"Internet Security Threat Report\" that roughly ninety-three percent of \"gateway\" attacks were targeted at unprepared home users. The term \"gateway attack\" was used to refer to an attack which aimed not at stealing data immediately, but rather at gaining access for future attacks.\nAccording to Symantec's \"Internet Security Threat Report\", this continues despite the increasing emphasis on internet security due to the expanding \"underground economy\". With more than fifty percent of the supporting servers located in the United States, this underground economy has become a haven for internet thieves, who use the system in order to sell stolen information. These pieces of information can range from generic things such as a user account or email to something as personal as a bank account number and PIN.\nWhile the processes these internet thieves use are abundant and unique, one popular trap people fall into is that of online purchasing. In a 2001 article titled \"Consumer Watch\", the popular online site PC World went called secure e-shopping a myth. Though unlike the gateway attacks mentioned above, these incidents of information being stolen through online purchases generally are more prevalent in medium to large e-commerce sites, rather than smaller individualized sites. This is assumed to be a result of the larger consumer population and purchases, which allow for more potential leeway with information.\nUltimately, however, the potential for a violation of one's privacy is typically out of their hands after purchasing from an online \"e-tailer\" or store. One of the most common forms in which hackers receive private information from online e-tailers actually comes from an attack placed upon the site's servers responsible for maintaining information about previous transactions. For as experts explain, these e-tailers are not doing nearly enough to maintain or improve their security measures. Even those sites that clearly present a privacy or security policy can be subject to hackers\u2019 havoc as most policies only rely upon encryption technology which only applies to the actual transfer of a customer's data. However, with this being said, most e-tailers have been making improvements, going as far as covering some of the credit card fees if the information's abuse can be traced back to the site's servers.\nAs one of the largest growing concerns American adults have of current internet privacy policies, identity and credit theft remain a constant figure in the debate surrounding privacy online. A 1997 study by the Boston Consulting Group showed that participants of the study were most concerned about their privacy on the internet compared to any other media. However, it is important to recall that these issues are not the only prevalent concerns society has. Another prevalent issue remains members of society sending disconcerting emails to one another. It is for this reason in 2001 that for one of the first times the public expressed approval of government intervention in their private lives.\nWith the overall public anxiety regarding the constantly expanding trend of online crimes, in 2001 roughly fifty-four percent of Americans polled showed a general approval for the FBI monitoring those emails deemed suspicious. Thus, it was born the idea for the FBI program: \"Carnivore\", which was going to be used as a searching method, allowing the FBI to hopefully home in on potential criminals. Unlike the overall approval of the FBI's intervention, Carnivore was not met with as much of a majority's approval. Rather, the public seemed to be divided with forty-five percent siding in its favor, forty-five percent opposed to the idea for its ability to potentially interfere with ordinary citizen's messages, and ten percent claiming indifference. While this may seem slightly tangent to the topic of internet privacy, it is important to consider that at the time of this poll, the general population's approval on government actions was declining, reaching thirty-one percent versus the forty-one percent it held a decade prior. This figure in collaboration with the majority's approval of FBI intervention demonstrates an emerging emphasis on the issue of internet privacy in society and more importantly, the potential implications it may hold on citizens\u2019 lives.\nOnline users must seek to protect the information they share with online websites, specifically social media. In today's Web 2.0 individuals have become the public producers of personal information. Users create their own digital trails that hackers and companies alike capture and utilize for a variety of marketing and advertisement targeting. A recent paper from the Rand Corporation claims \"privacy is not the opposite of sharing \u2013 rather, it is control over sharing.\" Internet privacy concerns arise from the surrender of personal information to engage in a variety of acts, from transactions to commenting in online forums. Protection against invasions of online privacy will require individuals to make an effort informing and protecting themselves via existing software solutions, to pay premiums for such protections or require individuals to place greater pressure on governing institutions to enforce privacy laws and regulations regarding consumer and personal information.\nImpact of internet surveillance tools on marginalized communities.\nInternet privacy issues also affect existing class distinctions in the United States, often disproportionately impacting historically marginalized groups typically classified by race and class. Individuals with access to private digital connections that have protective services are able to more easily prevent data privacy risks of personal information and surveillance issues. Members of historically marginalized communities face greater risks of surveillance through the process of data profiling, which increases the likelihood of being stereotyped, targeted, and exploited, thus exacerbating pre-existing inequities that foster uneven playing fields. There are severe, and often unintentional, implications for big data which results in data profiling. For example, automated systems of employment verification run by the federal government such as E-verify tend to misidentify people with names that do not adhere to standardized Caucasian-sounding names as ineligible to work in the United States, thus widening unemployment gaps and preventing social mobility. This case exemplifies how some programs have bias embedded within their codes.\nTools using algorithms and artificial intelligence have also been used to target marginalized communities with policing measures, such as using facial recognition softwares and predictive policing technologies that use data to predict where a crime will most likely occur, and who will engage in the criminal activity. Studies have shown that these tools exacerbate the existing issue of over-policing in areas that are predominantly home to marginalized groups. These tools and other means of data collection can also prohibit historically marginalized and low-income groups from financial services regulated by the state, such as securing loans for house mortgages. Black applicants are rejected by mortgage and mortgage refinancing services at a much higher rate than white people, exacerbating existing racial divisions. Members of minority groups have lower incomes and lower credit scores than white people, and often live in areas with lower home values. Another example of technologies being used for surveilling practices is seen in immigration. Border control systems often use artificial intelligence in facial recognition systems, fingerprint scans, ground sensors, aerial video surveillance machines, and decision-making in asylum determination processes. This has led to large-scale data storage and physical tracking of refugees and migrants.\nWhile broadband was implemented as a means to transform the relationship between historically marginalized communities and technology to ultimately narrow the digital inequalities, inadequate privacy protections compromise user rights, profile users, and spur skepticism towards technology among users. Some automated systems, like the United Kingdom government\u2019s Universal Credit system in 2013, have failed to take into account that people, often minorities, may already lack internet access or digital literacy skills and therefore be deemed ineligible for online identity verification requirements, such as forms for job applications or to receive social security benefits, for example. Marginalized communities using broadband services may also not be aware of how digital information flows and is shared with powerful media conglomerates, reflecting a broader sense of distrust and fear these communities have with the state. Marginalized communities may therefore end up feeling dissatisfied or targeted by broadband services, whether from nonprofit community service providers or state providers.\nLaws and regulations.\nGlobal privacy policies.\nThe General Data Protection Regulation (GDPR) is the toughest privacy and security law in the world. Though it was drafted and passed by the European Union (EU), it imposes obligations onto organizations anywhere, so long as they target or collect data related to people in the EU. There are no globally unified laws and regulations.\nEuropean General Data protection regulation.\nIn 2009 the European Union has for the first time created awareness on tracking practices when the ePrivacy-Directive (2009/136/EC) was put in force. In order to comply with this directive, websites had to actively inform the visitor about the use of cookies. This disclosure has been typically implemented by showing small information banners. 9 years later, by 25 May 2018 the European General Data Protection Regulation (GDPR) came in force, which targets to regulate and restrict the usage of personal data in general, irrespective of how the information is being processed. The regulation primarily applies to so-called \u201ccontrollers\u201d, which are (a) all organizations that process personal information within the European Union, and (b) all organizations which process personal information of EU-based persons outside the European Union. Article 4 (1) defines personal information as anything that may be used for identifying a \u201cdata subject\u201d (e.g. natural person) either directly or in combination with other personal information. In theory this even takes common internet identifiers such as cookies or IP-Addresses in scope of this regulation. Processing such personal information is restricted unless a \"lawful reason\" according to Article 6 (1) applies. The most important lawful reason for data processing on the internet is the explicit content given by the data subject. More strict requirements apply for sensitive personal information (Art 9), which may be used for revealing information about ethnic origin, political opinion, religion, trade union membership, biometrics, health or sexual orientation. However, explicit user content still is sufficient to process such sensitive personal information (Art 9 (2) lit a). \u201cExplicit consent\u201d requires an affirmative act (Art 4 (11)), which is given if the individual person is able to freely choose and does consequently actively opt in.\nAs per June 2020, typical cookie implementations are not compliant to this regulation, and other practices such as device fingerprinting, cross-website-logins or 3rd party-requests are typically not disclosed, even though many opinions consider such methods in scope of the GDPR. The reason for this controversy is the ePrivacy-Directive 2009/136/EC which is still unchanged in force. An updated version of this directive, formulated as ePrivacy Regulation, shall enlarge the scope from cookies only to any type of tracking method. It shall furthermore cover any kind of electronic communication channels such as Skype or WhatsApp. The new ePrivacy-Regulation was planned to come in force together with the GDPR, but as per July 2020 it was still under review. Some people assume that lobbying is the reason for this massive delay.\nIrrespective of the pending ePrivacy-Regulation, the European High Court has decided in October 2019 (case C-673/17) that the current law is not fulfilled if the disclosed information in the cookie disclaimer is imprecise, or if the consent checkbox is pre-checked. Consequently, many cookie disclaimers that were in use at that time were confirmed to be incompliant to the current data protection laws. However, even this high court judgement only refers to cookies and not to other tracking methods.\nInternet privacy in China.\nOne of the most popular topics of discussion in regards to internet privacy is China. Although China is known for its remarkable reputation on maintaining internet privacy among many online users, it could potentially be a major jeopardy to the lives of many online users who have their information exchanged on the web on a regular basis. For instance, in China, there is a new software that will enable the concept of surveillance among the majority of online users and present a risk to their privacy. The main concern with privacy of internet users in China is the lack thereof. China has a well known policy of censorship when it comes to the spread of information through public media channels. Censorship has been prominent in Mainland China since the communist party gained power in China over 60 years ago. With the development of the internet, however, privacy became more of a problem for the government. The Chinese Government has been accused of actively limiting and editing the information that flows into the country via various media. The internet poses a particular set of issues for this type of censorship, especially when search engines are involved. Yahoo! for example, encountered a problem after entering China in the mid-2000s. A Chinese journalist, who was also a Yahoo! user, sent private emails using the Yahoo! server regarding the Chinese government. Yahoo! provided information to the Chinese government officials track down journalist, Shi Tao. Shi Tao allegedly posted state secrets to a New York-based website. Yahoo provided incriminating records of the journalist's account logins to the Chinese government and thus, Shi Tao was sentenced to ten years in prison. These types of occurrences have been reported numerous times and have been criticized by foreign entities such as the creators of the Tor network, which was designed to circumvent network surveillance in multiple countries.\nUser privacy in China is not as cut-and-dry as it is in other parts of the world. China, reportedly, has a much more invasive policy when internet activity involves the Chinese government. For this reason, search engines are under constant pressure to conform to Chinese rules and regulations on censorship while still attempting to keep their integrity. Therefore, most search engines operate differently in China than in other countries, such as the US or Britain, if they operate in China at all. There are two types of intrusions that occur in China regarding the internet: the alleged intrusion of the company providing users with internet service, and the alleged intrusion of the Chinese government. The intrusion allegations made against companies providing users with internet service are based upon reports that companies, such as Yahoo! in the previous example, are using their access to the internet users' private information to track and monitor users' internet activity. Additionally, there have been reports that personal information has been sold. For example, students preparing for exams would receive calls from unknown numbers selling school supplies. The claims made against the Chinese government lie in the fact that the government is forcing internet-based companies to track users private online data without the user knowing that they are being monitored. Both alleged intrusions are relatively harsh and possibly force foreign internet service providers to decide if they value the Chinese market over internet privacy. Also, many websites are blocked in China such as Facebook and Twitter. However many Chinese internet users use special methods like a VPN to unblock websites that are blocked.\nInternet privacy in Sweden.\nSweden is considered to be at the forefront of internet use and regulations. On 11 May 1973 Sweden enacted the Data Act \u2212 the world's first national data protection law. They are constantly innovating the way that the internet is used and how it impacts their people. In 2012, Sweden received a Web Index Score of 100, a score that measures how the internet significantly influences political, social, and economic impact, placing them first among 61 other nations. Sweden received this score while in the process of exceeding new mandatory implementations from the European Union. Sweden placed more restrictive guidelines on the directive on intellectual property rights enforcement (IPRED) and passed the FRA-law in 2009 that allowed for the legal sanctioning of surveillance of internet traffic by state authorities. The FRA has a history of intercepting radio signals and has stood as the main intelligence agency in Sweden since 1942. Sweden has a mixture of government's strong push towards implementing policy and citizens' continued perception of a free and neutral internet. Both of the previously mentioned additions created controversy by critics but they did not change the public perception even though the new FRA-law was brought in front of the European Court of Human Rights for human rights violations. The law was established by the National Defense Radio Establishment (Forsvarets Radio Anstalt - FRA) to eliminate outside threats. However, the law also allowed for authorities to monitor all cross-border communication without a warrant. Sweden's recent emergence into internet dominance may be explained by their recent climb in users. Only 2% of all Swedes were connected to the internet in 1995 but at last count in 2012, 89% had broadband access. This was due in large part once again to the active Swedish government introducing regulatory provisions to promote competition among internet service providers. These regulations helped grow web infrastructure and forced prices below the European average.\nFor copyright laws, Sweden was the birthplace of the Pirate Bay, an infamous file-sharing website. File sharing has been illegal in Sweden since it was developed, however, there was never any real fear of being persecuted for the crime until 2009 when the Swedish Parliament was the first in the European Union to pass the intellectual property rights directive. This directive persuaded internet service providers to announce the identity of suspected violators.\nSweden also has its infamous centralized block list. The list is generated by authorities and was originally crafted to eliminate sites hosting child pornography. However, there is no legal way to appeal a site that ends up on the list and as a result, many non-child pornography sites have been blacklisted. Sweden's government enjoys a high level of trust from their citizens. Without this trust, many of these regulations would not be possible and thus many of these regulations may only be feasible in the Swedish context.\nInternet privacy in the United States.\nAndrew Grove, co-founder and former CEO of Intel Corporation, offered his thoughts on internet privacy in an interview published in May 2000:\nMore than two decades later, Susan Ariel Aaronson, director of the Digital Trade and Data Governance Hub at George Washington University observed, in 2022, that:\nOverview.\nWith the Republicans in control of all three branches of the U.S. government, lobbyists for internet service providers (ISPs) and tech firms persuaded lawmakers to dismantle regulations to protect privacy which had been made during the Obama administration. These FCC rules had required ISPs to get \"explicit consent\" before gathering and selling their private internet information, such as the consumers' browsing histories, locations of businesses visited and applications used. Trade groups wanted to be able to sell this information for profit. Lobbyists persuaded Republican senator Jeff Flake and Republican representative Marsha Blackburn to sponsor legislation to dismantle internet privacy rules; Flake received $22,700 in donations and Blackburn received $20,500 in donations from these trade groups. On March 23, 2017, abolition of these privacy protections passed on a narrow party-line vote. In June 2018, California passed the law restricting companies from sharing user data without permission. Also, users would be informed to whom the data is being sold and why. On refusal to sell the data, companies are allowed to charge a little higher to these consumers. Mitt Romney, despite approving a Twitter comment of Mark Cuban during a conversation with Glenn Greenwald about anonymity in January 2018, was revealed as the owner of the Pierre Delecto lurker account in October 2019.\nLegal threats.\nUsed by government agencies are array of technologies designed to track and gather internet users' information are the topic of much debate between privacy advocates, civil liberties advocates and those who believe such measures are necessary for law enforcement to keep pace with rapidly changing communications technology.\nSpecific examples:\nChildren and internet privacy.\nInternet privacy is a growing concern with children and the content they are able to view. Aside from that, many concerns for the privacy of email, the vulnerability of internet users to have their internet usage tracked, and the collection of personal information also exist. These concerns have begun to bring the issues of internet privacy before the courts and judges.", "categories": ["Category:All Wikipedia articles in need of updating", "Category:All Wikipedia neutral point of view disputes", "Category:All articles needing additional references", "Category:All articles that may contain original research", "Category:All articles with specifically marked weasel-worded phrases", "Category:All articles with style issues", "Category:All articles with unsourced statements", "Category:Articles needing additional references from June 2014", "Category:Articles that may contain original research from November 2022", "Category:Articles with excerpts"]}, {"docid": 2356314, "title": "Open-source software development", "text": "Open-source software development (OSSD) is the process by which open-source software, or similar software whose source code is publicly available, is developed by an open-source software project. These are software products available with its source code under an open-source license to study, change, and improve its design. Examples of some popular open-source software products are Mozilla Firefox, Google Chromium, Android, LibreOffice and the VLC media player.\nHistory.\nIn 1997, Eric S. Raymond wrote \"The Cathedral and the Bazaar\". In this book, Raymond makes the distinction between two kinds of software development. The first is the conventional closed-source development. This kind of development method is, according to Raymond, like the building of a cathedral; central planning, tight organization and one process from start to finish. The second is the progressive open-source development, which is more like \"a great babbling bazaar of differing agendas and approaches out of which a coherent and stable system could seemingly emerge only by a succession of miracles.\" The latter analogy points to the discussion involved in an open-source development process.\nDifferences between the two styles of development, according to Bar and Fogel, are in general the handling (and creation) of bug reports and feature requests, and the constraints under which the programmers are working. In closed-source software development, the programmers are often spending a lot of time dealing with and creating bug reports, as well as handling feature requests. This time is spent on creating and prioritizing further development plans. This leads to part of the development team spending a lot of time on these issues, and not on the actual development. Also, in closed-source projects, the development teams must often work under management-related constraints (such as deadlines, budgets, etc.) that interfere with technical issues of the software. In open-source software development, these issues are solved by integrating the users of the software in the development process, or even letting these users build the system themselves.\nModel.\nOpen-source software development can be divided into several phases. The phases specified here are derived from \"Sharma et al\". A diagram displaying the process-data structure of open-source software development is shown on the right. In this picture, the phases of open-source software development are displayed, along with the corresponding data elements. This diagram is made using the meta-modeling and meta-process modeling techniques.\nStarting an open-source project.\nThere are several ways in which work on an open-source project can start:\nEric Raymond observed in his essay \"The Cathedral and the Bazaar\" that announcing the intent for a project is usually inferior to releasing a working project to the public.\nIt's a common mistake to start a project when contributing to an existing similar project would be more effective (NIH syndrome). To start a successful project it is very important to investigate what's already there. The process starts with a choice between the adopting of an existing project, or the starting of a new project. If a new project is started, the process goes to the Initiation phase. If an existing project is adopted, the process goes directly to the Execution phase.\nTypes of open-source projects.\nSeveral types of open-source projects exist. First, there is the garden variety of software programs and libraries, which consist of standalone pieces of code. Some might even be dependent on other open-source projects. These projects serve a specified purpose and fill a definite need. Examples of this type of project include the Linux kernel, the Firefox web browser and the LibreOffice office suite of tools.\nDistributions are another type of open-source project. Distributions are collections of software that are published from the same source with a common purpose. The most prominent example of a \"distribution\" is an operating system. There are many Linux distributions (such as Debian, Fedora Core, Mandriva, Slackware, Ubuntu etc.) which ship the Linux kernel along with many user-land components. There are other distributions, like ActivePerl, the Perl programming language for various operating systems, and Cygwin distributions of open-source programs for Microsoft Windows.\nOther open-source projects, like the BSD derivatives, maintain the source code of an entire operating system, the kernel and all of its core components, in one revision control system; developing the entire system together as a single team. These operating system development projects closely integrate their tools, more so than in the other distribution-based systems.\nFinally, there is the book or standalone document project. These items usually do not ship as part of an open-source software package. The Linux Documentation Project hosts many such projects that document various aspects of the Linux operating system. There are many other examples of this type of open-source project.\nMethods.\nIt is hard to run an open-source project following a more traditional software development method like the waterfall model, because in these traditional methods it is not allowed to go back to a previous phase. In open-source software development, requirements are rarely gathered before the start of the project; instead they are based on early releases of the software product, as Robbins describes. Besides requirements, often volunteer staff is attracted to help develop the software product based on the early releases of the software. This networking effect is essential according to Abrahamsson et al.: \u201cif the introduced prototype gathers enough attention, it will gradually start to attract more and more developers\u201d. However, Abrahamsson et al. also point out that the community is very harsh, much like the business world of closed-source software: \u201cif you find the customers you survive, but without customers you die\u201d.\nFuggetta argues that \u201crapid prototyping, incremental and evolutionary development, spiral lifecycle, rapid application development, and, recently, extreme programming and the agile software process can be equally applied to proprietary and open source software\u201d. He also pinpoints Extreme Programming as an extremely useful method for open source software development. More generally, all Agile programming methods are applicable to open-source software development, because of their iterative and incremental character. Other Agile method are equally useful for both open and closed source software development:Internet-Speed Development, for example is suitable for open-source software development because of the distributed development principle it adopts. Internet-Speed Development uses geographically distributed teams to \u2018work around the clock\u2019. This method, mostly adopted by large closed-source firms, (because they're the only ones which afford development centers in different time zones), works equally well in open source projects because a software developed by a large group of volunteers shall naturally tend to have developers spread across all time zones.\nTools.\nCommunication channels.\nDevelopers and users of an open-source project are not all necessarily working on the project in proximity. They require some electronic means of communications. E-mail is one of the most common forms of communication among open-source developers and users. Often, electronic mailing lists are used to make sure e-mail messages are delivered to all interested parties at once. This ensures that at least one of the members can reply to it. In order to communicate in real time, many projects use an instant messaging method such as IRC. Web forums have recently become a common way for users to get help with problems they encounter when using an open-source product. Wikis have become common as a communication medium for developers and users.\nVersion control systems.\nIn OSS development the participants, who are mostly volunteers, are distributed amongst different geographic regions so there is need for tools to aid participants to collaborate in the development of source code.\nDuring early 2000s, Concurrent Versions System (CVS) was a prominent example of a source code collaboration tool being used in OSS projects. CVS helps manage the files and codes of a project when several people are working on the project at the same time. CVS allows several people to work on the same file at the same time. This is done by moving the file into the users\u2019 directories and then merging the files when the users are done. CVS also enables one to easily retrieve a previous version of a file. During mid 2000s, The Subversion revision control system (SVN) was created to replace CVS. It is quickly gaining ground as an OSS project version control system.\nMany open-source projects are now using distributed revision control systems, which scale better than centralized repositories such as SVN and CVS. Popular examples are git, used by the Linux kernel, and Mercurial, used by the Python programming language.\nBug trackers and task lists.\nMost large-scale projects require a bug tracking system to keep track of the status of various issues in the development of the project.\nTesting and debugging tools.\nSince OSS projects undergo frequent integration, tools that help automate testing during system integration are used. An example of such tool is Tinderbox. Tinderbox enables participants in an OSS project to detect errors during system integration. Tinderbox runs a continuous build process and informs users about the parts of source code that have issues and on which platform(s) these issues arise.\nA debugger is a computer program that is used to debug (and sometimes test or optimize) other programs. GNU Debugger (GDB) is an example of a debugger used in open-source software development. This debugger offers remote debugging, what makes it especially applicable to open-source software development.\nA memory leak tool or memory debugger is a programming tool for finding memory leaks and buffer overflows. A memory leak is a particular kind of unnecessary memory consumption by a computer program, where the program fails to release memory that is no longer needed. Examples of memory leak detection tools used by Mozilla are the XPCOM Memory Leak tools.\nValidation tools are used to check if pieces of code conform to the specified syntax. An example of a validation tool is Splint.\nPackage management.\nA package management system is a collection of tools to automate the process of installing, upgrading, configuring, and removing software packages from a computer. The Red Hat Package Manager (RPM) for .rpm and Advanced Packaging Tool (APT) for .deb file format, are package management systems used by a number of Linux distributions.\nPublicizing a project.\nSoftware directories and release logs:\nArticles:", "categories": ["Category:All articles needing additional references", "Category:All articles that may contain original research", "Category:All articles with unsourced statements", "Category:Articles needing additional references from May 2013", "Category:Articles that may contain original research from October 2019", "Category:Articles with short description", "Category:Articles with unsourced statements from November 2014", "Category:Articles with unsourced statements from October 2019", "Category:Free software", "Category:Short description matches Wikidata"]}, {"docid": 7933386, "title": "CUDA", "text": "CUDA (or Compute Unified Device Architecture) is a parallel computing platform and application programming interface (API) that allows software to use certain types of graphics processing units (GPUs) for general purpose processing, an approach called general-purpose computing on GPUs (GPGPU). CUDA is a software layer that gives direct access to the GPU's virtual instruction set and parallel computational elements, for the execution of compute kernels.\nCUDA is designed to work with programming languages such as C, C++, and Fortran. This accessibility makes it easier for specialists in parallel programming to use GPU resources, in contrast to prior APIs like Direct3D and OpenGL, which required advanced skills in graphics programming. CUDA-powered GPUs also support programming frameworks such as OpenMP, OpenACC and OpenCL; and HIP by compiling such code to CUDA.\nCUDA was created by Nvidia. When it was first introduced, the name was an acronym for Compute Unified Device Architecture, but Nvidia later dropped the common use of the acronym.\nBackground.\nThe graphics processing unit (GPU), as a specialized computer processor, addresses the demands of real-time high-resolution 3D graphics compute-intensive tasks. By 2012, GPUs had evolved into highly parallel multi-core systems allowing efficient manipulation of large blocks of data. This design is more effective than general-purpose central processing unit (CPUs) for algorithms in situations where processing large blocks of data is done in parallel, such as:\nOntology.\nThe following table offers a non-exact description for the ontology of CUDA framework.\nProgramming abilities.\nThe CUDA platform is accessible to software developers through CUDA-accelerated libraries, compiler directives such as OpenACC, and extensions to industry-standard programming languages including C, C++ and Fortran. C/C++ programmers can use 'CUDA C/C++', compiled to PTX with nvcc, Nvidia's LLVM-based C/C++ compiler, or by clang itself. Fortran programmers can use 'CUDA Fortran', compiled with the PGI CUDA Fortran compiler from The Portland Group.\nIn addition to libraries, compiler directives, CUDA C/C++ and CUDA Fortran, the CUDA platform supports other computational interfaces, including the Khronos Group's OpenCL, Microsoft's DirectCompute, OpenGL Compute Shader and C++ AMP. Third party wrappers are also available for Python, Perl, Fortran, Java, Ruby, Lua, Common Lisp, Haskell, R, MATLAB, IDL, Julia, and native support in Mathematica.\nIn the computer game industry, GPUs are used for graphics rendering, and for game physics calculations (physical effects such as debris, smoke, fire, fluids); examples include PhysX and Bullet. CUDA has also been used to accelerate non-graphical applications in computational biology, cryptography and other fields by an order of magnitude or more.\nCUDA provides both a low level API (CUDA Driver API, non single-source) and a higher level API (CUDA Runtime API, single-source). The initial CUDA SDK was made public on 15 February 2007, for Microsoft Windows and Linux. Mac OS X support was later added in version 2.0, which supersedes the beta released February 14, 2008. CUDA works with all Nvidia GPUs from the G8x series onwards, including GeForce, Quadro and the Tesla line. CUDA is compatible with most standard operating systems.\nCUDA 8.0 comes with the following libraries (for compilation & runtime, in alphabetical order):\nCUDA 8.0 comes with these other software components:\nCUDA 9.0\u20139.2 comes with these other components:\nCUDA 10 comes with these other components:\nCUDA 11.0-11.8 comes with these other components:\nAdvantages.\nCUDA has several advantages over traditional general-purpose computation on GPUs (GPGPU) using graphics APIs:\nExample.\nThis example code in C++ loads a texture from an image into an array on the GPU:\ntexture tex;\nvoid foo()\n cudaArray* cu_array;\n // Allocate array\n cudaChannelFormatDesc description = cudaCreateChannelDesc();\n cudaMallocArray(&cu_array, &description, width, height);\n // Copy image data to array\n cudaMemcpyToArray(cu_array, image, width*height*sizeof(float), cudaMemcpyHostToDevice);\n // Set texture parameters (default)\n tex.addressMode[0] = cudaAddressModeClamp;\n tex.addressMode[1] = cudaAddressModeClamp;\n tex.filterMode = cudaFilterModePoint;\n tex.normalized = false; // do not normalize coordinates\n // Bind the array to the texture\n cudaBindTextureToArray(tex, cu_array);\n // Run kernel\n dim3 blockDim(16, 16, 1);\n dim3 gridDim((width + blockDim.x - 1)/ blockDim.x, (height + blockDim.y - 1) / blockDim.y, 1);\n kernel\u00ab< gridDim, blockDim, 0 \u00bb>(d_data, height, width);\n // Unbind the array from the texture\n cudaUnbindTexture(tex);\n} //end foo()\n__global__ void kernel(float* odata, int height, int width)\n unsigned int x = blockIdx.x*blockDim.x + threadIdx.x;\n unsigned int y = blockIdx.y*blockDim.y + threadIdx.y;\n if (x < width && y < height) {\n float c = tex2D(tex, x, y);\n odata[y*width+x] = c;\nBelow is an example given in Python that computes the product of two arrays on the GPU. The unofficial Python language bindings can be obtained from \"PyCUDA\".\nimport pycuda.compiler as comp\nimport pycuda.driver as drv\nimport numpy\nimport pycuda.autoinit\nmod = comp.SourceModule(\n__global__ void multiply_them(float *dest, float *a, float *b)\n const int i = threadIdx.x;\n dest[i] = a[i] * b[i];\n\"\"\"\nmultiply_them = mod.get_function(\"multiply_them\")\na = numpy.random.randn(400).astype(numpy.float32)\nb = numpy.random.randn(400).astype(numpy.float32)\ndest = numpy.zeros_like(a)\nmultiply_them(drv.Out(dest), drv.In(a), drv.In(b), block=(400, 1, 1))\nprint(dest - a * b)\nAdditional Python bindings to simplify matrix multiplication operations can be found in the program \"pycublas\".\nimport numpy\nfrom pycublas import CUBLASMatrix\nA = CUBLASMatrix(numpy.mat(1, 2, 3], [4, 5, 6, numpy.float32))\nB = CUBLASMatrix(numpy.mat(2, 3], [4, 5], [6, 7, numpy.float32))\nC = A * B\nprint(C.np_mat())\nwhile CuPy directly replaces NumPy:\nimport cupy\na = cupy.random.randn(400)\nb = cupy.random.randn(400)\ndest = cupy.zeros_like(a)\nprint(dest - a * b)\nGPUs supported.\nSupported CUDA Compute Capability versions for CUDA SDK version and Microarchitecture (by code name):\nNote: CUDA SDK 10.2 is the last official release for macOS, as support will not be available for macOS in newer releases.\nCUDA Compute Capability by version with associated GPU semiconductors and GPU card models (separated by their various application areas):\n'*' \u2013 OEM-only products\nVersion features and specifications.\nData types.\nNote: Any missing lines or empty entries do reflect some lack of information on that exact item.\nTensor cores.\nNote: Any missing lines or empty entries do reflect some lack of information on that exact item.\nMultiprocessor Architecture.\nFor more information read the Nvidia CUDA programming guide.", "categories": ["Category:All Wikipedia articles in need of updating", "Category:All articles with bare URLs for citations", "Category:All articles with unsourced statements", "Category:Articles with GND identifiers", "Category:Articles with J9U identifiers", "Category:Articles with LCCN identifiers", "Category:Articles with PDF format bare URLs for citations", "Category:Articles with bare URLs for citations from August 2022", "Category:Articles with bare URLs for citations from March 2022", "Category:Articles with bare URLs for citations from May 2022"]}, {"docid": 46561507, "title": "Visual Studio Code", "text": "Visual Studio Code, also commonly referred to as VS Code, is a source-code editor made by Microsoft with the Electron Framework, for Windows, Linux and macOS. Features include support for debugging, syntax highlighting, intelligent code completion, snippets, code refactoring, and embedded Git. Users can change the theme, keyboard shortcuts, preferences, and install extensions that add functionality.\nIn the Stack Overflow 2022 Developer Survey, Visual Studio Code was ranked the most popular developer environment tool among 71,010 respondents, with 74.48% reporting that they use it.\nHistory.\nVisual Studio Code was first announced on April 29, 2015, by Microsoft at the 2015 Build conference. A preview build was released shortly thereafter.\nOn November 18, 2015, the source of Visual Studio Code was released under the MIT License, and made available on GitHub. Extension support was also announced. On April 14, 2016, Visual Studio Code graduated from the public preview stage and was released to the Web. Microsoft has released most of Visual Studio Code's source code on GitHub under the permissive MIT License, while the releases by Microsoft are proprietary freeware.\nFeatures.\nVisual Studio Code is a source-code editor that can be used with a variety of programming languages, including C, C#, C++, Fortran, Go, Java, JavaScript, Node.js, Python, Rust, and Julia. It is based on the Electron framework, which is used to develop Node.js web applications that run on the Blink layout engine. Visual Studio Code employs the same editor component (codenamed \"Monaco\") used in Azure DevOps (formerly called Visual Studio Online and Visual Studio Team Services).\nOut of the box, Visual Studio Code includes basic support for most common programming languages. This basic support includes syntax highlighting, bracket matching, code folding, and configurable snippets. Visual Studio Code also ships with IntelliSense for JavaScript, TypeScript, JSON, CSS, and HTML, as well as debugging support for Node.js. Support for additional languages can be provided by freely available extensions on the VS Code Marketplace.\nInstead of a project system, it allows users to open one or more directories, which can then be saved in workspaces for future reuse. This allows it to operate as a language-agnostic code editor for any language. It supports many programming languages and a set of features that differs per language. Unwanted files and folders can be excluded from the project tree via the settings. Many Visual Studio Code features are not exposed through menus or the user interface but can be accessed via the command palette.\nVisual Studio Code can be extended via extensions, available through a central repository. This includes additions to the editor and language support. A notable feature is the ability to create extensions that add support for new languages, themes, debuggers, time travel debuggers, perform static code analysis, and add code linters using the Language Server Protocol.\nSource control is a built-in feature of Visual Studio Code. It has a dedicated tab inside of the menu bar where users can access version control settings and view changes made to the current project. To use the feature, Visual Studio Code must be linked to any supported version control system (Git, Apache Subversion, Perforce, etc.). This allows users to create repositories as well as to make push and pull requests directly from the Visual Studio Code program.\nVisual Studio Code includes multiple extensions for FTP, allowing the software to be used as a free alternative for web development. Code can be synced between the editor and the server, without downloading any extra software.\nVisual Studio Code allows users to set the code page in which the active document is saved, the newline character, and the programming language of the active document. This allows it to be used on any platform, in any locale, and for any given programming language.\nVisual Studio Code collects usage data and sends it to Microsoft, although this can be disabled. Due to the open-source nature of the application, the telemetry code is accessible to the public, who can see exactly what is collected.\nReception.\nIn the 2016 Developers Survey of Stack Overflow, Visual Studio Code ranked No. 13 among the top popular development tools, with only 7% of the 47,000 respondents using it. Two years later, however, Visual Studio Code achieved the No. 1 spot, with 35% of the 75,000 respondents using it. In the 2019 Developers Survey, Visual Studio Code was also ranked No. 1, with 50% of the 87,000 respondents using it. In the 2021 Developers Survey, Visual Studio Code continued to be ranked No. 1, with 74.5% of the 71,000 respondents using it, and 74.48% of the 71,010 responses in the 2022 survey.\nExternal links.\nVSCodium.\nVSCodium is a community-driven, freely-licensed binary distribution of Microsoft's editor VS Code.", "categories": ["Category:2015 software", "Category:All articles with a promotional tone", "Category:Articles with a promotional tone from November 2022", "Category:Articles with short description", "Category:HTML editors", "Category:Java development tools", "Category:Linux text editors", "Category:MacOS text editors", "Category:Microsoft Visual Studio", "Category:Microsoft free software"]}, {"docid": 324378, "title": "C standard library", "text": "The C standard library or libc is the standard library for the C programming language, as specified in the ISO C standard. Starting from the original ANSI C standard, it was developed at the same time as the C library POSIX specification, which is a superset of it. Since ANSI C was adopted by the International Organization for Standardization, the C standard library is also called the ISO C library.\nThe C standard library provides macros, type definitions and functions for tasks such as string handling, mathematical computations, input/output processing, memory management, and several other operating system services.\nApplication programming interface (API).\nHeader files.\nThe application programming interface (API) of the C standard library is declared in a number of header files. Each header file contains one or more function declarations, data type definitions, and macros.\nAfter a long period of stability, three new header files (codice_1, codice_2, and codice_3) were added with \"Normative Addendum 1\" (NA1), an addition to the C Standard ratified in 1995. Six more header files (codice_4, codice_5, codice_6, codice_7, codice_8, and codice_9) were added with C99, a revision to the C Standard published in 1999, and five more files (codice_10, codice_11, codice_12, codice_13, and codice_14) with C11 in 2011. In total, there are now 29 header files:\nThree of the header files (codice_4, codice_11, and codice_13) are conditional features that implementations are not required to support.\nThe POSIX standard added several nonstandard C headers for Unix-specific functionality. Many have found their way to other architectures. Examples include codice_18 and codice_19. A number of other groups are using other nonstandard headers \u2013 the GNU C Library has codice_20, and HP OpenVMS has the codice_21 function.\nDocumentation.\nOn Unix-like systems, the authoritative documentation of the actually implemented API is provided in the form of man pages. On most systems, man pages on standard library functions are in section\u00a03; section\u00a07 may contain some more generic pages on underlying concepts (e.g. codice_22 in Linux).\nImplementations.\nUnix-like systems typically have a C library in shared library form, but the header files (and compiler toolchain) may be absent from an installation so C development may not be possible. The C library is considered part of the operating system on Unix-like systems. The C functions, including the ISO C standard ones, are widely used by programs, and are regarded as if they were not only an implementation of something in the C language, but also \"de facto\" part of the operating system interface. Unix-like operating systems generally cannot function if the C library is erased. This is true for applications which are dynamically as opposed to statically linked. Further, the kernel itself (at least in the case of Linux) operates independently of any libraries. \nOn Microsoft Windows, the core system dynamic libraries (DLLs) provide an implementation of the C standard library for the Microsoft Visual\u00a0C++ compiler v6.0; the C standard library for newer versions of the Microsoft Visual\u00a0C++ compiler is provided by each compiler individually, as well as \"redistributable\" packages. Compiled applications written in C are either statically linked with a C library, or linked to a dynamic version of the library that is shipped with these applications, rather than relied upon to be present on the targeted systems. Functions in a compiler's C library are not regarded as interfaces to Microsoft Windows.\nMany other implementations exist, provided with both various operating systems and C compilers. Some of the popular implementations are the following:\nCompiler built-in functions.\nSome compilers (for example, GCC) provide built-in versions of many of the functions in the C standard library; that is, the implementations of the functions are written into the compiled object file, and the program calls the built-in versions instead of the functions in the C library shared object file. This reduces function-call overhead, especially if function calls are replaced with inline variants, and allows other forms of optimization (as the compiler knows the control-flow characteristics of the built-in variants), but may cause confusion when debugging (for example, the built-in versions cannot be replaced with instrumented variants).\nHowever, the built-in functions must behave like ordinary functions in accordance with ISO C. The main implication is that the program must be able to create a pointer to these functions by taking their address, and invoke the function by means of that pointer. If two pointers to the same function are derived in two different translation units in the program, these two pointers must compare equal; that is, the address comes by resolving the name of the function, which has external (program-wide) linkage.\nLinking, libm.\nUnder FreeBSD and glibc, some functions such as sin() are not linked in by default and are instead bundled in the mathematical library libm. If any of them are used, the linker must be given the directive codice_23. POSIX requires that the c99 compiler supports codice_23, and that the functions declared in the headers codice_25, codice_4, and codice_5 are available for linking if codice_23 is specified, but does not specify if the functions are linked by default. musl satisfies this requirement by putting everything into a single libc library and providing an empty libm.\nDetection.\nAccording to the C standard the macro codice_29 shall be defined to 1 if the implementation is hosted. A hosted implementation has all the headers specified by the C standard. An implementation can also be \"freestanding\" which means that these headers will not be present. If an implementation is \"freestanding\", it shall define codice_29 to 0.\nProblems and workarounds.\nBuffer overflow vulnerabilities.\nSome functions in the C standard library have been notorious for having buffer overflow vulnerabilities and generally encouraging buggy programming ever since their adoption. The most criticized items are:\nExcept the extreme case with codice_34, all the security vulnerabilities can be avoided by introducing auxiliary code to perform memory management, bounds checking, input checking, etc. This is often done in the form of wrappers that make standard library functions safer and easier to use. This dates back to as early as \"The Practice of Programming\" book by B. Kernighan and R. Pike where the authors commonly use wrappers that print error messages and quit the program if an error occurs.\nThe ISO C committee published Technical reports TR 24731-1 and is working on TR 24731-2 to propose adoption of some functions with bounds checking and automatic buffer allocation, correspondingly. The former has met severe criticism with some praise, the latter received mixed responses. Despite this, TR 24731-1 has been implemented into Microsoft's C standard library and its compiler issues warnings when using old \"insecure\" functions.\nThreading problems, vulnerability to race conditions.\nThe codice_37 routine is criticized for being thread unsafe and otherwise vulnerable to race conditions.\nError handling.\nThe error handling of the functions in the C standard library is not consistent and sometimes confusing. According to the Linux manual page codice_38, \"The current (version 2.8) situation under glibc is messy. Most (but not all) functions raise exceptions on errors. Some also set \"errno\". A few functions set \"errno\", but don't raise an exception. A very few functions do neither.\"\nStandardization.\nThe original C language provided no built-in functions such as I/O operations, unlike traditional languages such as COBOL and Fortran. Over time, user communities of C shared ideas and implementations of what is now called C standard libraries. Many of these ideas were incorporated eventually into the definition of the standardized C language.\nBoth Unix and C were created at AT&T's Bell Laboratories in the late 1960s and early 1970s. During the 1970s the C language became increasingly popular. Many universities and organizations began creating their own variants of the language for their own projects. By the beginning of the 1980s compatibility problems between the various C implementations became apparent. In 1983 the American National Standards Institute (ANSI) formed a committee to establish a standard specification of C known as \"ANSI C\". This work culminated in the creation of the so-called C89 standard in 1989. Part of the resulting standard was a set of software libraries called the ANSI C standard library.\nPOSIX standard library.\nPOSIX, as well as SUS, specify a number of routines that should be available over and above those in the basic C standard library. The POSIX specification includes header files for, among other uses, multi-threading, networking, and regular expressions. These are often implemented alongside the C standard library functionality, with varying degrees of closeness. For example, glibc implements functions such as codice_39 within codice_40, but before NPTL was merged into glibc it constituted a separate library with its own linker flag argument. Often, this POSIX-specified functionality will be regarded as part of the library; the basic C library may be identified as the ANSI or ISO C library.\nBSD libc.\nBSD libc is a superset of the POSIX standard library supported by the C libraries included with BSD operating systems such as FreeBSD, NetBSD, OpenBSD and macOS. BSD libc has some extensions that are not defined in the original standard, many of which first appeared in 1994's 4.4BSD release (the first to be largely developed after the first standard was issued in 1989). Some of the extensions of BSD libc are:\nThe C standard library in other languages.\nSome languages include the functionality of the standard C library in their own libraries. The library may be adapted to better suit the language's structure, but the operational semantics are kept similar. The C++ language, for example, includes the functionality of the C standard library in the namespace codice_54 (e.g., codice_55, codice_56, codice_57), in header files with similar names to the C ones (codice_58, codice_59, codice_60, etc.). Other languages that take similar approaches are D, Perl, Ruby and the main implementation of Python known as CPython. In Python 2, for example, the built-in file objects are defined as \"implemented using C's codice_61 package\", so that the available operations (open, read, write, etc.) are expected to have the same behavior as the corresponding C functions. Rust has a crate called which allows several C functions, structs, and other type definitions to be used.\nComparison to standard libraries of other languages.\nThe C standard library is small compared to the standard libraries of some other languages. The C library provides a basic set of mathematical functions, string manipulation, type conversions, and file and console-based I/O. It does not include a standard set of \"container types\" like the C++ Standard Template Library, let alone the complete graphical user interface (GUI) toolkits, networking tools, and profusion of other functionality that Java and the .NET Framework provide as standard. The main advantage of the small standard library is that providing a working ISO C environment is much easier than it is with other languages, and consequently porting C to a new platform is comparatively easy.", "categories": ["Category:All articles with unsourced statements", "Category:Articles with short description", "Category:Articles with unsourced statements from November 2010", "Category:CS1 maint: url-status", "Category:C (programming language)", "Category:C standard library", "Category:Short description is different from Wikidata", "Category:Webarchive template wayback links"]}, {"docid": 93817, "title": "Data type", "text": "In computer science and computer programming, a data type (or simply type) is a collection or grouping of data values, usually specified by a set of possible values, a set of allowed operations on these values, and/or a representation of these values as machine types. A data type specification in a program constrains the possible values that an expression, such as a variable or a function call, might take. On literal data, it tells the compiler or interpreter how the programmer intends to use the data. Most programming languages support basic data types of integer numbers (of varying sizes), floating-point numbers (which approximate real numbers), characters and Booleans.\nConcept.\nA data type may be specified for many reasons: similarity, convenience, or to focus the attention. It is frequently a matter of good organization\nthat aids the understanding of complex definitions. Almost all programming languages explicitly include the notion of data type, though the possible data types are often restricted by considerations of simplicity, computability, or regularity. An explicit data type declaration typically allows the compiler to choose an efficient machine representation, but the conceptual organization offered by data types should not be discounted.\nDifferent languages may use different data types or similar types with different semantics. For example, in the Python programming language, codice_1 represents an arbitrary-precision integer which has the traditional numeric operations such as addition, subtraction, and multiplication. However, in the Java programming language, the type codice_1 represents the set of 32-bit integers ranging in value from \u22122,147,483,648 to 2,147,483,647, with arithmetic operations that wrap on overflow. In Rust this 32-bit integer type is denoted codice_3 and panics on overflow in debug mode.\nMost programming languages also allow the programmer to define additional data types, usually by combining multiple elements of other types and defining the valid operations of the new data type. For example, a programmer might create a new data type named \"complex number\" that would include real and imaginary parts, or a color data type represented by three bytes denoting the amounts each of red, green, and blue, and a string representing the color's name.\nData types are used within type systems, which offer various ways of defining, implementing, and using them. In a type system, a data type represents a constraint placed upon the interpretation of data, describing representation, interpretation and structure of values or objects stored in computer memory. The type system uses data type information to check correctness of computer programs that access or manipulate the data. A compiler may use the static type of a value to optimize the storage it needs and the choice of algorithms for operations on the value. In many C compilers the data type, for example, is represented in 32 bits, in accord with the IEEE specification for single-precision floating point numbers. They will thus use floating-point-specific microprocessor operations on those values (floating-point addition, multiplication, etc.).\nMost data types in statistics have comparable types in computer programming, and vice versa, as shown in the following table:\nDefinition.\n identified five definitions of a \"type\" that were used\u2014sometimes implicitly\u2014in the literature:\nThe definition in terms of a representation was often done in imperative languages such as ALGOL and Pascal, while the definition in terms of a value space and behaviour was used in higher-level languages such as Simula and CLU. Types including behavior align more closely with object-oriented models, whereas a structured programming model would tend to not include code, and are called plain old data structures.\nClassification.\nData types may be categorized according to several factors:\nThe terminology varies - in the literature, primitive, built-in, basic, atomic, and fundamental may be used interchangeably.\nExamples.\nMachine data types.\nAll data in computers based on digital electronics is represented as bits (alternatives 0 and 1) on the lowest level. The smallest addressable unit of data is usually a group of bits called a byte (usually an octet, which is 8 bits). The unit processed by machine code instructions is called a word (, typically 32 or 64 bits).\nMachine data types \"expose\" or make available fine-grained control over hardware, but this can also expose implementation details that make code less portable. Hence machine types are mainly used in systems programming or low-level programming languages. In higher-level languages most data types are \"abstracted\" in that they do not have a language-defined machine representation. The C programming language, for instance, supplies types such as booleans, integers, floating-point numbers, etc., but the precise bit representations of these types are implementation-defined. The only C type with a precise machine representation is the codice_4 type that represents a byte.\nBoolean type.\nThe Boolean type represents the values true and false. Although only two values are possible, they are more often represented as a word rather as a single bit as it requires more machine instructions to store and retrieve an individual bit. Many programming languages do not have an explicit Boolean type, instead using an integer type and interpreting (for instance) 0 as false and other values as true.\nBoolean data refers to the logical structure of how the language is interpreted to the machine language. In this case a Boolean 0 refers to the logic False. True is always a non zero, especially a one which is known as Boolean 1.\nNumeric types.\nAlmost all programming languages supply one or more integer data types. They may either supply a small number of predefined subtypes restricted to certain ranges (such as codice_5 and codice_6 and their corresponding codice_7 variants in C/C++); or allow users to freely define subranges such as 1..12 (e.g. Pascal/Ada). If a corresponding native type does not exist on the target platform, the compiler will break them down into code using types that do exist. For instance, if a 32-bit integer is requested on a 16 bit platform, the compiler will tacitly treat it as an array of two 16 bit integers.\nFloating point data types represent certain fractional values (rational numbers, mathematically). Although they have predefined limits on both their maximum values and their precision, they are sometimes misleadingly called reals (evocative of mathematical real numbers). They are typically stored internally in the form (where and are integers), but displayed in familiar decimal form.\nFixed point data types are convenient for representing monetary values. They are often implemented internally as integers, leading to predefined limits.\nFor independence from architecture details, a Bignum or arbitrary precision codice_8 type might be supplied. This represents an integer or rational to a precision limited only by the available memory and computational resources on the system. Bignum implementations of arithmetic operations on machine-sized values are significantly slower than the corresponding machine operations.\nEnumerations.\nThe enumerated type has distinct values, which can be compared and assigned, but which do not necessarily have any particular concrete representation in the computer's memory; compilers and interpreters can represent them arbitrarily. For example, the four suits in a deck of playing cards may be four enumerators named \"CLUB\", \"DIAMOND\", \"HEART\", \"SPADE\", belonging to an enumerated type named \"suit\". If a variable \"V\" is declared having \"suit\" as its data type, one can assign any of those four values to it. Some implementations allow programmers to assign integer values to the enumeration values, or even treat them as type-equivalent to integers.\nString and text types.\nStrings are a sequence of characters used to store words or plain text, most often textual markup languages representing formatted text. Characters may be a letter of some alphabet, a digit, a blank space, a punctuation mark, etc. Characters are drawn from a character set such as ASCII. Character and string types can have different subtypes according to the character encoding. The original 7-bit wide ASCII was found to be limited, and superseded by 8, 16 and 32-bit sets, which can encode a wide variety of non-Latin alphabets (such as Hebrew and Chinese) and other symbols. Strings may be of either variable length or fixed length, and some programming languages have both types. They may also be subtyped by their maximum size.\nSince most character sets include the digits, it is possible to have a numeric string, such as codice_9. These numeric strings are usually considered distinct from numeric values such as codice_10, although some languages automatically convert between them.\nUnion types.\nA union type definition will specify which of a number of permitted subtypes may be stored in its instances, e.g. \"float or long integer\". In contrast with a record, which could be defined to contain a float \"and\" an integer, a union may only contain one subtype at a time.\nA tagged union (also called a variant, variant record, discriminated union, or disjoint union) contains an additional field indicating its current type for enhanced type safety.\nAlgebraic data types.\nAn algebraic data type (ADT) is a possibly recursive sum type of product types. A value of an ADT consists of a constructor tag together with zero or more field values, with the number and type of the field values fixed by the constructor. The set of all possible values of an ADT is the set-theoretic disjoint union (sum), of the sets of all possible values of its variants (product of fields). Values of algebraic types are analyzed with pattern matching, which identifies a value's constructor and extracts the fields it contains.\nIf there is only one constructor, then the ADT corresponds to a product type similar to a tuple or record. A constructor with no fields corresponds to the empty product (unit type). If all constructors have no fields then the ADT corresponds to an enumerated type.\nOne common ADT is the option type, defined in Haskell as .\nData structures.\nSome types are very useful for storing and retrieving data and are called data structures. Common data structures include:\nAbstract data types.\nAn abstract data type is a data type that does not specify the concrete representation of the data. Instead, a formal \"specification\" based on the data type's operations is used to describe it. Any \"implementation\" of a specification must fulfill the rules given. For example, a stack has push/pop operations that follow a Last-In-First-Out rule, and can be concretely implemented using either a list or an array. Another example is a set which stores values, without any particular order, and no repeated values. Values themselves are not retrieved from sets, rather one tests a value for membership to obtain a boolean \"in\" or \"not in\".\nAbstract data types are used in formal semantics and program verification and, less strictly, in design. Beyond verification, a specification might immediately be turned into an implementation. The OBJ family of programming languages for instance bases on this option using equations for specification and rewriting to run them. Algebraic specification was an important subject of research in CS around 1980 and almost a synonym for abstract data types at that time. It has a mathematical foundation in universal algebra. The specification language can be made more expressive by allowing other formulas than only equations.\nA more involved example is the Boom hierarchy of the binary tree, list, bag and set abstract data types. All these data types can be declared by three operations: \"null\", which constructs the empty container, \"single\", which constructs a container from a single element and \"append\", which combines two containers of the same type. The complete specification for the four data types can then be given by successively adding the following rules over these operations:\nAccess to the data can be specified by pattern-matching over the three operations, e.g. a \"member\" function for these containers by:\nCare must be taken to ensure that the function is invariant under the relevant rules for the data type. Within each of the equivalence classes implied by the chosen subset of equations, it has to yield the same result for all of its members.\nPointers and references.\nThe main non-composite, derived type is the pointer, a data type whose value refers directly to (or \"points to\") another value stored elsewhere in the computer memory using its address. It is a primitive kind of reference. (In everyday terms, a page number in a book could be considered a piece of data that refers to another one). Pointers are often stored in a format similar to an integer; however, attempting to dereference or \"look up\" a pointer whose value was never a valid memory address would cause a program to crash. To ameliorate this potential problem, pointers are considered a separate type to the type of data they point to, even if the underlying representation is the same.\nFunction types.\nFunctional programming languages treat functions as a distinct datatype and allow values of this type to be stored in variables and passed to functions. Some multi-paradigm languages such as JavaScript also have mechanisms for treating functions as data. Most contemporary type systems go beyond JavaScript's simple type \"function object\" and have a family of function types differentiated by argument and return types, such as the type codice_11 denoting functions taking an integer and returning a boolean. In C, a function is not a first-class data type but function pointers can be manipulated by the program. Java and C++ originally did not have function values but have added them in C++11 and Java 8.\nType constructors.\nA type constructor builds new types from old ones, and can be thought of as an operator taking zero or more types as arguments and producing a type. Product types, function types, power types and list types can be made into type constructors.\nQuantified types.\nUniversally-quantified and existentially-quantified types are based on predicate logic. Universal quantification is written as formula_1 or codice_12 and is the intersection over all types codice_13 of the body codice_14, i.e. the value is of type codice_14 for every codice_13. Existential quantification written as formula_2 or codice_17 and is the union over all types codice_13 of the body codice_14, i.e. the value is of type codice_14 for some codice_13.\nIn Haskell, universal quantification is commonly used, but existential types must be encoded by transforming codice_22 to codice_23 or a similar type.\nRefinement types.\nA refinement type is a type endowed with a predicate which is assumed to hold for any element of the refined type. For instance, the type of natural numbers greater than 5 may be written as formula_3\nDependent types.\nA dependent type is a type whose definition depends on a value. Two common examples of dependent types are dependent functions and dependent pairs. The return type of a dependent function may depend on the value (not just type) of one of its arguments. A dependent pair may have a second value of which the type depends on the first value.\nIntersection types.\nAn intersection type is a type containing those values that are members of two specified types. For example, in Java the class implements both the and the interfaces. Therefore, an object of type is a member of the type . Considering types as sets of values, the intersection type formula_4 is the set-theoretic intersection of formula_5 and formula_6. It is also possible to define a dependent intersection type, denoted formula_7, where the type formula_6 may depend on the term variable formula_9.\nMeta types.\nSome programming languages represent the type information as data, enabling type introspection and reflection. In contrast, higher order type systems, while allowing types to be constructed from other types and passed to functions as values, typically avoid basing computational decisions on them.\nConvenience types.\nFor convenience, high-level languages and databases may supply ready-made \"real world\" data types, for instance times, dates, and monetary values (currency). These may be built-in to the language or implemented as composite types in a library.", "categories": ["Category:All articles containing potentially dated statements", "Category:All articles needing additional references", "Category:All articles with unsourced statements", "Category:Articles containing potentially dated statements from 2011", "Category:Articles needing additional references from June 2021", "Category:Articles with GND identifiers", "Category:Articles with J9U identifiers", "Category:Articles with LCCN identifiers", "Category:Articles with LNB identifiers", "Category:Articles with NKC identifiers"]}, {"docid": 6021, "title": "C (programming language)", "text": "C (\"pronounced\" \" \u2013 like the letter c\") is a general-purpose computer programming language. It was created in the 1970s by Dennis Ritchie, and remains very widely used and influential. By design, C's features cleanly reflect the capabilities of the targeted CPUs. It has found lasting use in operating systems, device drivers, protocol stacks, though decreasingly for application software. C is commonly used on computer architectures that range from the largest supercomputers to the smallest microcontrollers and embedded systems.\nA successor to the programming language B, C was originally developed at Bell Labs by Ritchie between 1972 and 1973 to construct utilities running on Unix. It was applied to re-implementing the kernel of the Unix operating system. During the 1980s, C gradually gained popularity. It has become one of the most widely used programming languages, with C compilers available for practically all modern computer architectures and operating systems. The book \"The C Programming Language\", co-authored by the original language designer, served for many years as the \"de facto\" standard for the language.\nC has been standardized by ANSI since 1989 (ANSI C) and by the International Organization for Standardization (ISO).\nC is an imperative procedural language, supporting structured programming, lexical variable scope and recursion, with a static type system. It was designed to be compiled to provide low-level access to memory and language constructs that map efficiently to machine instructions, all with minimal runtime support. Despite its low-level capabilities, the language was designed to encourage cross-platform programming. A standards-compliant C program written with portability in mind can be compiled for a wide variety of computer platforms and operating systems with few changes to its source code.\nSince 2000, C has consistently ranked among the top two languages in the TIOBE index, a measure of the popularity of programming languages.\nOverview.\nC is an imperative, procedural language in the ALGOL tradition. It has a static type system. In C, all executable code is contained within subroutines (also called \"functions\", though not in the sense of functional programming). Function parameters are passed by value, although arrays are passed as pointers, i.e. the address of the first item in the array. \"Pass-by-reference\" is simulated in C by explicitly passing pointers to the thing being referenced.\nC program source text is free-form code. The semicolon separates statements and curly braces are used for grouping blocks of statements.\nThe C language also exhibits the following characteristics:\nWhile C does not include certain features found in other languages (such as object orientation and garbage collection), these can be implemented or emulated, often through the use of external libraries (e.g., the GLib Object System or the Boehm garbage collector).\nRelations to other languages.\nMany later languages have borrowed directly or indirectly from C, including C++, C#, Unix's C shell, D, Go, Java, JavaScript (including transpilers), Julia, Limbo, LPC, Objective-C, Perl, PHP, Python, Ruby, Rust, Swift, Verilog and SystemVerilog (hardware description languages). These languages have drawn many of their control structures and other basic features from C. Most of them (Python being a dramatic exception) also express highly similar syntax to C, and they tend to combine the recognizable expression and statement syntax of C with underlying type systems, data models, and semantics that can be radically different.\nHistory.\nEarly developments.\nThe origin of C is closely tied to the development of the Unix operating system, originally implemented in assembly language on a PDP-7 by Dennis Ritchie and Ken Thompson, incorporating several ideas from colleagues. Eventually, they decided to port the operating system to a PDP-11. The original PDP-11 version of Unix was also developed in assembly language.\nB.\nThompson wanted a programming language for developing utilities for the new platform. At first, he tried to write a Fortran compiler, but soon gave up the idea. Instead, he created a cut-down version of the recently developed BCPL systems programming language. The official description of BCPL was not available at the time and Thompson modified the syntax to be less wordy, and similar to a simplified ALGOL known as SMALGOL. Thompson called the result \"B\". He described B as \"BCPL semantics with a lot of SMALGOL syntax\". Like BCPL, B had a bootstrapping compiler to facilitate porting to new machines. However, few utilities were ultimately written in B because it was too slow, and could not take advantage of PDP-11 features such as byte addressability.\nNew B and first C release.\nIn 1971, Ritchie started to improve B, to utilise the features of the more-powerful PDP-11. A significant addition was a character data type. He called this \"New B\" (NB). Thompson started to use NB to write the Unix kernel, and his requirements shaped the direction of the language development. Through to 1972, richer types were added to the NB language: NB had arrays of codice_12 and codice_13. Pointers, the ability to generate pointers to other types, arrays of all types, and types to be returned from functions were all also added. Arrays within expressions became pointers. A new compiler was written, and the language was renamed C.\nThe C compiler and some utilities made with it were included in Version 2 Unix, which is also known as Research Unix.\nStructures and the Unix kernel re-write.\nAt Version 4 Unix, released in November 1973, the Unix kernel was extensively re-implemented in C. By this time, the C language had acquired some powerful features such as codice_6 types.\nThe preprocessor was introduced around 1973 at the urging of Alan Snyder and also in recognition of the usefulness of the file-inclusion mechanisms available in BCPL and PL/I. Its original version provided only included files and simple string replacements: codice_15 and codice_16 of parameterless macros. Soon after that, it was extended, mostly by Mike Lesk and then by John Reiser, to incorporate macros with arguments and conditional compilation.\nUnix was one of the first operating system kernels implemented in a language other than assembly. Earlier instances include the Multics system (which was written in PL/I) and Master Control Program (MCP) for the Burroughs B5000 (which was written in ALGOL) in 1961. In around 1977, Ritchie and Stephen C. Johnson made further changes to the language to facilitate portability of the Unix operating system. Johnson's Portable C Compiler served as the basis for several implementations of C on new platforms.\nK&R C.\nIn 1978, Brian Kernighan and Dennis Ritchie published the first edition of \"The C Programming Language\". This book, known to C programmers as \"K&R\", served for many years as an informal specification of the language. The version of C that it describes is commonly referred to as \"K&R C\". As this was released in 1978, it is also referred to as \"C78\". The second edition of the book covers the later ANSI C standard, described below.\n\"K&R\" introduced several language features:\nEven after the publication of the 1989 ANSI standard, for many years K&R C was still considered the \"lowest common denominator\" to which C programmers restricted themselves when maximum portability was desired, since many older compilers were still in use, and because carefully written K&R C code can be legal Standard C as well.\nIn early versions of C, only functions that return types other than codice_12 must be declared if used before the function definition; functions used without prior declaration were presumed to return type codice_12.\nFor example:\nlong some_function(); /* This is a function declaration, so the compiler can know the name and return type of this function. */\n/* int */ other_function(); /* Another function declaration. Because this is an early version of C, there is an implicit 'int' type here. A comment shows where the explicit 'int' type specifier would be required in later versions. */\n/* int */ calling_function() /* This is a function definition, including the body of the code following in the { curly brackets }. Because no return type is specified, the function implicitly returns an 'int' in this early version of C. */\n long test1;\n register /* int */ test2; /* Again, note that 'int' is not required here. The 'int' type specifier */\n /* in the comment would be required in later versions of C. */\n /* The 'register' keyword indicates to the compiler that this variable should */\n /* ideally be stored in a register as opposed to within the stack frame. */\n test1 = some_function();\n if (test1 > 1)\n test2 = 0;\n else\n test2 = other_function();\n return test2;\nThe codice_12 type specifiers which are commented out could be omitted in K&R C, but are required in later standards.\nSince K&R function declarations did not include any information about function arguments, function parameter type checks were not performed, although some compilers would issue a warning message if a local function was called with the wrong number of arguments, or if multiple calls to an external function used different numbers or types of arguments. Separate tools such as Unix's lint utility were developed that (among other things) could check for consistency of function use across multiple source files.\nIn the years following the publication of K&R C, several features were added to the language, supported by compilers from AT&T (in particular PCC) and some other vendors. These included:\nThe large number of extensions and lack of agreement on a standard library, together with the language popularity and the fact that not even the Unix compilers precisely implemented the K&R specification, led to the necessity of standardization.\nANSI C and ISO C.\nDuring the late 1970s and 1980s, versions of C were implemented for a wide variety of mainframe computers, minicomputers, and microcomputers, including the IBM PC, as its popularity began to increase significantly.\nIn 1983, the American National Standards Institute (ANSI) formed a committee, X3J11, to establish a standard specification of C. X3J11 based the C standard on the Unix implementation; however, the non-portable portion of the Unix C library was handed off to the IEEE working group 1003 to become the basis for the 1988 POSIX standard. In 1989, the C standard was ratified as ANSI X3.159-1989 \"Programming Language C\". This version of the language is often referred to as ANSI C, Standard C, or sometimes C89.\nIn 1990, the ANSI C standard (with formatting changes) was adopted by the International Organization for Standardization (ISO) as ISO/IEC 9899:1990, which is sometimes called C90. Therefore, the terms \"C89\" and \"C90\" refer to the same programming language.\nANSI, like other national standards bodies, no longer develops the C standard independently, but defers to the international C standard, maintained by the working group ISO/IEC JTC1/SC22/WG14. National adoption of an update to the international standard typically occurs within a year of ISO publication.\nOne of the aims of the C standardization process was to produce a superset of K&R C, incorporating many of the subsequently introduced unofficial features. The standards committee also included several additional features such as function prototypes (borrowed from C++), codice_9 pointers, support for international character sets and locales, and preprocessor enhancements. Although the syntax for parameter declarations was augmented to include the style used in C++, the K&R interface continued to be permitted, for compatibility with existing source code.\nC89 is supported by current C compilers, and most modern C code is based on it. Any program written only in Standard C and without any hardware-dependent assumptions will run correctly on any platform with a conforming C implementation, within its resource limits. Without such precautions, programs may compile only on a certain platform or with a particular compiler, due, for example, to the use of non-standard libraries, such as GUI libraries, or to a reliance on compiler- or platform-specific attributes such as the exact size of data types and byte endianness.\nIn cases where code must be compilable by either standard-conforming or K&R C-based compilers, the codice_37 macro can be used to split the code into Standard and K&R sections to prevent the use on a K&R C-based compiler of features available only in Standard C.\nAfter the ANSI/ISO standardization process, the C language specification remained relatively static for several years. In 1995, Normative Amendment 1 to the 1990 C standard (ISO/IEC 9899/AMD1:1995, known informally as C95) was published, to correct some details and to add more extensive support for international character sets.\nC99.\nThe C standard was further revised in the late 1990s, leading to the publication of ISO/IEC 9899:1999 in 1999, which is commonly referred to as \"C99\". It has since been amended three times by Technical Corrigenda.\nC99 introduced several new features, including inline functions, several new data types (including codice_38 and a codice_39 type to represent complex numbers), variable-length arrays and flexible array members, improved support for IEEE 754 floating point, support for variadic macros (macros of variable arity), and support for one-line comments beginning with codice_40, as in BCPL or C++. Many of these had already been implemented as extensions in several C compilers.\nC99 is for the most part backward compatible with C90, but is stricter in some ways; in particular, a declaration that lacks a type specifier no longer has codice_12 implicitly assumed. A standard macro codice_42 is defined with value codice_43 to indicate that C99 support is available. GCC, Solaris Studio, and other C compilers now support many or all of the new features of C99. The C compiler in Microsoft Visual C++, however, implements the C89 standard and those parts of C99 that are required for compatibility with C++11.\nIn addition, the C99 standard requires support for Unicode identifiers in the form of escaped characters (e.g. or ) and suggests support for raw Unicode names.\nC11.\nIn 2007, work began on another revision of the C standard, informally called \"C1X\" until its official publication of ISO/IEC 9899:2011 on 2011-12-08. The C standards committee adopted guidelines to limit the adoption of new features that had not been tested by existing implementations.\nThe C11 standard adds numerous new features to C and the library, including type generic macros, anonymous structures, improved Unicode support, atomic operations, multi-threading, and bounds-checked functions. It also makes some portions of the existing C99 library optional, and improves compatibility with C++. The standard macro codice_42 is defined as codice_45 to indicate that C11 support is available.\nC17.\nPublished in June 2018 as ISO/IEC 9899:2018, C17 is the current standard for the C programming language. It introduces no new language features, only technical corrections, and clarifications to defects in C11. The standard macro codice_42 is defined as codice_47.\nC23.\nC23 is the informal name for the next (after C17) major C language standard revision. It is expected to be published in 2024.\nEmbedded C.\nHistorically, embedded C programming requires nonstandard extensions to the C language in order to support exotic features such as fixed-point arithmetic, multiple distinct memory banks, and basic I/O operations.\nIn 2008, the C Standards Committee published a technical report extending the C language to address these issues by providing a common standard for all implementations to adhere to. It includes a number of features not available in normal C, such as fixed-point arithmetic, named address spaces, and basic I/O hardware addressing.\nSyntax.\nC has a formal grammar specified by the C standard. Line endings are generally not significant in C; however, line boundaries do have significance during the preprocessing phase. Comments may appear either between the delimiters codice_48 and codice_49, or (since C99) following codice_40 until the end of the line. Comments delimited by codice_48 and codice_49 do not nest, and these sequences of characters are not interpreted as comment delimiters if they appear inside string or character literals.\nC source files contain declarations and function definitions. Function definitions, in turn, contain declarations and statements. Declarations either define new types using keywords such as codice_6, codice_33, and codice_8, or assign types to and perhaps reserve storage for new variables, usually by writing the type followed by the variable name. Keywords such as codice_13 and codice_12 specify built-in types. Sections of code are enclosed in braces (codice_58 and codice_59, sometimes called \"curly brackets\") to limit the scope of declarations and to act as a single statement for control structures.\nAs an imperative language, C uses \"statements\" to specify actions. The most common statement is an \"expression statement\", consisting of an expression to be evaluated, followed by a semicolon; as a side effect of the evaluation, functions may be called and variables may be assigned new values. To modify the normal sequential execution of statements, C provides several control-flow statements identified by reserved keywords. Structured programming is supported by codice_60 ... [codice_61] conditional execution and by codice_62 ... codice_4, codice_4, and codice_2 iterative execution (looping). The codice_2 statement has separate initialization, testing, and reinitialization expressions, any or all of which can be omitted. codice_67 and codice_68 can be used within the loop. Break is used to leave the innermost enclosing loop statement and continue is used to skip to its reinitialisation. There is also a non-structured codice_69 statement which branches directly to the designated label within the function. codice_5 selects a codice_71 to be executed based on the value of an integer expression. Different from many other languages, control-flow will fall through to the next codice_71 unless terminated by a codice_67.\nExpressions can use a variety of built-in operators and may contain function calls. The order in which arguments to functions and operands to most operators are evaluated is unspecified. The evaluations may even be interleaved. However, all side effects (including storage to variables) will occur before the next \"sequence point\"; sequence points include the end of each expression statement, and the entry to and return from each function call. Sequence points also occur during evaluation of expressions containing certain operators (codice_74, codice_75, codice_76 and the comma operator). This permits a high degree of object code optimization by the compiler, but requires C programmers to take more care to obtain reliable results than is needed for other programming languages.\nKernighan and Ritchie say in the Introduction of \"The C Programming Language\": \"C, like any other language, has its blemishes. Some of the operators have the wrong precedence; some parts of the syntax could be better.\" The C standard did not attempt to correct many of these blemishes, because of the impact of such changes on already existing software.\nCharacter set.\nThe basic C source character set includes the following characters:\nNewline indicates the end of a text line; it need not correspond to an actual single character, although for convenience C treats it as one.\nAdditional multi-byte encoded characters may be used in string literals, but they are not entirely portable. The latest C standard (C11) allows multi-national Unicode characters to be embedded portably within C source text by using codice_84 or codice_85 encoding (where the codice_86 denotes a hexadecimal character), although this feature is not yet widely implemented.\nThe basic C execution character set contains the same characters, along with representations for alert, backspace, and carriage return. Run-time support for extended character sets has increased with each revision of the C standard.\nReserved words.\nC89 has 32 reserved words, also known as keywords, which are the words that cannot be used for any purposes other than those for which they are predefined:\nC99 reserved five more words:\nC11 reserved seven more words:\nMost of the recently reserved words begin with an underscore followed by a capital letter, because identifiers of that form were previously reserved by the C standard for use only by implementations. Since existing program source code should not have been using these identifiers, it would not be affected when C implementations started supporting these extensions to the programming language. Some standard headers do define more convenient synonyms for underscored identifiers. The language previously included a reserved word called codice_131, but this was seldom implemented, and has now been removed as a reserved word.\nOperators.\nC supports a rich set of operators, which are symbols used within an expression to specify the manipulations to be performed while evaluating that expression. C has operators for:\nC uses the operator codice_137 (used in mathematics to express equality) to indicate assignment, following the precedent of Fortran and PL/I, but unlike ALGOL and its derivatives. C uses the operator codice_147 to test for equality. The similarity between these two operators (assignment and equality) may result in the accidental use of one in place of the other, and in many cases, the mistake does not produce an error message (although some compilers produce warnings). For example, the conditional expression codice_167 might mistakenly be written as codice_168, which will be evaluated as true if codice_77 is not zero after the assignment.\nThe C operator precedence is not always intuitive. For example, the operator codice_147 binds more tightly than (is executed prior to) the operators codice_139 (bitwise AND) and codice_140 (bitwise OR) in expressions such as codice_173, which must be written as codice_174 if that is the coder's intent.\n\"Hello, world\" example.\nThe \"hello, world\" example, which appeared in the first edition of \"K&R\", has become the model for an introductory program in most programming textbooks. The program prints \"hello, world\" to the standard output, which is usually a terminal or screen display.\nThe original version was:\nmain()\n printf(\"hello, world\\n\");\nA standard-conforming \"hello, world\" program is:\nint main(void)\n printf(\"hello, world\\n\");\nThe first line of the program contains a preprocessing directive, indicated by codice_15. This causes the compiler to replace that line with the entire text of the codice_176 standard header, which contains declarations for standard input and output functions such as codice_177 and codice_178. The angle brackets surrounding codice_176 indicate that codice_176 can be located using a search strategy that prefers headers provided with the compiler to other headers having the same name, as opposed to double quotes which typically include local or project-specific header files.\nThe next line indicates that a function named codice_181 is being defined. The codice_181 function serves a special purpose in C programs; the run-time environment calls the codice_181 function to begin program execution. The type specifier codice_12 indicates that the value that is returned to the invoker (in this case the run-time environment) as a result of evaluating the codice_181 function, is an integer. The keyword codice_9 as a parameter list indicates that this function takes no arguments.\nThe opening curly brace indicates the beginning of the definition of the codice_181 function.\nThe next line \"calls\" (diverts execution to) a function named codice_177, which in this case is supplied from a system library. In this call, the codice_177 function is \"passed\" (provided with) a single argument, the address of the first character in the string literal codice_190. The string literal is an unnamed array with elements of type codice_13, set up automatically by the compiler with a final 0-valued character to mark the end of the array (codice_177 needs to know this). The codice_193 is an \"escape sequence\" that C translates to a \"newline\" character, which on output signifies the end of the current line. The return value of the codice_177 function is of type codice_12, but it is silently discarded since it is not used. (A more careful program might test the return value to determine whether or not the codice_177 function succeeded.) The semicolon codice_197 terminates the statement.\nThe closing curly brace indicates the end of the code for the codice_181 function. According to the C99 specification and newer, the codice_181 function, unlike any other function, will implicitly return a value of codice_81 upon reaching the codice_59 that terminates the function. (Formerly an explicit codice_202 statement was required.) This is interpreted by the run-time system as an exit code indicating successful execution.\nData types.\nThe type system in C is static and weakly typed, which makes it similar to the type system of ALGOL descendants such as Pascal. There are built-in types for integers of various sizes, both signed and unsigned, floating-point numbers, and enumerated types (codice_8). Integer type codice_13 is often used for single-byte characters. C99 added a boolean datatype. There are also derived types including arrays, pointers, records (codice_6), and unions (codice_33).\nC is often used in low-level systems programming where escapes from the type system may be necessary. The compiler attempts to ensure type correctness of most expressions, but the programmer can override the checks in various ways, either by using a \"type cast\" to explicitly convert a value from one type to another, or by using pointers or unions to reinterpret the underlying bits of a data object in some other way.\nSome find C's declaration syntax unintuitive, particularly for function pointers. (Ritchie's idea was to declare identifiers in contexts resembling their use: \"declaration reflects use\".)\nC's \"usual arithmetic conversions\" allow for efficient code to be generated, but can sometimes produce unexpected results. For example, a comparison of signed and unsigned integers of equal width requires a conversion of the signed value to unsigned. This can generate unexpected results if the signed value is negative.\nPointers.\nC supports the use of pointers, a type of reference that records the address or location of an object or function in memory. Pointers can be \"dereferenced\" to access data stored at the address pointed to, or to invoke a pointed-to function. Pointers can be manipulated using assignment or pointer arithmetic. The run-time representation of a pointer value is typically a raw memory address (perhaps augmented by an offset-within-word field), but since a pointer's type includes the type of the thing pointed to, expressions including pointers can be type-checked at compile time. Pointer arithmetic is automatically scaled by the size of the pointed-to data type.\nPointers are used for many purposes in C. Text strings are commonly manipulated using pointers into arrays of characters. Dynamic memory allocation is performed using pointers; the result of a codice_207 is usually cast to the data type of the data to be stored. Many data types, such as trees, are commonly implemented as dynamically allocated codice_6 objects linked together using pointers. Pointers to other pointers are often used in multi-dimensional arrays and arrays of codice_6 objects. Pointers to functions (\"function pointers\") are useful for passing functions as arguments to higher-order functions (such as qsort or bsearch), in dispatch tables, or as callbacks to event handlers .\nA \"null pointer value\" explicitly points to no valid location. Dereferencing a null pointer value is undefined, often resulting in a segmentation fault. Null pointer values are useful for indicating special cases such as no \"next\" pointer in the final node of a linked list, or as an error indication from functions returning pointers. In appropriate contexts in source code, such as for assigning to a pointer variable, a \"null pointer constant\" can be written as codice_81, with or without explicit casting to a pointer type, or as the codice_211 macro defined by several standard headers. In conditional contexts, null pointer values evaluate to false, while all other pointer values evaluate to true.\nVoid pointers (codice_212) point to objects of unspecified type, and can therefore be used as \"generic\" data pointers. Since the size and type of the pointed-to object is not known, void pointers cannot be dereferenced, nor is pointer arithmetic on them allowed, although they can easily be (and in many contexts implicitly are) converted to and from any other object pointer type.\nCareless use of pointers is potentially dangerous. Because they are typically unchecked, a pointer variable can be made to point to any arbitrary location, which can cause undesirable effects. Although properly used pointers point to safe places, they can be made to point to unsafe places by using invalid pointer arithmetic; the objects they point to may continue to be used after deallocation (dangling pointers); they may be used without having been initialized (wild pointers); or they may be directly assigned an unsafe value using a cast, union, or through another corrupt pointer. In general, C is permissive in allowing manipulation of and conversion between pointer types, although compilers typically provide options for various levels of checking. Some other programming languages address these problems by using more restrictive reference types.\nArrays.\nArray types in C are traditionally of a fixed, static size specified at compile time. The more recent C99 standard also allows a form of variable-length arrays. However, it is also possible to allocate a block of memory (of arbitrary size) at run-time, using the standard library's codice_207 function, and treat it as an array.\nSince arrays are always accessed (in effect) via pointers, array accesses are typically \"not\" checked against the underlying array size, although some compilers may provide bounds checking as an option. Array bounds violations are therefore possible and can lead to various repercussions, including illegal memory accesses, corruption of data, buffer overruns, and run-time exceptions.\nC does not have a special provision for declaring multi-dimensional arrays, but rather relies on recursion within the type system to declare arrays of arrays, which effectively accomplishes the same thing. The index values of the resulting \"multi-dimensional array\" can be thought of as increasing in row-major order. Multi-dimensional arrays are commonly used in numerical algorithms (mainly from applied linear algebra) to store matrices. The structure of the C array is well suited to this particular task. However, in early versions of C the bounds of the array must be known fixed values or else explicitly passed to any subroutine that requires them, and dynamically sized arrays of arrays cannot be accessed using double indexing. (A workaround for this was to allocate the array with an additional \"row vector\" of pointers to the columns.) C99 introduced \"variable-length arrays\" which address this issue.\nThe following example using modern C (C99 or later) shows allocation of a two-dimensional array on the heap and the use of multi-dimensional array indexing for accesses (which can use bounds-checking on many C compilers):\nint func(int N, int M)\n float (*p)[N][M] = malloc(sizeof *p);\n if (!p)\n return -1;\n for (int i = 0; i < N; i++)\n for (int j = 0; j < M; j++)\n (*p)[i][j] = i + j;\n print_array(N, M, p);\n free(p);\n return 1;\nAnd here is a similar implementation using C99's \"Auto VLA\" feature:\nint func(int N, int M)\n // Caution: checks should be made to ensure N*M*sizeof(float) does NOT exceed limitations for auto VLAs and is within available size of stack.\n float p[N][M]; // auto VLA is held on the stack, and sized when the function is invoked\n for (int i = 0; i < N; i++)\n for (int j = 0; j < M; j++)\n p[i][j] = i + j;\n // no need to free(p) since it will disappear when the function exits, along with the rest of the stack frame\n return 1;\nArray\u2013pointer interchangeability.\nThe subscript notation codice_214 (where codice_215 designates a pointer) is syntactic sugar for codice_216. Taking advantage of the compiler's knowledge of the pointer type, the address that codice_217 points to is not the base address (pointed to by codice_215) incremented by codice_25 bytes, but rather is defined to be the base address incremented by codice_25 multiplied by the size of an element that codice_215 points to. Thus, codice_214 designates the codice_223th element of the array.\nFurthermore, in most expression contexts (a notable exception is as operand of codice_109), an expression of array type is automatically converted to a pointer to the array's first element. This implies that an array is never copied as a whole when named as an argument to a function, but rather only the address of its first element is passed. Therefore, although function calls in C use pass-by-value semantics, arrays are in effect passed by reference.\nThe total size of an array codice_215 can be determined by applying codice_109 to an expression of array type. The size of an element can be determined by applying the operator codice_109 to any dereferenced element of an array codice_79, as in codice_229. Thus, the number of elements in a declared array codice_79 can be determined as codice_231. Note, that if only a pointer to the first element is available as it is often the case in C code because of the automatic conversion described above, the information about the full type of the array and its length are lost.\nMemory management.\nOne of the most important functions of a programming language is to provide facilities for managing memory and the objects that are stored in memory. C provides three principal ways to allocate memory for objects:\nThese three approaches are appropriate in different situations and have various trade-offs. For example, static memory allocation has little allocation overhead, automatic allocation may involve slightly more overhead, and dynamic memory allocation can potentially have a great deal of overhead for both allocation and deallocation. The persistent nature of static objects is useful for maintaining state information across function calls, automatic allocation is easy to use but stack space is typically much more limited and transient than either static memory or heap space, and dynamic memory allocation allows convenient allocation of objects whose size is known only at run-time. Most C programs make extensive use of all three.\nWhere possible, automatic or static allocation is usually simplest because the storage is managed by the compiler, freeing the programmer of the potentially error-prone chore of manually allocating and releasing storage. However, many data structures can change in size at runtime, and since static allocations (and automatic allocations before C99) must have a fixed size at compile-time, there are many situations in which dynamic allocation is necessary. Prior to the C99 standard, variable-sized arrays were a common example of this. (See the article on codice_207 for an example of dynamically allocated arrays.) Unlike automatic allocation, which can fail at run time with uncontrolled consequences, the dynamic allocation functions return an indication (in the form of a null pointer value) when the required storage cannot be allocated. (Static allocation that is too large is usually detected by the linker or loader, before the program can even begin execution.)\nUnless otherwise specified, static objects contain zero or null pointer values upon program startup. Automatically and dynamically allocated objects are initialized only if an initial value is explicitly specified; otherwise they initially have indeterminate values (typically, whatever bit pattern happens to be present in the storage, which might not even represent a valid value for that type). If the program attempts to access an uninitialized value, the results are undefined. Many modern compilers try to detect and warn about this problem, but both false positives and false negatives can occur.\nHeap memory allocation has to be synchronized with its actual usage in any program to be reused as much as possible. For example, if the only pointer to a heap memory allocation goes out of scope or has its value overwritten before it is deallocated explicitly, then that memory cannot be recovered for later reuse and is essentially lost to the program, a phenomenon known as a \"memory leak.\" Conversely, it is possible for memory to be freed, but is referenced subsequently, leading to unpredictable results. Typically, the failure symptoms appear in a portion of the program unrelated to the code that causes the error, making it difficult to diagnose the failure. Such issues are ameliorated in languages with automatic garbage collection.\nLibraries.\nThe C programming language uses libraries as its primary method of extension. In C, a library is a set of functions contained within a single \"archive\" file. Each library typically has a header file, which contains the prototypes of the functions contained within the library that may be used by a program, and declarations of special data types and macro symbols used with these functions. In order for a program to use a library, it must include the library's header file, and the library must be linked with the program, which in many cases requires compiler flags (e.g., codice_236, shorthand for \"link the math library\").\nThe most common C library is the C standard library, which is specified by the ISO and ANSI C standards and comes with every C implementation (implementations which target limited environments such as embedded systems may provide only a subset of the standard library). This library supports stream input and output, memory allocation, mathematics, character strings, and time values. Several separate standard headers (for example, codice_176) specify the interfaces for these and other standard library facilities.\nAnother common set of C library functions are those used by applications specifically targeted for Unix and Unix-like systems, especially functions which provide an interface to the kernel. These functions are detailed in various standards such as POSIX and the Single UNIX Specification.\nSince many programs have been written in C, there are a wide variety of other libraries available. Libraries are often written in C because C compilers generate efficient object code; programmers then create interfaces to the library so that the routines can be used from higher-level languages like Java, Perl, and Python.\nFile handling and streams.\nFile input and output (I/O) is not part of the C language itself but instead is handled by libraries (such as the C standard library) and their associated header files (e.g. codice_176). File handling is generally implemented through high-level I/O which works through streams. A stream is from this perspective a data flow that is independent of devices, while a file is a concrete device. The high-level I/O is done through the association of a stream to a file. In the C standard library, a buffer (a memory area or queue) is temporarily used to store data before it is sent to the final destination. This reduces the time spent waiting for slower devices, for example a hard drive or solid state drive. Low-level I/O functions are not part of the standard C library but are generally part of \"bare metal\" programming (programming that's independent of any operating system such as most embedded programming). With few exceptions, implementations include low-level I/O.\nLanguage tools.\nA number of tools have been developed to help C programmers find and fix statements with undefined behavior or possibly erroneous expressions, with greater rigor than that provided by the compiler. The tool lint was the first such, leading to many others.\nAutomated source code checking and auditing are beneficial in any language, and for C many such tools exist, such as Lint. A common practice is to use Lint to detect questionable code when a program is first written. Once a program passes Lint, it is then compiled using the C compiler. Also, many compilers can optionally warn about syntactically valid constructs that are likely to actually be errors. MISRA C is a proprietary set of guidelines to avoid such questionable code, developed for embedded systems.\nThere are also compilers, libraries, and operating system level mechanisms for performing actions that are not a standard part of C, such as bounds checking for arrays, detection of buffer overflow, serialization, dynamic memory tracking, and automatic garbage collection.\nTools such as Purify or Valgrind and linking with libraries containing special versions of the memory allocation functions can help uncover runtime errors in memory usage.\nUses.\nRationale for use in systems programming.\nC is widely used for systems programming in implementing operating systems and embedded system applications. This is for several reasons:\nOnce used for web development.\nHistorically, C was sometimes used for web development using the Common Gateway Interface (CGI) as a \"gateway\" for information between the web application, the server, and the browser. C may have been chosen over interpreted languages because of its speed, stability, and near-universal availability. It is no longer common practice for web development to be done in C, and many other web development tools exist.\nSome other languages are themselves written in C.\nA consequence of C's wide availability and efficiency is that compilers, libraries and interpreters of other programming languages are often implemented in C. For example, the reference implementations of Python, Perl, Ruby, and PHP are written in C.\nUsed for computationally-intensive libraries.\nC enables programmers to create efficient implementations of algorithms and data structures, because the layer of abstraction from hardware is thin, and its overhead is low, an important criterion for computationally intensive programs. For example, the GNU Multiple Precision Arithmetic Library, the GNU Scientific Library, Mathematica, and MATLAB are completely or partially written in C. Many languages support calling library functions in C, for example, the Python-based framework NumPy uses C for the high-performance and hardware-interacting aspects.\nC as an intermediate language.\nC is sometimes used as an intermediate language by implementations of other languages. This approach may be used for portability or convenience; by using C as an intermediate language, additional machine-specific code generators are not necessary. C has some features, such as line-number preprocessor directives and optional superfluous commas at the end of initializer lists, that support compilation of generated code. However, some of C's shortcomings have prompted the development of other C-based languages specifically designed for use as intermediate languages, such as C--. Also, contemporary major compilers GCC and LLVM both feature an intermediate representation that is not C, and those compilers support front ends for many languages including C.\nEnd-user applications.\nC has also been widely used to implement end-user applications. However, such applications can also be written in newer, higher-level languages.\nLimitations.\nWhile C has been popular, influential and hugely successful, it has drawbacks, including:\nFor some purposes, restricted styles of C have been adopted, e.g. MISRA C or CERT C, in an attempt to reduce the opportunity for bugs. Databases such as CWE attempt to count the ways C etc. has vulnerabilities, along with recommendations for mitigation.\nThere are tools that can mitigate against some of the drawbacks. Contemporary C compilers include checks which may generate warnings to help identify many potential bugs.\nSome of these drawbacks have prompted the construction of other languages.\nRelated languages.\nC has both directly and indirectly influenced many later languages such as C++ and Java. The most pervasive influence has been syntactical; all of the languages mentioned combine the statement and (more or less recognizably) expression syntax of C with type systems, data models or large-scale program structures that differ from those of C, sometimes radically.\nSeveral C or near-C interpreters exist, including Ch and CINT, which can also be used for scripting.\nWhen object-oriented programming languages became popular, C++ and Objective-C were two different extensions of C that provided object-oriented capabilities. Both languages were originally implemented as source-to-source compilers; source code was translated into C, and then compiled with a C compiler.\nThe C++ programming language (originally named \"C with Classes\") was devised by Bjarne Stroustrup as an approach to providing object-oriented functionality with a C-like syntax. C++ adds greater typing strength, scoping, and other tools useful in object-oriented programming, and permits generic programming via templates. Nearly a superset of C, C++ now supports most of C, with a few exceptions.\nObjective-C was originally a very \"thin\" layer on top of C, and remains a strict superset of C that permits object-oriented programming using a hybrid dynamic/static typing paradigm. Objective-C derives its syntax from both C and Smalltalk: syntax that involves preprocessing, expressions, function declarations, and function calls is inherited from C, while the syntax for object-oriented features was originally taken from Smalltalk.\nIn addition to C++ and Objective-C, Ch, Cilk, and Unified Parallel C are nearly supersets of C.", "categories": ["Category:All Wikipedia articles in need of updating", "Category:All articles needing additional references", "Category:All articles with unsourced statements", "Category:All articles with vague or ambiguous time", "Category:American inventions", "Category:Articles needing additional references from July 2014", "Category:Articles needing additional references from October 2012", "Category:Articles with BNF identifiers", "Category:Articles with BNFdata identifiers", "Category:Articles with FAST identifiers"]}, {"docid": 7392, "title": "Class (computer programming)", "text": "In object-oriented programming, a class is an extensible program-code-template for creating objects, providing initial values for state (member variables) and implementations of behavior (member functions or methods). In many languages, the class name is used as the name for the class (the template itself), the name for the default constructor of the class (a subroutine that creates objects), and as the type of objects generated by instantiating the class; these distinct concepts are easily conflated. Although, to the point of conflation, one could argue that is a feature inherent in a language because of its polymorphic nature and why these languages are so powerful, dynamic and adaptable for use compared to languages without polymorphism present. Thus they can model dynamic systems (i.e. the real world, machine learning, AI) more easily.\nWhen an object is created by a constructor of the class, the resulting object is called an instance of the class, and the member variables specific to the object are called instance variables, to contrast with the class variables shared across the class.\nIn certain languages, classes are, as a matter of fact, only a compile-time feature (new classes cannot be declared at run-time), while in other languages classes are first-class citizens, and are generally themselves objects (typically of type or similar). In these languages, a class that creates classes within itself is called a metaclass.\nClass vs. type.\nIn its most casual usage, people often refer to the \"class\" of an object, but narrowly speaking objects have \"type\": the interface, namely the types of member variables, the signatures of member functions (methods), and properties these satisfy. At the same time, a class has an implementation (specifically the implementation of the methods), and can create objects of a given type, with a given implementation. In the terms of type theory, a class is an implementationa \"concrete\" data structure and collection of subroutineswhile a type is an interface. Different (concrete) classes can produce objects of the same (abstract) type (depending on type system); for example, the type might be implemented with two classes (fast for small stacks, but scales poorly) and (scales well but high overhead for small stacks). Similarly, a given class may have several different constructors.\nClass types generally represent nouns, such as a person, place or thing, or something nominalized, and a class represents an implementation of these. For example, a type might represent the properties and functionality of bananas in general, while the and classes would represent ways of producing bananas (say, banana suppliers or data structures and functions to represent and draw bananas in a video game). The class could then produce particular bananas: instances of the class would be objects of type . Often only a single implementation of a type is given, in which case the class name is often identical with the type name.\nDesign and implementation.\nClasses are composed from structural and behavioral constituents. Programming languages that include classes as a programming construct offer support, for various class-related features, and the syntax required to use these features varies greatly from one programming language to another.\nStructure.\nA class contains data field descriptions (or \"properties\", \"fields\", \"data members\", or \"attributes\"). These are usually field types and names that will be associated with state variables at program run time; these state variables either belong to the class or specific instances of the class. In most languages, the structure defined by the class determines the layout of the memory used by its instances. Other implementations are possible: for example, objects in Python use associative key-value containers.\nSome programming languages such as Eiffel support specification of invariants as part of the definition of the class, and enforce them through the type system. Encapsulation of state is necessary for being able to enforce the invariants of the class.\nBehavior.\nThe behavior of class or its instances is defined using methods. Methods are subroutines with the ability to operate on objects or classes. These operations may alter the state of an object or simply provide ways of accessing it. Many kinds of methods exist, but support for them varies across languages. Some types of methods are created and called by programmer code, while other special methods\u2014such as constructors, destructors, and conversion operators\u2014are created and called by compiler-generated code. A language may also allow the programmer to define and call these special methods.\nThe concept of class interface.\nEvery class \"implements\" (or \"realizes\") an interface by providing structure and behavior. Structure consists of data and state, and behavior consists of code that specifies how methods are implemented. There is a distinction between the definition of an interface and the implementation of that interface; however, this line is blurred in many programming languages because class declarations both define and implement an interface. Some languages, however, provide features that separate interface and implementation. For example, an abstract class can define an interface without providing implementation.\nLanguages that support class inheritance also allow classes to inherit interfaces from the classes that they are derived from.\nFor example, if \"class A\" inherits from \"class B\" and if \"class B\" implements the interface \"interface B\" then \"class A\" also inherits the functionality(constants and methods declaration) provided by \"interface B\".\nIn languages that support access specifiers, the interface of a class is considered to be the set of public members of the class, including both methods and attributes (via implicit getter and setter methods); any private members or internal data structures are not intended to be depended on by external code and thus are not part of the interface.\nObject-oriented programming methodology dictates that the operations of any interface of a class are to be independent of each other. It results in a layered design where clients of an interface use the methods declared in the interface. An interface places no requirements for clients to invoke the operations of one interface in any particular order. This approach has the benefit that client code can assume that the operations of an interface are available for use whenever the client has access to the object. \nExample.\nThe buttons on the front of your television set are the interface between you and the electrical wiring on the other side of its plastic casing. You press the \"power\" button to toggle the television on and off. In this example, your particular television is the instance, each method is represented by a button, and all the buttons together compose the interface (other television sets that are the same model as yours would have the same interface). In its most common form, an interface is a specification of a group of related methods without any associated implementation of the methods.\nA television set also has a myriad of \"attributes\", such as size and whether it supports colour, which together comprise its structure. A class represents the full description of a television, including its attributes (structure) and buttons (interface).\nGetting the total number of televisions manufactured could be a \"static method\" of the television class. This method is clearly associated with the class, yet is outside the domain of each individual instance of the class. A static method that finds a particular instance out of the set of all television objects is another example.\nMember accessibility.\nThe following is a common set of access specifiers:\nAlthough many object-oriented languages support the above access specifiers, their semantics may differ.\nObject-oriented design uses the access specifiers in conjunction with careful design of public method implementations to enforce class invariants\u2014constraints on the state of the objects. A common usage of access specifiers is to separate the internal data of a class from its interface: the internal structure is made private, while public accessor methods can be used to inspect or alter such private data.\nAccess specifiers do not necessarily control \"visibility\", in that even private members may be visible to client external code. In some languages, an inaccessible but visible member may be referred to at run-time (for example, by a pointer returned from a member function), but an attempt to use it by referring to the name of the member from client code will be prevented by the type checker.\nThe various object-oriented programming languages enforce member accessibility and visibility to various degrees, and depending on the language's type system and compilation policies, enforced at either compile-time or run-time. For example, the Java language does not allow client code that accesses the private data of a class to compile.\n In the C++ language, private methods are visible, but not accessible in the interface; however, they may be made invisible by explicitly declaring fully abstract classes that represent the interfaces of the class.\nSome languages feature other accessibility schemes:\nInter-class relationships.\nIn addition to the design of standalone classes, programming languages may support more advanced class design based upon relationships between classes. The inter-class relationship design capabilities commonly provided are \"compositional\" and \"hierarchical\".\nCompositional.\nClasses can be composed of other classes, thereby establishing a compositional relationship between the enclosing class and its embedded classes. Compositional relationship between classes is also commonly known as a \"has-a\" relationship. For example, a class \"Car\" could be composed of and contain a class \"Engine\". Therefore, a Car \"has an\" Engine. One aspect of composition is containment, which is the enclosure of component instances by the instance that has them. If an enclosing object contains component instances by value, the components and their enclosing object have a similar lifetime. If the components are contained by reference, they may not have a similar lifetime. For example, in Objective-C 2.0:\n@interface Car : NSObject\n@property NSString *name;\n@property Engine *engine\n@property NSArray *tires;\n@end\nThis class \"has\" an instance of (a string object), , and (an array object).\nHierarchical.\nClasses can be \"derived\" from one or more existing classes, thereby establishing a hierarchical relationship between the derived-from classes (\"base classes\", \"parent classes\" or ') and the derived class (\"child class\" or \"subclass\") . The relationship of the derived class to the derived-from classes is commonly known as an is-a relationship. For example, a class 'Button' could be derived from a class 'Control'. Therefore, a Button is a\"' Control. Structural and behavioral members of the parent classes are \"inherited\" by the child class. Derived classes can define additional structural members (data fields) and behavioral members (methods) in addition to those that they \"inherit\" and are therefore \"specializations\" of their superclasses. Also, derived classes can override inherited methods if the language allows.\nNot all languages support multiple inheritance. For example, Java allows a class to implement multiple interfaces, but only inherit from one class. If multiple inheritance is allowed, the hierarchy is a directed acyclic graph (or DAG for short), otherwise it is a tree. The hierarchy has classes as nodes and inheritance relationships as links. Classes in the same level are more likely to be associated than classes in different levels. The levels of this hierarchy are called layers or levels of abstraction.\nExample (Simplified Objective-C 2.0 code, from iPhone SDK):\n@interface UIResponder : NSObject //...\n@interface UIView : UIResponder //...\n@interface UIScrollView : UIView //...\n@interface UITableView : UIScrollView //...\nIn this example, a UITableView is a UIScrollView is a UIView is a UIResponder is an NSObject.\nDefinitions of subclass.\nConceptually, a superclass is a superset of its subclasses. For example, a common class hierarchy would involve as a superclass of and , while would be a subclass of . These are all subset relations in set theory as well, i.e., all squares are rectangles but not all rectangles are squares.\nA common conceptual error is to mistake a \"part of\" relation with a subclass. For example, a car and truck are both kinds of vehicles and it would be appropriate to model them as subclasses of a vehicle class. However, it would be an error to model the component parts of the car as subclass relations. For example, a car is composed of an engine and body, but it would not be appropriate to model engine or body as a subclass of car.\nIn object-oriented modeling these kinds of relations are typically modeled as object properties. In this example, the class would have a property called . would be typed to hold a collection of objects, such as instances of , , , etc.\nObject modeling languages such as UML include capabilities to model various aspects of \"part of\" and other kinds of relations \u2013 data such as the cardinality of the objects, constraints on input and output values, etc. This information can be utilized by developer tools to generate additional code beside the basic data definitions for the objects, such as error checking on get and set methods.\nOne important question when modeling and implementing a system of object classes is whether a class can have one or more superclasses. In the real world with actual sets it would be rare to find sets that did not intersect with more than one other set. However, while some systems such as Flavors and CLOS provide a capability for more than one parent to do so at run time introduces complexity that many in the object-oriented community consider antithetical to the goals of using object classes in the first place. Understanding which class will be responsible for handling a message can get complex when dealing with more than one superclass. If used carelessly this feature can introduce some of the same system complexity and ambiguity classes were designed to avoid.\nMost modern object-oriented languages such as Smalltalk and Java require single inheritance at run time. For these languages, multiple inheritance may be useful for modeling but not for an implementation.\nHowever, semantic web application objects do have multiple superclasses. The volatility of the Internet requires this level of flexibility and the technology standards such as the Web Ontology Language (OWL) are designed to support it.\nA similar issue is whether or not the class hierarchy can be modified at run time. Languages such as Flavors, CLOS, and Smalltalk all support this feature as part of their meta-object protocols. Since classes are themselves first-class objects, it is possible to have them dynamically alter their structure by sending them the appropriate messages. Other languages that focus more on strong typing such as Java and C++ do not allow the class hierarchy to be modified at run time. Semantic web objects have the capability for run time changes to classes. The rational is similar to the justification for allowing multiple superclasses, that the Internet is so dynamic and flexible that dynamic changes to the hierarchy are required to manage this volatility.\nOrthogonality of the class concept and inheritance.\nAlthough class-based languages are commonly assumed to support inheritance, inheritance is not an intrinsic aspect of the concept of classes. Some languages, often referred to as \"object-based languages\", support classes yet do not support inheritance. Examples of object-based languages include earlier versions of Visual Basic.\nWithin object-oriented analysis.\nIn object-oriented analysis and in UML, an association between two classes represents a collaboration between the classes or their corresponding instances. Associations have direction; for example, a bi-directional association between two classes indicates that both of the classes are aware of their relationship. Associations may be labeled according to their name or purpose.\nAn association role is given end of an association and describes the role of the corresponding class. For example, a \"subscriber\" role describes the way instances of the class \"Person\" participate in a \"subscribes-to\" association with the class \"Magazine\". Also, a \"Magazine\" has the \"subscribed magazine\" role in the same association. Association role multiplicity describes how many instances correspond to each instance of the other class of the association. Common multiplicities are \"0..1\", \"1..1\", \"1..*\" and \"0..*\", where the \"*\" specifies any number of instances.\nTaxonomy of classes.\nThere are many categories of classes, some of which overlap.\nAbstract and concrete.\nIn a language that supports inheritance, an abstract class, or abstract base class (ABC), is a class that cannot be instantiated because it is either labeled as abstract or it simply specifies abstract methods (or \"virtual methods\"). An abstract class may provide implementations of some methods, and may also specify virtual methods via signatures that are to be implemented by direct or indirect descendants of the abstract class. Before a class derived from an abstract class can be instantiated, all abstract methods of its parent classes must be implemented by some class in the derivation chain.\nMost object-oriented programming languages allow the programmer to specify which classes are considered abstract and will not allow these to be instantiated. For example, in Java, C# and PHP, the keyword \"abstract\" is used. In C++, an abstract class is a class having at least one abstract method given by the appropriate syntax in that language (a pure virtual function in C++ parlance).\nA class consisting of only virtual methods is called a Pure Abstract Base Class (or \"Pure ABC\") in C++ and is also known as an \"interface\" by users of the language. Other languages, notably Java and C#, support a variant of abstract classes called an interface via a keyword in the language. In these languages, multiple inheritance is not allowed, but a class can implement multiple interfaces. Such a class can only contain abstract publicly accessible methods.\nA concrete class is a class that can be instantiated, as opposed to abstract classes, which cannot. \nLocal and inner.\nIn some languages, classes can be declared in scopes other than the global scope. There are various types of such classes.\nAn inner class is a class defined within another class. The relationship between an inner class and its containing class can also be treated as another type of class association. An inner class is typically neither associated with instances of the enclosing class nor instantiated along with its enclosing class. Depending on language, it may or may not be possible to refer to the class from outside the enclosing class. A related concept is \"inner types\", also known as \"inner data type\" or \"nested type\", which is a generalization of the concept of inner classes. C++ is an example of a language that supports both inner classes and inner types (via \"typedef\" declarations).\nAnother type is a local class, which is a class defined within a procedure or function. This limits references to the class name to within the scope where the class is declared. Depending on the semantic rules of the language, there may be additional restrictions on local classes compared to non-local ones. One common restriction is to disallow local class methods to access local variables of the enclosing function. For example, in C++, a local class may refer to static variables declared within its enclosing function, but may not access the function's automatic variables.\nMetaclasses.\nMetaclasses are classes whose instances are classes. A metaclass describes a common structure of a collection of classes and can implement a design pattern or describe particular kinds of classes. Metaclasses are often used to describe frameworks.\nIn some languages, such as Python, Ruby or Smalltalk, a class is also an object; thus each class is an instance of a unique metaclass that is built into the language.\nThe Common Lisp Object System (CLOS) provides metaobject protocols (MOPs) to implement those classes and metaclasses.\nNon-subclassable.\nNon-subclassable classes allow programmers to design classes and hierarchies of classes where at some level in the hierarchy, further derivation is prohibited (a stand-alone class may be also designated as non-subclassable, preventing the formation of any hierarchy). Contrast this to \"abstract\" classes, which imply, encourage, and require derivation in order to be used at all. A non-subclassable class is implicitly \"concrete\".\nA non-subclassable class is created by declaring the class as in C# or as in Java or PHP. For example, Java's class is designated as \"final\".\nNon-subclassable classes may allow a compiler (in compiled languages) to perform optimizations that are not available for subclassable classes. \nOpen class.\nAn open class is one that can be changed. Typically, an executable program cannot be changed by customers. Developers can often change some classes, but typically cannot change standard or built-in ones. In Ruby, all classes are open. In Python, classes can be created at runtime, and all can be modified afterwards. Objective-C categories permit the programmer to add methods to an existing class without the need to recompile that class or even have access to its source code.\nMixins.\nSome languages have special support for mixins, though in any language with multiple inheritance a mixin is simply a class that does not represent an is-a-type-of relationship. Mixins are typically used to add the same methods to multiple classes; for example, a class might provide a method called when included in classes and that do not share a common parent.\nPartial.\nIn languages supporting the feature, a partial class is a class whose definition may be split into multiple pieces, within a single source-code file or across multiple files. The pieces are merged at compile-time, making compiler output the same as for a non-partial class.\nThe primary motivation for introduction of partial classes is to facilitate the implementation of code generators, such as visual designers. It is otherwise a challenge or compromise to develop code generators that can manage the generated code when it is interleaved within developer-written code. Using partial classes, a code generator can process a separate file or coarse-grained partial class within a file, and is thus alleviated from intricately interjecting generated code via extensive parsing, increasing compiler efficiency and eliminating the potential risk of corrupting developer code. In a simple implementation of partial classes, the compiler can perform a phase of precompilation where it \"unifies\" all the parts of a partial class. Then, compilation can proceed as usual.\nOther benefits and effects of the partial class feature include:\nPartial classes have existed in Smalltalk under the name of \"Class Extensions\" for considerable time. With the arrival of the .NET framework 2, Microsoft introduced partial classes, supported in both C# 2.0 and Visual Basic 2005. WinRT also supports partial classes.\nExample in VB.NET.\nThis simple example, written in Visual Basic .NET, shows how parts of the same class are defined in two different files.\nPartial Class MyClass\n Private _name As String\nEnd Class\nPartial Class MyClass\n Public Readonly Property Name() As String\n Get\n Return _name\n End Get\n End Property\nEnd Class\nWhen compiled, the result is the same as if the two files were written as one, like this:\nClass MyClass\n Private _name As String\n Public Readonly Property Name() As String\n Get\n Return _name\n End Get\n End Property\nEnd Class\nExample in Objective-C.\nIn Objective-C, partial classes, also known as categories, may even spread over multiple libraries and executables, like the following example. But a key difference is that Objective-C's categories can overwrite definitions in another interface declaration, and that categories are not equal to original class definition (the first requires the last). Instead, .NET partial class can not have conflicting definitions, and all partial definitions are equal to the others.\nIn Foundation, header file NSData.h:\n@interface NSData : NSObject\n- (id)initWithContentsOfURL:(NSURL *)URL;\n@end\nIn user-supplied library, a separate binary from Foundation framework, header file NSData+base64.h:\n@interface NSData (base64)\n- (NSString *)base64String;\n- (id)initWithBase64String:(NSString *)base64String;\n@end\nAnd in an app, yet another separate binary file, source code file main.m:\nint main(int argc, char *argv[])\n if (argc < 2)\n return EXIT_FAILURE;\n NSString *sourceURLString = [NSString stringWithCString:argv[1]];\n NSData *data = ;\n NSLog(@\"%@\", [data base64String]);\n return EXIT_SUCCESS;\nThe dispatcher will find both methods called over the NSData instance and invoke both of them correctly.\nUninstantiable.\nUninstantiable classes allow programmers to group together per-class fields and methods that are accessible at runtime without an instance of the class. Indeed, instantiation is prohibited for this kind of class.\nFor example, in C#, a class marked \"static\" can not be instantiated, can only have static members (fields, methods, other), may not have \"instance constructors\", and is \"sealed\".\nUnnamed.\nAn unnamed class or anonymous class is a class that is not bound to a name or identifier upon definition. This is analogous to named versus unnamed functions.\nBenefits.\nThe benefits of organizing software into object classes fall into three categories:\nObject classes facilitate rapid development because they lessen the semantic gap between the code and the users. System analysts can talk to both developers and users using essentially the same vocabulary, talking about accounts, customers, bills, etc. Object classes often facilitate rapid development because most object-oriented environments come with powerful debugging and testing tools. Instances of classes can be inspected at run time to verify that the system is performing as expected. Also, rather than get dumps of core memory, most object-oriented environments have interpreted debugging capabilities so that the developer can analyze exactly where in the program the error occurred and can see which methods were called to which arguments and with what arguments.\nObject classes facilitate ease of maintenance via encapsulation. When developers need to change the behavior of an object they can localize the change to just that object and its component parts. This reduces the potential for unwanted side effects from maintenance enhancements.\nSoftware re-use is also a major benefit of using Object classes. Classes facilitate re-use via inheritance and interfaces. When a new behavior is required it can often be achieved by creating a new class and having that class inherit the default behaviors and data of its superclass and then tailor some aspect of the behavior or data accordingly. Re-use via interfaces (also known as methods) occurs when another object wants to invoke (rather than create a new kind of) some object class. This method for re-use removes many of the common errors that can make their way into software when one program re-uses code from another.\nRun-time representation.\nAs a data type, a class is usually considered as a compile-time construct. A language or library may also support prototype or factory metaobjects that represent run-time information about classes, or even represent metadata that provides access to reflection facilities and ability to manipulate data structure formats at run-time. Many languages distinguish this kind of run-time type information about classes from a class on the basis that the information is not needed at run-time. Some dynamic languages do not make strict distinctions between run-time and compile-time constructs, and therefore may not distinguish between metaobjects and classes.\nFor example, if Human is a metaobject representing the class Person, then instances of class Person can be created by using the facilities of the Human metaobject.", "categories": ["Category:All articles needing additional references", "Category:All articles with unsourced statements", "Category:Articles needing additional references from April 2012", "Category:Articles needing additional references from May 2012", "Category:Articles with example Java code", "Category:Articles with short description", "Category:Articles with unsourced statements from April 2012", "Category:Class (computer programming)", "Category:Programming constructs", "Category:Programming language topics"]}, {"docid": 27471338, "title": "Object-oriented programming", "text": "Object-Oriented Programming (OOP) is a programming paradigm based on the concept of \"objects\", which can contain data and code. The data is in the form of fields (often known as attributes or \"properties\"), and the code is in the form of procedures (often known as \"methods\"). \nA common feature of objects is that procedures (or methods) are attached to them and can access and modify the object's data fields. In this brand of OOP, there is usually a special name such as or used to refer to the current object. In OOP, computer programs are designed by making them out of objects that interact with one another. OOP languages are diverse, but the most popular ones are class-based, meaning that objects are instances of classes, which also determine their types.\nMany of the most widely used programming languages (such as C++, Java, Python, etc.) are multi-paradigm and they support object-oriented programming to a greater or lesser degree, typically in combination with imperative, procedural programming. \nSignificant object-oriented languages include: Ada, ActionScript, C++, Common Lisp, C#, Dart, Eiffel, Fortran 2003, Haxe, Java, JavaScript, Kotlin, logo, MATLAB, Objective-C, Object Pascal, Perl, PHP, Python, R, Raku, Ruby, Scala, SIMSCRIPT, Simula, Smalltalk, Swift, Vala and Visual Basic.NET.\nHistory.\nTerminology invoking \"objects\" and \"oriented\" in the modern sense of object-oriented programming made its first appearance at MIT in the late 1950s and early 1960s. In the environment of the artificial intelligence group, as early as 1960, \"object\" could refer to identified items (LISP atoms) with properties (attributes);\nAlan Kay later cited a detailed understanding of LISP internals as a strong influence on his thinking in 1966.\nAnother early MIT example was Sketchpad created by Ivan Sutherland in 1960\u20131961; in the glossary of the 1963 technical report based on his dissertation about Sketchpad, Sutherland defined notions of \"object\" and \"instance\" (with the class concept covered by \"master\" or \"definition\"), albeit specialized to graphical interaction.\nAlso, an MIT ALGOL version, AED-0, established a direct link between data structures (\"plexes\", in that dialect) and procedures, prefiguring what were later termed \"messages\", \"methods\", and \"member functions\".\nSimula introduced important concepts that are today an essential part of object-oriented programming, such as class and object, inheritance, and dynamic binding. \nThe object-oriented Simula programming language was used mainly by researchers involved with physical modelling, such as models to study and improve the movement of ships and their content through cargo ports.\nIn the 1970s, the first version of the Smalltalk programming language was developed at Xerox PARC by Alan Kay, Dan Ingalls and Adele Goldberg. Smalltalk-72 included a programming environment and was dynamically typed, and at first was interpreted, not compiled. Smalltalk became noted for its application of object orientation at the language-level and its graphical development environment. Smalltalk went through various versions and interest in the language grew. While Smalltalk was influenced by the ideas introduced in Simula 67 it was designed to be a fully dynamic system in which classes could be created and modified dynamically.\nIn the 1970s, Smalltalk influenced the Lisp community to incorporate object-based techniques that were introduced to developers via the Lisp machine. Experimentation with various extensions to Lisp (such as LOOPS and Flavors introducing multiple inheritance and mixins) eventually led to the Common Lisp Object System, which integrates functional programming and object-oriented programming and allows extension via a Meta-object protocol. In the 1980s, there were a few attempts to design processor architectures that included hardware support for objects in memory but these were not successful. Examples include the Intel iAPX 432 and the Linn Smart Rekursiv.\nIn 1981, Goldberg edited the August issue of Byte Magazine, introducing Smalltalk and object-oriented programming to a wider audience. In 1986, the Association for Computing Machinery organised the first \"Conference on Object-Oriented Programming, Systems, Languages, and Applications\" (OOPSLA), which was unexpectedly attended by 1,000 people. In the mid-1980s Objective-C was developed by Brad Cox, who had used Smalltalk at ITT Inc., and Bjarne Stroustrup, who had used Simula for his PhD thesis, eventually went to create the object-oriented C++. In 1985, Bertrand Meyer also produced the first design of the Eiffel language. Focused on software quality, Eiffel is a purely object-oriented programming language and a notation supporting the entire software lifecycle. Meyer described the Eiffel software development method, based on a small number of key ideas from software engineering and computer science, in Object-Oriented Software Construction. Essential to the quality focus of Eiffel is Meyer's reliability mechanism, Design by Contract, which is an integral part of both the method and language.\nIn the early and mid-1990s object-oriented programming developed as the dominant programming paradigm when programming languages supporting the techniques became widely available. These included Visual FoxPro 3.0, C++, and Delphi. Its dominance was further enhanced by the rising popularity of graphical user interfaces, which rely heavily upon object-oriented programming techniques. An example of a closely related dynamic GUI library and OOP language can be found in the Cocoa frameworks on Mac OS X, written in Objective-C, an object-oriented, dynamic messaging extension to C based on Smalltalk. OOP toolkits also enhanced the popularity of event-driven programming (although this concept is not limited to OOP).\nAt ETH Z\u00fcrich, Niklaus Wirth and his colleagues had also been investigating such topics as data abstraction and modular programming (although this had been in common use in the 1960s or earlier). Modula-2 (1978) included both, and their succeeding design, Oberon, included a distinctive approach to object orientation, classes, and such.\nObject-oriented features have been added to many previously existing languages, including Ada, BASIC, Fortran, Pascal, and COBOL. Adding these features to languages that were not initially designed for them often led to problems with compatibility and maintainability of code.\nMore recently, a number of languages have emerged that are primarily object-oriented, but that are also compatible with procedural methodology. Two such languages are Python and Ruby. Probably the most commercially important recent object-oriented languages are Java, developed by Sun Microsystems, as well as C# and Visual Basic.NET (VB.NET), both designed for Microsoft's .NET platform. Each of these two frameworks shows, in its own way, the benefit of using OOP by creating an abstraction from implementation. VB.NET and C# support cross-language inheritance, allowing classes defined in one language to subclass classes defined in the other language.\nFeatures.\nObject-oriented programming uses objects, but not all of the associated techniques and structures are supported directly in languages that claim to support OOP. It performs operations on operands. The features listed below are common among languages considered to be strongly class- and object-oriented (or multi-paradigm with OOP support), with notable exceptions mentioned.\nShared with non-OOP languages.\nModular programming support provides the ability to group procedures into files and modules for organizational purposes. Modules are namespaced so identifiers in one module will not conflict with a procedure or variable sharing the same name in another file or module.\nObjects and classes.\nLanguages that support object-oriented programming (OOP) typically use inheritance for code reuse and extensibility in the form of either classes or prototypes. Those that use classes support two main concepts:\nObjects sometimes correspond to things found in the real world. For example, a graphics program may have objects such as \"circle\", \"square\", \"menu\". An online shopping system might have objects such as \"shopping cart\", \"customer\", and \"product\". Sometimes objects represent more abstract entities, like an object that represents an open file, or an object that provides the service of translating measurements from U.S. customary to metric.\nEach object is said to be an instance of a particular class (for example, an object with its name field set to \"Mary\" might be an instance of class Employee). Procedures in object-oriented programming are known as methods; variables are also known as fields, members, attributes, or properties. This leads to the following terms:\nObjects are accessed somewhat like variables with complex internal structure, and in many languages are effectively pointers, serving as actual references to a single instance of said object in memory within a heap or stack. They provide a layer of abstraction which can be used to separate internal from external code. External code can use an object by calling a specific instance method with a certain set of input parameters, read an instance variable, or write to an instance variable. Objects are created by calling a special type of method in the class known as a constructor. A program may create many instances of the same class as it runs, which operate independently. This is an easy way for the same procedures to be used on different sets of data.\nObject-oriented programming that uses classes is sometimes called class-based programming, while prototype-based programming does not typically use classes. As a result, significantly different yet analogous terminology is used to define the concepts of \"object\" and \"instance\".\nIn some languages classes and objects can be composed using other concepts like traits and mixins.\nClass-based vs prototype-based.\nIn class-based languages the \"classes\" are defined beforehand and the \"objects\" are instantiated based on the classes. If two objects \"apple\" and \"orange\" are instantiated from the class \"Fruit\", they are inherently fruits and it is guaranteed that you may handle them in the same way; e.g. a programmer can expect the existence of the same attributes such as \"color\" or \"sugar_content\" or \"is_ripe\".\nIn prototype-based languages the \"objects\" are the primary entities. No \"classes\" even exist. The \"prototype\" of an object is just another object to which the object is linked. Every object has one \"prototype\" link (and only one). New objects can be created based on already existing objects chosen as their prototype. You may call two different objects \"apple\" and \"orange\" a fruit, if the object \"fruit\" exists, and both \"apple\" and \"orange\" have \"fruit\" as their prototype. The idea of the \"fruit\" class doesn't exist explicitly, but as the equivalence class of the objects sharing the same prototype. The attributes and methods of the \"prototype\" are delegated to all the objects of the equivalence class defined by this prototype. The attributes and methods \"owned\" individually by the object may not be shared by other objects of the same equivalence class; e.g. the attribute \"sugar_content\" may be unexpectedly not present in \"apple\". Only single inheritance can be implemented through the prototype.\nDynamic dispatch/message passing.\nIt is the responsibility of the object, not any external code, to select the procedural code to execute in response to a method call, typically by looking up the method at run time in a table associated with the object. This feature is known as dynamic dispatch. If the call variability relies on more than the single type of the object on which it is called (i.e. at least one other parameter object is involved in the method choice), one speaks of multiple dispatch.\nA method call is also known as \"message passing\". It is conceptualized as a message (the name of the method and its input parameters) being passed to the object for dispatch.\nData abstraction.\nData abstraction is a design pattern in which data are visible only to semantically related functions, so as to prevent misuse. The success of data abstraction leads to frequent incorporation of data hiding as a design principle in object oriented and pure functional programming.\nIf a class does not allow calling code to access internal object data and permits access through methods only, this is a form of information hiding known as abstraction. Some languages (Java, for example) let classes enforce access restrictions explicitly, for example denoting internal data with the codice_1 keyword and designating methods intended for use by code outside the class with the codice_2 keyword. Methods may also be designed public, private, or intermediate levels such as codice_3 (which allows access from the same class and its subclasses, but not objects of a different class). In other languages (like Python) this is enforced only by convention (for example, codice_1 methods may have names that start with an underscore). In C#, Swift & Kotlin languages, codice_5 keyword permits access only to files present in same assembly, package or module as that of the class.\nEncapsulation.\nEncapsulation prevents external code from being concerned with the internal workings of an object. This facilitates code refactoring, for example allowing the author of the class to change how objects of that class represent their data internally without changing any external code (as long as \"public\" method calls work the same way). It also encourages programmers to put all the code that is concerned with a certain set of data in the same class, which organizes it for easy comprehension by other programmers. Encapsulation is a technique that encourages decoupling.\nComposition, inheritance, and delegation.\nObjects can contain other objects in their instance variables; this is known as object composition. For example, an object in the Employee class might contain (either directly or through a pointer) an object in the Address class, in addition to its own instance variables like \"first_name\" and \"position\". Object composition is used to represent \"has-a\" relationships: every employee has an address, so every Employee object has access to a place to store an Address object (either directly embedded within itself, or at a separate location addressed via a pointer).\nLanguages that support classes almost always support inheritance. This allows classes to be arranged in a hierarchy that represents \"is-a-type-of\" relationships. For example, class Employee might inherit from class Person. All the data and methods available to the parent class also appear in the child class with the same names. For example, class Person might define variables \"first_name\" and \"last_name\" with method \"make_full_name()\". These will also be available in class Employee, which might add the variables \"position\" and \"salary\". This technique allows easy re-use of the same procedures and data definitions, in addition to potentially mirroring real-world relationships in an intuitive way. Rather than utilizing database tables and programming subroutines, the developer utilizes objects the user may be more familiar with: objects from their application domain.\nSubclasses can override the methods defined by superclasses. Multiple inheritance is allowed in some languages, though this can make resolving overrides complicated. Some languages have special support for mixins, though in any language with multiple inheritance, a mixin is simply a class that does not represent an is-a-type-of relationship. Mixins are typically used to add the same methods to multiple classes. For example, class UnicodeConversionMixin might provide a method unicode_to_ascii() when included in class FileReader and class WebPageScraper, which don't share a common parent.\nAbstract classes cannot be instantiated into objects; they exist only for the purpose of inheritance into other \"concrete\" classes that can be instantiated. In Java, the codice_6 keyword can be used to prevent a class from being subclassed.\nThe doctrine of composition over inheritance advocates implementing has-a relationships using composition instead of inheritance. For example, instead of inheriting from class Person, class Employee could give each Employee object an internal Person object, which it then has the opportunity to hide from external code even if class Person has many public attributes or methods. Some languages, like Go do not support inheritance at all.\nThe \"open/closed principle\" advocates that classes and functions \"should be open for extension, but closed for modification\".\nDelegation is another language feature that can be used as an alternative to inheritance.\nPolymorphism.\nSubtyping \u2013 a form of polymorphism \u2013 is when calling code can be independent of which class in the supported hierarchy it is operating on \u2013 the parent class or one of its descendants. Meanwhile, the same operation name among objects in an inheritance hierarchy may behave differently.\nFor example, objects of type Circle and Square are derived from a common class called Shape. The Draw function for each type of Shape implements what is necessary to draw itself while calling code can remain indifferent to the particular type of Shape being drawn.\nThis is another type of abstraction that simplifies code external to the class hierarchy and enables strong separation of concerns.\nOpen recursion.\nIn languages that support open recursion, object methods can call other methods on the same object (including themselves), typically using a special variable or keyword called codice_7 or codice_8. This variable is \"late-bound\"; it allows a method defined in one class to invoke another method that is defined later, in some subclass thereof.\nOOP languages.\nSimula (1967) is generally accepted as being the first language with the primary features of an object-oriented language. It was created for making simulation programs, in which what came to be called objects were the most important information representation. Smalltalk (1972 to 1980) is another early example, and the one with which much of the theory of OOP was developed. Concerning the degree of object orientation, the following distinctions can be made:\nOOP in dynamic languages.\nIn recent years, object-oriented programming has become especially popular in dynamic programming languages. Python, PowerShell, Ruby and Groovy are dynamic languages built on OOP principles, while Perl and PHP have been adding object-oriented features since Perl 5 and PHP 4, and ColdFusion since version 6.\nThe Document Object Model of HTML, XHTML, and XML documents on the Internet has bindings to the popular JavaScript/ECMAScript language. JavaScript is perhaps the best known prototype-based programming language, which employs cloning from prototypes rather than inheriting from a class (contrast to class-based programming). Another scripting language that takes this approach is Lua.\nOOP in a network protocol.\nThe messages that flow between computers to request services in a client-server environment can be designed as the linearizations of objects defined by class objects known to both the client and the server. For example, a simple linearized object would consist of a length field, a code point identifying the class, and a data value. A more complex example would be a command consisting of the length and code point of the command and values consisting of linearized objects representing the command's parameters. Each such command must be directed by the server to an object whose class (or superclass) recognizes the command and is able to provide the requested service. Clients and servers are best modeled as complex object-oriented structures. Distributed Data Management Architecture (DDM) took this approach and used class objects to define objects at four levels of a formal hierarchy:\nThe initial version of DDM defined distributed file services. It was later extended to be the foundation of Distributed Relational Database Architecture (DRDA).\nDesign patterns.\nChallenges of object-oriented design are addressed by several approaches. Most common is known as the design patterns codified by Gamma \"et al.\". More broadly, the term \"design patterns\" can be used to refer to any general, repeatable, solution pattern to a commonly occurring problem in software design. Some of these commonly occurring problems have implications and solutions particular to object-oriented development.\nInheritance and behavioral subtyping.\nIt is intuitive to assume that inheritance creates a semantic \"is a\" relationship, and thus to infer that objects instantiated from subclasses can always be \"safely\" used instead of those instantiated from the superclass. This intuition is unfortunately false in most OOP languages, in particular in all those that allow mutable objects. Subtype polymorphism as enforced by the type checker in OOP languages (with mutable objects) cannot guarantee behavioral subtyping in any context. Behavioral subtyping is undecidable in general, so it cannot be implemented by a program (compiler). Class or object hierarchies must be carefully designed, considering possible incorrect uses that cannot be detected syntactically. This issue is known as the Liskov substitution principle.\nGang of Four design patterns.\n\"Design Patterns: Elements of Reusable Object-Oriented Software\" is an influential book published in 1994 by Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides, often referred to humorously as the \"Gang of Four\". Along with exploring the capabilities and pitfalls of object-oriented programming, it describes 23 common programming problems and patterns for solving them.\nAs of April 2007, the book was in its 36th printing.\nThe book describes the following patterns:\nObject-orientation and databases.\nBoth object-oriented programming and relational database management systems (RDBMSs) are extremely common in software . Since relational databases don't store objects directly (though some RDBMSs have object-oriented features to approximate this), there is a general need to bridge the two worlds. The problem of bridging object-oriented programming accesses and data patterns with relational databases is known as object-relational impedance mismatch. There are a number of approaches to cope with this problem, but no general solution without downsides. One of the most common approaches is object-relational mapping, as found in IDE languages such as Visual FoxPro and libraries such as Java Data Objects and Ruby on Rails' ActiveRecord.\nThere are also object databases that can be used to replace RDBMSs, but these have not been as technically and commercially successful as RDBMSs.\nReal-world modeling and relationships.\nOOP can be used to associate real-world objects and processes with digital counterparts. However, not everyone agrees that OOP facilitates direct real-world mapping (see Criticism section) or that real-world mapping is even a worthy goal; Bertrand Meyer argues in \"Object-Oriented Software Construction\" that a program is not a model of the world but a model of some part of the world; \"Reality is a cousin twice removed\". At the same time, some principal limitations of OOP have been noted.\nFor example, the circle-ellipse problem is difficult to handle using OOP's concept of inheritance.\nHowever, Niklaus Wirth (who popularized the adage now known as Wirth's law: \"Software is getting slower more rapidly than hardware becomes faster\") said of OOP in his paper, \"Good Ideas through the Looking Glass\", \"This paradigm closely reflects the structure of systems 'in the real world', and it is therefore well suited to model complex systems with complex behaviours\" (contrast KISS principle).\nSteve Yegge and others noted that natural languages lack the OOP approach of strictly prioritizing \"things\" (objects/nouns) before \"actions\" (methods/verbs). This problem may cause OOP to suffer more convoluted solutions than procedural programming.\nOOP and control flow.\nOOP was developed to increase the reusability and maintainability of source code. Transparent representation of the control flow had no priority and was meant to be handled by a compiler. With the increasing relevance of parallel hardware and multithreaded coding, developing transparent control flow becomes more important, something hard to achieve with OOP.\nResponsibility- vs. data-driven design.\nResponsibility-driven design defines classes in terms of a contract, that is, a class should be defined around a responsibility and the information that it shares. This is contrasted by Wirfs-Brock and Wilkerson with data-driven design, where classes are defined around the data-structures that must be held. The authors hold that responsibility-driven design is preferable.\nSOLID and GRASP guidelines.\nSOLID is a mnemonic invented by Michael Feathers which spells out five software engineering design principles:\nGRASP (General Responsibility Assignment Software Patterns) is another set of guidelines advocated by Craig Larman.\nCriticism.\nThe OOP paradigm has been criticised for a number of reasons, including not meeting its stated goals of reusability and modularity, and for overemphasizing one aspect of software design and modeling (data/objects) at the expense of other important aspects (computation/algorithms).\nLuca Cardelli has claimed that OOP code is \"intrinsically less efficient\" than procedural code, that OOP can take longer to compile, and that OOP languages have \"extremely poor modularity properties with respect to class extension and modification\", and tend to be extremely complex. The latter point is reiterated by Joe Armstrong, the principal inventor of Erlang, who is quoted as saying:\nA study by Potok et al. has shown no significant difference in productivity between OOP and procedural approaches.\nChristopher J. Date stated that critical comparison of OOP to other technologies, relational in particular, is difficult because of lack of an agreed-upon and rigorous definition of OOP; however, Date and Darwen have proposed a theoretical foundation on OOP that uses OOP as a kind of customizable type system to support RDBMS.\nIn an article Lawrence Krubner claimed that compared to other languages (LISP dialects, functional languages, etc.) OOP languages have no unique strengths, and inflict a heavy burden of unneeded complexity.\nAlexander Stepanov compares object orientation unfavourably to generic programming:\nPaul Graham has suggested that OOP's popularity within large companies is due to \"large (and frequently changing) groups of mediocre programmers\". According to Graham, the discipline imposed by OOP prevents any one programmer from \"doing too much damage\".\nLeo Brodie has suggested a connection between the standalone nature of objects and a tendency to duplicate code in violation of the don't repeat yourself principle of software development.\nSteve Yegge noted that, as opposed to functional programming:\nRich Hickey, creator of Clojure, described object systems as overly simplistic models of the real world. He emphasized the inability of OOP to model time properly, which is getting increasingly problematic as software systems become more concurrent.\nEric S. Raymond, a Unix programmer and open-source software advocate, has been critical of claims that present object-oriented programming as the \"One True Solution\", and has written that object-oriented programming languages tend to encourage thickly layered programs that destroy transparency. Raymond compares this unfavourably to the approach taken with Unix and the C programming language.\nRob Pike, a programmer involved in the creation of UTF-8 and Go, has called object-oriented programming \"the Roman numerals of computing\" and has said that OOP languages frequently shift the focus from data structures and algorithms to types. Furthermore, he cites an instance of a Java professor whose \"idiomatic\" solution to a problem was to create six new classes, rather than to simply use a lookup table.\nRegarding inheritance, Bob Martin states that because they are software, related classes do not necessarily share the relationships of the things they represent.\nFormal semantics.\nObjects are the run-time entities in an object-oriented system. They may represent a person, a place, a bank account, a table of data, or any item that the program has to handle.\nThere have been several attempts at formalizing the concepts used in object-oriented programming. The following concepts and constructs have been used as interpretations of OOP concepts:\nAttempts to find a consensus definition or theory behind objects have not proven very successful (however, see Abadi & Cardelli, \"A Theory of Objects\" for formal definitions of many OOP concepts and constructs), and often diverge widely. For example, some definitions focus on mental activities, and some on program structuring. One of the simpler definitions is that OOP is the act of using \"map\" data structures or arrays that can contain functions and pointers to other maps, all with some syntactic and scoping sugar on top. Inheritance can be performed by cloning the maps (sometimes called \"prototyping\").", "categories": ["Category:All articles containing potentially dated statements", "Category:All articles needing additional references", "Category:All articles with unsourced statements", "Category:Articles containing potentially dated statements from 2006", "Category:Articles needing additional references from August 2009", "Category:Articles with BNE identifiers", "Category:Articles with BNF identifiers", "Category:Articles with BNFdata identifiers", "Category:Articles with FAST identifiers", "Category:Articles with GND identifiers"]}]}
{"user_id": 2, "seed_docs": [{"docid": 49725, "title": "American bison", "text": "The American bison (: bison) (Bison bison), also called the American buffalo or simply buffalo (not to be confused with true buffalo), is a species of bison native to North America. It is one of two extant species of bison, alongside the European bison. Its historical range, by 9000 BC, is described as the great bison belt, a tract of rich grassland that ran from Alaska to the Gulf of Mexico, east to the Atlantic Seaboard (nearly to the Atlantic tidewater in some areas), as far north as New York, south to Georgia, and according to some sources, further south to Florida, with sightings in North Carolina near Buffalo Ford on the Catawba River as late as 1750. \nOnce roaming in vast herds, the species nearly became extinct by a combination of commercial hunting and slaughter in the 19th century and introduction of bovine diseases from domestic cattle. With a population of 60 million in the late 18th century, the species was culled down to just 541 animals by 1889 as part of the subjugation of the Native Americans, because the American bison was a major resource for their traditional way of life (food source, hides for clothing and shelter, and horns and bones for tools). Recovery efforts expanded in the mid-20th century, with a resurgence to roughly 31,000 wild bison as of March 2019. For many years, the population was primarily found in a few national parks and reserves. Through multiple reintroductions, the species now freely roams wild in several regions in the United States, Canada, and Mexico, with it also being introduced to Yakutia in Russia.\nTwo subspecies or ecotypes have been described: the plains bison (\"B. b. bison\"), smaller in size and with a more rounded hump, and the wood bison (\"B. b. athabascae\")\u2014the larger of the two and having a taller, square hump. Furthermore, the plains bison has been suggested to consist of a northern plains (\"B. b. montanae\") and a southern plains (\"B. b. bison\") subspecies, bringing the total to three. However, this is generally not supported. The wood bison is one of the largest wild species of extant bovid in the world, surpassed only by the Asian gaur. Among extant land animals in North America, the bison is the heaviest and the longest, and the second tallest after the moose.\nSpanning back millennia, Native American tribes have had cultural and spiritual connections to the American bison. It is the national mammal of the United States of America.\nEtymology.\nIn American English, both \"buffalo\" and \"bison\" are considered correct terms for the American bison. However in British English, the word \"buffalo\" is reserved for the African buffalo and water buffalo and not used for the bison.\nIn English usage, the term \"buffalo\" was used to refer to the American mammal as early as 1625. The word \"bison\" was applied in the 1690s.\n\"Buffalo\" was applied to the American bison by Samuel de Champlain as the French word \"buffles\" in 1616 (published 1619), after seeing skins and a drawing. These were shown to him by members of the Nipissing First Nation, who said they travelled forty days (from east of Lake Huron) to trade with another nation who hunted the animals. \"Buffel\" in turn comes from Portuguese \"bufalo\" (water buffalo), which comes from Latin \"bufalus\" (an antelope, gazelle, or wild ox), from Greek \"boubalos\". From the same Greek word \"boubalos\" we also get the Bubal hartebeest.\n\"Bison\" was borrowed from French \"bison\" in the early 1600s, from Latin \"bison\" (aurochs), from a Proto-Germanic word similar to wisent.\nIn Plains Indian languages in general, male and female bison are distinguished, with each having a different designation rather than there being a single generic word covering both sexes. Thus:\nSuch a distinction is not a general feature of the language (for example, Arapaho possesses gender-neutral terms for other large mammals such as elk, mule deer, etc.), and so presumably is due to the special significance of the bison in Plains Indian life and culture.\nDescription.\nA bison has a shaggy, long, dark-brown winter coat, and a lighter-weight, lighter-brown summer coat. Male bison are significantly larger and heavier than females. Plains bison are often in the smaller range of sizes, and wood bison in the larger range. Head-rump lengths at maximum up to for males and for females long and the tail adding . Heights at withers in the species can reach up to for \"B. b. bison\" and \"B. b. athabascae\" respectively. Typically weights can range from , with medians of (\"B.b. bison\") and (\"B.b.athabascae\") in males, and with medians of in females, although the lowest weights probably representing typical weight around the age of sexual maturity at 2 to 3 years of age. \nThe heaviest wild bull for \"B.b.bison\" ever recorded weighed while there had been bulls estimated to be . \"B.b.athabascae\" is significantly larger and heavier on average than \"B.b.bison\" while the number of recorded samples for the former was limited after the rediscovery of a relatively pure herd. Elk Island National Park, which has wild populations of both wood and plains bison, has recorded maximum weights for bull bison of 1186\u00a0kg (plains) and 1099\u00a0kg (wood), but noted that 3/4 of all bison over 1000\u00a0kg were wood bison. When raised in captivity and farmed for meat, the bison can grow unnaturally heavy and the largest semidomestic bison weighed . The heads and forequarters are massive, and both sexes have short, curved horns that can grow up to long with to width, which they use in fighting for status within the herd and for defense.\nBison are herbivores, grazing on the grasses and sedges of the North American prairies. Their daily schedule involves two-hour periods of grazing, resting, and cud chewing, then moving to a new location to graze again. Sexually mature young bulls may try to start mating with cows by the age of two or three years, but if more mature bulls are present, they may not be able to compete until they reach five years of age.\nFor the first two months of life, calves are lighter in color than mature bison. One extremely rare condition is the white buffalo, in which the calf turns entirely white.\nEvolution.\nBison are members of the tribe Bovini. Genetic evidence from nuclear DNA indicates that the closest living relatives of bison are yaks, with bison being nested within the genus \"Bos,\" rendering \"Bos\" without including bison paraphyletic. While nuclear DNA indicates that the two living bison species are each others closest living relatives, the mitochondrial DNA of European bison is more closely related to that of domestic cattle and aurochs, which is either suggested to be the result of incomplete lineage sorting or ancient introgression. Bison first appeared in Asia during the Early Pleistocene, around 2.6 million years ago. Bison only arrived in North America 195,000 to 135,000 years ago, during the late Middle Pleistocene, descending from the widespread Siberian steppe bison (\"Bison priscus\"), which had migrated through Beringia. Following its first appearance in North America, the bison rapidly differentiated into new species such as the largest of all bison, the long-horned \"Bison latifrons\" as well as \"Bison antiquus\". The first appearance of bison in North America is considered to define the regional Rancholabrean faunal stage, due to its major impact on the ecology of the continent. Modern American bison are thought to have evolved from \"B. antiquus\" during the Late Pleistocene-Holocene transition via the intermediate form \"Bison occidentalis\".\nDifferences from European bison.\nAlthough they are superficially similar, the American and European bison exhibit a number of physical and behavioral differences. Adult American bison are slightly heavier on average because of their less rangy build and have shorter legs, which render them slightly shorter at the shoulder. American bison tend to graze more and browse less than their European relatives because their necks are set differently. Compared to the nose of the American bison, that of the European species is set farther forward than the forehead when the neck is in a neutral position. The body of the American bison is hairier, though its tail has less hair than that of the European bison. The horns of the European bison point forward through the plane of its face, making it more adept at fighting through the interlocking of horns in the same manner as domestic cattle, unlike the American bison, which favors charging. American bison are more easily tamed than the European and breed more readily with domestic cattle.\nCrossbreeding with cattle.\nDuring the population bottleneck, after the great slaughter of American bison during the 1800s, the number of bison remaining alive in North America declined to as low as 541. During that period, a handful of ranchers gathered remnants of the existing herds to save the species from extinction. These ranchers bred some of the bison with cattle in an effort to produce \"cattalo\" or \"beefalo\". Accidental crossings were also known to occur. Generally, male domestic bulls were crossed with bison cows, producing offspring of which only the females were fertile. The crossbred animals did not demonstrate any form of hybrid vigor, so the practice was abandoned. The proportion of cattle DNA that has been measured in introgressed individuals and bison herds today is typically quite low, ranging from 0.56 to 1.8%. In the United States, many ranchers are now using DNA testing to cull the residual cattle genetics from their bison herds. The U.S. National Bison Association has adopted a code of ethics which prohibits its members from deliberately crossbreeding bison with any other species.\nRange and population.\nPopulation estimates in 2010 ranged from 400,000 to 500,000, with approximately 20,500 animals in 62 conservation herds and the remainder in approximately 6,400 commercial herds. According to the IUCN, roughly 15,000 bison are considered wild, free-range bison not primarily confined by fencing.\nThe Nature Conservancy (TNC) has reintroduced bison to over a dozen nature preserves around the United States. In October 2016, TNC established its easternmost bison herd in the country, at Kankakee Sands nature preserve in Morocco, Newton County, Indiana. In 2014, U.S Tribes and Canadian First Nations signed a treaty to help with the restoration of bison, the first to be signed in nearly 150 years.\nHabitat and trails.\nAmerican bison live in river valleys, and on prairies and plains. Typical habitat is open or semiopen grasslands, as well as sagebrush, semiarid lands, and scrublands. Some lightly wooded areas are also known historically to have supported bison. Bison also graze in hilly or mountainous areas where the slopes are not steep. Though not particularly known as high-altitude animals, bison in the Yellowstone Park bison herd are frequently found at elevations above and the Henry Mountains bison herd is found on the plains around the Henry Mountains, Utah, as well as in mountain valleys of the Henry Mountains to an altitude of . Reintroduced plains bison in Banff National Park have been observed to roam mountainous areas including high ridges and steep drainages, and archaeological finds indicate some bison historically may have spent their lives within mountains while others may have migrated in and out of mountains.\nThose in Yukon, Canada, typically summer in alpine plateaus above treeline. The first thoroughfares of North America, except for the time-obliterated paths of mastodon or muskox and the routes of the mound builders, were the traces made by bison and deer in seasonal migration and between feeding grounds and salt licks. Many of these routes, hammered by countless hoofs instinctively following watersheds and the crests of ridges in avoidance of lower places' summer muck and winter snowdrifts, were followed by the aboriginal North Americans as courses to hunting grounds and as warriors' paths. They were invaluable to explorers and were adopted by pioneers.\nBison traces were characteristically north and south, but several key east\u2013west trails were used later as railways. Some of these include the Cumberland Gap through the Blue Ridge Mountains to upper Kentucky. A heavily used trace crossed the Ohio River at the Falls of the Ohio and ran west, crossing the Wabash River near Vincennes, Indiana. In Senator Thomas Hart Benton's phrase saluting these sagacious path-makers, the bison paved the way for the railroads to the Pacific.\nMexico.\nThe southern extent of the historic range of the American bison includes northern Mexico and adjoining areas in the United States as documented by archeological records and historical accounts from Mexican archives from 700\u00a0CE to the 19th century. The Janos-Hidalgo bison herd has ranged between Chihuahua, Mexico, and New Mexico, United States, since at least the 1920s. The persistence of this herd suggests that habitat for bison is suitable in northern Mexico. In 2009, genetically pure bison were reintroduced to the Janos Biosphere Reserve in northern Chihuahua adding to the Mexican bison population. In 2020, the second herd was formed in Maderas del Carmen. A private reserve named Jag\u00fcey de Ferniza has kept bisons since before the above-mentioned reintroductions in Coahuila.\nIntroductions to Siberia.\nSince 2006, an outherd of wood bison sent from Alberta's Elk Island National Park was established in Yakutia, Russia as a practice of pleistocene rewilding; wood bison are the most closely related to the extinct bison species. The bison are adapting well to the cold climate, and Yakutia's Red List officially registered the species in 2019; a second herd was formed in 2020. \nIn Pleistocene Park, there are also 24 plains bison as wood bison could not be acquired.\nBehavior and ecology.\nBison are migratory and herd migrations can be directional as well as altitudinal in some areas. Bison have usual daily movements between foraging sites during the summer. In the Hayden Valley, Wyoming, bison have been recorded traveling, on average, per day. The summer ranges of bison appear to be influenced by seasonal vegetation changes, interspersion and size of foraging sites, the rut, and the number of biting insects. The size of preserve and availability of water may also be a factor. Bison are largely grazers, eating primarily grasses and sedges. On shortgrass pasture, bison predominately consume warm-season grasses. On mixed prairie, cool-season grasses, including some sedges, apparently compose 79\u201396% of their diet. In montane and northern areas, sedges are selected throughout the year. Bison also drink water or consume snow on a daily basis.\nSocial behavior and reproduction.\nFemale bison live in maternal herds which include other females and their offspring. Male offspring leave their maternal herd when around three years old and either live alone or join other males in bachelor herds. Male and female herds usually do not mingle until the breeding season, which can occur from July through September. However, female herds may also contain a few older males. During the breeding season, dominant bulls maintain a small harem of females for mating. Individual bulls \"tend\" cows until allowed to mate, by following them around and chasing away rival males. The tending bull shields the female's vision with his body so she will not see any other challenging males. A challenging bull may bellow or roar to get a female's attention and the tending bull has to bellow/roar back. The most dominant bulls mate in the first 2\u20133 weeks of the season. More subordinate bulls mate with any remaining estrous cow that has not mated yet. Male bison play no part in raising the young.\nBison herds have dominance hierarchies that exist for both males and females. A bison's dominance is related to its birth date. Bison born earlier in the breeding season are more likely to be larger and more dominant as adults. Thus, bison are able to pass on their dominance to their offspring as dominant bison breed earlier in the season. In addition to dominance, the older bison of a generation also have a higher fertility rate than the younger ones.\nBison mate in August and September; gestation is 285 days. A single reddish-brown calf nurses until the next calf is born. If the cow is not pregnant, a calf will nurse for 18 months. Cows nurse their calves for at least 7 or 8 months, but most calves seem to be weaned before the end of their first year. At three years of age, bison cows are mature enough to produce a calf. The birthing period for bison in boreal biomes is protracted compared to that of other northern ungulates, such as moose and caribou.\nBison have a life expectancy around 15 years in the wild and up to 25 years in captivity. However, males and females from a hunted population also subject to wolf predation in northern Canada have been reported to live to 22 and 25 years of age, respectively.\nBison have been observed to display homosexual behaviors, males much more so than females. In the case of males, it is unlikely to be related to dominance, but rather to social bonding or gaining sexual experience.\nHorning.\nBison mate in late spring and summer in more open plain areas. During fall and winter, bison tend to gather in more wooded areas. During this time, bison partake in horning behaviors. They rub their horns against trees, young saplings, and even utility poles. Aromatic trees like cedars and pine seem to be preferred. Horning appears to be associated with insect defense, as it occurs most often in the fall when the insect population is at its highest. Cedar and pines emit an aroma after bison horn them and this seems to be used as a deterrent for insects.\nWallowing behavior.\nA bison wallow is a shallow depression in the soil, which bison use either wet or dry. Bison roll in these depressions, covering themselves with dust or mud. Past and current hypotheses to explain the purpose of wallowing include grooming associated with shedding, male-male interaction (typically rutting), social behavior for group cohesion, play, relief from skin irritation due to biting insects, reduction of ectoparasite (tick and lice) load, and thermoregulation. Bison wallowing has important ecosystem engineering effects and enhances plant and animal diversity on prairies.\nPredation.\nWhile often secure from predation because of their size and strength, in some areas, vulnerable individuals are regularly preyed upon by wolves. Wolf predation typically peaks in late winter, when elk migrates south and bison are distressed with heavy snows and shortages of food sources, with attacks usually being concentrated on weakened and injured cows and calves. Wolves more actively target herds with calves than those without. The length of a predation episode varies, ranging from a few minutes to over nine hours. Bison display five apparent defense strategies in protecting calves from wolves: running to a cow; running to a herd; running to the nearest bull; running in the front or center of a stampeding herd; entering water bodies, such as lakes or rivers. When fleeing wolves in open areas, cows with young calves take the lead, while bulls take to the rear of the herds to guard the cows' escape. Bison typically ignore wolves not displaying hunting behavior. Wolf packs specializing in bison tend to have more males because their larger size than females allows them to wrestle prey to the ground more effectively. Healthy, mature bulls in herds rarely fall prey.\nGrizzly bears are known to feed on carcass and may steal wolves' kills. While grizzlies can also pose a threat to calves and sometimes old, injured, or sick adult bison, direct killing of non-calves is rare even when targeting lone and injured young individuals; attacking healthy bison is risky for bears, who can be killed instead.\nDangers to humans.\nBison are among the most dangerous animals encountered by visitors to the various North American national parks and will attack humans if provoked. They appear slow because of their lethargic movements but can easily outrun humans; bison have been observed running as fast as for . Bison may approach people for curiosity. Close encounters, including to touch the animals, can be dangerous, and gunshots do not startle them.\nBetween 1980 and 1999, more than three times as many people in Yellowstone National Park were injured by bison than by bears. During this period, bison charged and injured 79 people, with injuries ranging from goring puncture wounds and broken bones to bruises and abrasions. Bears injured 24 people during the same time. Three people died from the injuries inflicted\u2014one person by bison in 1983, and two people by bears in 1984 and 1986.\nGenetics.\nA major problem that bison face today is a lack of genetic diversity due to the population bottleneck the species experienced during its near-extinction event. Another genetic issue is the entry of genes from domestic cattle into the bison population, through hybridization.\nOfficially, the \"American buffalo\" is classified by the United States government as a type of cattle, and the government allows private herds to be managed as such. This is a reflection of the characteristics that bison share with cattle. Though the American bison is a separate species and usually regarded as being in a separate genus from domestic cattle (\"Bos taurus\"), they have a lot of genetic compatibility with cattle. American bison can interbreed with cattle, although only the female offspring are fertile in the first generation. These female hybrids can be bred back to either bison or domestic bulls, resulting in either 1/4 or 3/4 bison young. Female offspring from this cross are also fertile, but males are not reliably fertile unless they are either bison or domestic. Moreover, when they do interbreed, crossbreed animals in the first generation tend to look very much like purebred bison, so appearance is completely unreliable as a means of determining what is a purebred bison and what is a crossbred cow. Many ranchers have deliberately crossbred their cattle with bison, and some natural hybridization could be expected in areas where cattle and bison occur in the same range. Since cattle and bison eat similar food and tolerate similar conditions, they have often been in the same range together in the past, and opportunity for crossbreeding may sometimes have been common.\nIn recent decades, tests were developed to determine the source of mitochondrial DNA in cattle and bison, and most private \"buffalo\" herds were actually crossbred with cattle, and even most state and federal buffalo herds had some cattle DNA. With the advent of nuclear microsatellite DNA testing, the number of herds known to contain cattle genes has increased. As of 2011, though about 500,000 bison existed on private ranches and in public herds, perhaps only 15,000 to 25,000 of these bison were pure and not actually bison-cattle hybrids. DNA from domestic cattle (\"Bos taurus\") has been found in almost all examined bison herds. \nSignificant public bison herds that do not appear to have hybridized domestic cattle genes are the Yellowstone Park bison herd, the Henry Mountains bison herd, which was started with bison taken from Yellowstone Park, the Wind Cave bison herd, and the Wood Buffalo National Park bison herd and subsidiary herds started from it, in Canada.\nA landmark study of bison genetics performed by James Derr of Texas A&M University corroborated this. The Derr study was undertaken in an attempt to determine what genetic problems bison might face as they repopulate former areas, and it noted that bison seem to be adapting successfully, despite their apparent genetic bottleneck. One possible explanation for this might be the small amount of domestic cattle genes that are now in most bison populations, though this is not the only possible explanation for bison success.\nIn the study, cattle genes were also found in small amounts throughout most national, state, and private herds. \"The hybridization experiments conducted by some of the owners of the five foundation herds of the late 1800s, have left a legacy of a small amount of cattle genetics in many of our existing bison herds,\" said Derr. \"All of the state owned bison herds tested (except for possibly one) contain animals with domestic cattle mtDNA.\" \nIt appears that the one state herd that had no cattle genes was the Henry Mountains bison herd; the Henry Mountain herd was started initially with transplanted animals from Yellowstone Park. However, the extension of this herd into the Book Cliffs of central Utah involved mixing the founders with additional bison from another source, so it is not known if the Book Cliffs extension of the herd is also free of cattle hybridization.\nA separate study by Wilson and Strobeck, published in \"Genome\", was done to define the relationships between different herds of bison in the United States and Canada, and to determine whether the bison at Wood Buffalo National Park in Canada and the Yellowstone Park bison herd were possibly separate subspecies. The Wood Buffalo Park bison were determined to actually be crossbreeds between plains and wood bison, but their predominant genetic makeup was that of the expected \"wood buffalo\". However, the Yellowstone Park bison herd was pure plains bison, and not any of the other previously suggested subspecies. Another finding was that the bison in the Antelope Island herd in Utah appeared to be more distantly related to other plains bison in general than any other plains bison group that was tested, though this might be due to genetic drift caused by the small size of only 12 individuals in the founder population. A side finding of this was that the Antelope Island bison herd appears to be most closely related to the Wood Buffalo National Park bison herd, though the Antelope Island bison are actually plains bison.\nIn order to bolster the genetic diversity of the American bison, the National Park Service alongside the Department of the Interior announced on May 7, 2020, the 2020 Bison Conservation Initiative. This initiative focuses on maintaining the genetic diversity of the metapopulation rather than individual herds. Small populations of bison are at considerably larger risk due to their decreased gene pool and are susceptible to catastrophic events more so than larger herds. The 2020 Bison Conservation Initiative aims to translocate up to three bison every five to ten years between the Department of the Interior's herds. Specific smaller herds will require a more intense management plan. Translocated bison will also be screened for any health defects such as infection of brucellosis bacteria as to not put the larger herd at risk.\nPopulation bottlenecking.\nBecause of the mass slaughtering of bison during the 1870s, the plains bison population went through a population bottleneck from an estimated 60 million individuals\u2013an estimation based on an observation made by Colonel R.I. Dodge along the Arkansas River in Kansas in 1871\u2013to a founding population of around 100 individuals, split into six herds, five of which were managed by private ranchers and one managed by the New York Zoological Park (now the Bronx Zoo). Additionally, a wild herd consisting of 25 individuals in Yellowstone National Park survived the bottleneck.\nEach of the privately ranched herds had an initial effective population size (Ne) of an estimated 5 to 7 individuals, for a total combined effective population size of between 30 and 50 individuals, from which all of the modern plains bison descend. While these herds have remained mostly isolated, some more than others, there has been some interbreeding between the herds over the past 150 years.\nThe conservation efforts and copious amounts of data taken on American bison populations allow for American bison to serve as a useful study case of population bottlenecking and its effects. This is especially true of the Texas State Bison Herd, which underwent very extreme genetic bottlenecking, with a founding population of only 5 individuals.\nTexas State Bison Herd.\nThe Texas State Bison Herd (TSBH), also known as the Goodnight herd, was established by Charles Goodnight in the mid-1880s with five wild-caught calves. In 1887, the herd consisted of 13 individuals; in 1910, the population consisted of 125 individuals; and in the 1920s, the population ranged from 200-250 individuals. In 1929, Goodnight died and the herd switched hands multiple times, leaving the population of the herd unknown from 1930 until the herd was donated to the State of Texas in 1997, with a population of 36 individuals, solely descended from the original five calves. By 2002, the population of the TSBH consisted of 40 individuals and had concerningly low birth rates and high rates of calf mortality. This led to extra attention being given to this herd by conservationists who then performed significant amounts of genetic testing.\nIt is also crucial to mention that Goodnight was an advocate for the hybridization of bison with cattle, in the hopes creating a stronger and healthier breed. When the herd was donated to the State of Texas in 1997, genetic testing revealed that 6 out of 36 individuals still carried cattle mitochondrial DNA.\nResearchers found that the average number of alleles per locus and the heterozygosity levels (a measure of genetic diversity, where high heterozygosity is representative of high genetic diversity) for the TSBH were significantly lower than that of the Yellowstone National Park bison population and the Theodore Roosevelt National Park bison population. Additionally, of the 54 nuclear microsatellites that were examined, the TSBH had 8 monomorphic loci (i.e., each loci had only one allele), whereas in both the Yellowstone and Theodore Roosevelt herds there was only one monomorphic locus, indicating a much lower level of genetic diversity in the TSBH. The Yellowstone herd had an average number of alleles per locus of 4.75, the Theodore Roosevelt National Park herd had an average of 4.15 alleles per locus, but the TSBH only had an average of 2.54 alleles per locus, statistically significantly lower than the others. The heterozygosity level of the Yellowstone, Theodore Roosevelt, and TSBH populations were 0.63, 0.57, and 0.38 respectively, with the TSBH again having a statistically significantly lower value. This low genetic diversity found in TSBH is likely due to the critically low starting population, several additional bottlenecks throughout the herd\u2019s history\u2013leading to inbreeding depression\u2013, and a continuously low population allowing for genetic drift to have a large effect. Before any addition of new individuals, the rate of loss of genetic diversity was estimated to be between 30-40% over the proceeding 50 years.\nThe inbreeding depression resulting from the multiple extreme population bottlenecks in the TSBH led to a coefficient of inbreeding of 0.367, equal to the level of inbreeding that results from two generations of full-siblings mating.\nThe Texas State Bison Herd is also a useful example of the deleterious effects of extreme population bottlenecking, with an average natality rate of 0.376 offspring per female and a 1st-year mortality rate of 52.6% from 1997 to 2002, compared to an average natality rate of 0.560 offspring per female and a 1st-year mortality rate of 4.2% for the other bison herds.\nAdditionally, if it were not for the intervention of conservationists, the Texas State Bison Herd would have most likely gone extinct, as the population bottleneck would have proven to be too severe. Multiple population models based on the genetics of the TSBH in the early 2000s predicted a 99% chance of extinction of the TSBH in less than 50 years, with an estimation in 2004 giving the TSBH a 99% chance of extinction in 41 years without the introduction of any outside individuals (Halbert et al. 2004). Importantly for conservation, another simulation predicted that the addition of multiple (3-9) outside male bison into the herd would increase genetic diversity enough to give the herd a 100% chance of surviving for another 100 years.\nConservation efforts have led the current TSBH population to be at the carrying capacity of their habitat, at around 300 individuals. \nYellowstone National Park Bison Herd.\nThe Yellowstone National Park Bison herd started with only 25 individuals, and there was evidence of two population bottlenecking events from 1896-1912, with a population ranging between 25 and 50 individuals during this time. In 1902, 18 female and 3 male bison from outside herds\u2013the Pablo-Allard herd and Goodnight (TSBH) herds respectively\u2013were introduced to the Yellowstone herd. After the addition of those individuals, the effective population size is estimated to have been Ne=7.2 individuals. The Yellowstone herd was kept completely isolated from 1902 to around 1920, and these previously mentioned founders contributed between 60-70% of the genetics of the current bison population at Yellowstone. \nSimilar to the Texas State Bison Herd, the introduction of new individuals into the population in 1902 likely was the savior of this herd, which now numbers around 5,900 individuals as of summer 2022.\nHunting.\nBuffalo hunting, i.e. hunting of the American bison, was an activity fundamental to the Indigenous peoples of the Great Plains, providing more than 150 uses for all parts of the animal, including being a major food source, hides for clothing and shelter, bones and horns as tools as well as ceremonial and adornment uses. Bison hunting was later adopted by American professional hunters, as well as by the U.S. government, in an effort to sabotage the central resource of some American Indian Nations during the later portions of the American Indian Wars, leading to the near-extinction of the species around 1890. For many tribes the buffalo was an integral part of life\u2014something guaranteed to them by the Creator. In fact, for some Plains indigenous peoples, bison are known as the first people. The concept of species extinction was foreign to many tribes. \nThus, when the U.S. government began to massacre the buffalo, it was particularly harrowing to the Indigenous people. As Crow chief Plenty Coups described it: \"When the buffalo went away the hearts of my people fell to the ground, and they could not lift them up again. After this nothing happened. There was little singing anywhere.\" Spiritual loss was rampant; bison were an integral part of traditional tribal societies, and they would frequently take part in ceremonies for each bison they killed to honor its sacrifice. In order to boost morale during this time, Sioux and other tribes took part in the Ghost Dance, which consisted of hundreds of people dancing until 100 persons were lying unconscious.\nToday, many conservation measures have been taken by Native Americans, with the Inter Tribal Bison Council being one of the most significant. It was formed in 1990, composed of 56 tribes in 19 states. These tribes represent a collective herd of more than 15,000 bison and focus on reestablishing herds on tribal lands in order to promote culture, revitalize spiritual solidarity, and restore the ecosystem. Some Inter Tribal Bison Council members argue that the bison's economic value is one of the main factors driving its resurgence. Bison serve as a low cost substitute for cattle, and can withstand the winters in the Plains region far easier than cattle.\nAs livestock.\nBison are increasingly raised for meat, hide, wool, and dairy products. The majority of American bison in the world are raised for human consumption or fur clothing. Bison meat is generally considered to taste very similar to beef, but is lower in fat and cholesterol, yet higher in protein than beef, which has led to the development of beefalo, a fertile hybrid of bison and domestic cattle. In 2005, about 35,000 bison were processed for meat in the U.S., with the National Bison Association and USDA providing a \"Certified American Buffalo\" program with birth-to-consumer tracking of bison via RFID ear tags. A market even exists for kosher bison meat; these bison are slaughtered at one of the few kosher mammal slaughterhouses in the U.S., and the meat is then distributed nationwide.\nBison are found in publicly and privately held herds. Custer State Park in South Dakota is home to 1,500 bison, one of the largest publicly held herds in the world, but some question the genetic purity of the animals. Wildlife officials believe that free roaming herds with minimal cattle introgression on public lands in North America can be found only in: the Yellowstone Park bison herd; the Henry Mountains bison herd at the Book Cliffs and Henry Mountains in Utah; at Wind Cave National Park in South Dakota; Fort Peck Indian Reservation in Montana; Mackenzie Bison Sanctuary in the Northwest Territories; Elk Island National Park and Wood Buffalo National Park in Alberta; Grasslands National Park and Prince Albert National Park in Saskatchewan. Another population, the Antelope Island bison herd on Antelope Island in Utah, consisting of 550 to 700 bison, is also one of the largest and oldest public herds in the United States, but the bison in that herd are considered to be only semifree roaming, since they are confined to the Antelope Island. In addition, recent genetic studies indicate that, like most bison herds, the Antelope Island bison herd has a small number of genes from domestic cattle. In 2002, the United States government donated some bison calves from South Dakota and Colorado to the Mexican government. Their descendants live in the Mexican nature reserves El Uno Ranch at Janos and Santa Elena Canyon, Chihuahua, and Boquillas del Carmen, Coahuila, located near the southern banks of the Rio Grande, and around the grassland state line with Texas and New Mexico.\nRecent genetic studies of privately owned herds of bison show that many of them include animals with genes from domestic cattle. For example, the herd on Santa Catalina Island, California, isolated since 1924 after being brought there for a movie shoot, were found to have cattle introgression. As few as 12,000 to 15,000 pure bison are estimated to remain in the world. The numbers are uncertain because the tests used to date\u2014mitochondrial DNA analysis\u2014indicate only if the maternal line (back from mother to mother) ever included domesticated bovines, thus say nothing about possible male input in the process. Most hybrids were found to look exactly like purebred bison; therefore, appearance is not a good indicator of genetics.\nThe size of the Canadian domesticated herd (genetic questions aside) grew dramatically through the 1990s and 2000s. The 2006 Census of Agriculture reported the Canadian herd at 195,728 head, a 34.9% increase since 2001. Of this total, over 95% were located in Western Canada, and less than 5% in Eastern Canada. Alberta was the province with the largest herd, accounting for 49.7% of the herd and 45.8% of the farms. The next-largest herds were in Saskatchewan (23.9%), Manitoba (10%), and British Columbia (6%). The main producing regions were in the northern parts of the Canadian prairies, specifically in the parkland belt, with the Peace River region (shared between Alberta and British Columbia) being the most important cluster, accounting for 14.4% of the national herd. Canada also exports bison meat, totaling in 2006.\nA proposal known as Buffalo Commons has been suggested by a handful of academics and policymakers to restore large parts of the drier portion of the Great Plains to native prairie grazed by bison. Proponents argue that current agricultural use of the shortgrass prairie is not sustainable, pointing to periodic disasters, including the Dust Bowl, and continuing significant human population loss over the last 60 years. However, this plan is opposed by some who live in the areas in question.\nDomestication.\nDespite being the closest relatives of domestic cattle native to North America, bison were never domesticated by Native Americans. Later attempts of domestication by Europeans prior to the 20th century met with limited success. Bison were described as having a \"wild and ungovernable temper\"; they can jump close to vertically, and run when agitated. This agility and speed, combined with their great size and weight, makes bison herds difficult to confine, as they can easily escape or destroy most fencing systems, including most razor wire. The most successful systems involve large, fences made from welded steel I beams sunk at least into concrete. These fencing systems, while expensive, require very little maintenance. Furthermore, making the fence sections overlap so the grassy areas beyond are not visible prevents the bison from trying to get to new range.\nAs a symbol.\nNative Americans.\nAmong many Native American tribes, especially the Plains Indians, the bison is considered a sacred animal and religious symbol. According to University of Montana anthropology and Native American studies professor S. Neyooxet Greymorning, \"The creation stories of where buffalo came from put them in a very spiritual place among many tribes. The buffalo crossed many different areas and functions, and it was utilized in many ways. It was used in ceremonies, as well as to make tipi covers that provided homes for people, utensils, shields, weapons and parts were used for sewing with the sinew.\" The Sioux consider the birth of a white buffalo to be the return of White Buffalo Calf Woman, their primary cultural prophet and the bringer of their \"Seven Sacred Rites\". Among the Mandan and Hidatsa, the White Buffalo Cow Society was the most sacred of societies for women.\nNorth America.\nThe American bison is often used in North America in official seals, flags, and logos. In 2016, the American bison became the national mammal of the United States. The bison is a popular symbol in the Great Plains states: Kansas, Oklahoma, and Wyoming have adopted the animal as their official state mammal, and many sports teams have chosen the bison as their mascot. In Canada, the bison is the official animal of the province of Manitoba and appears on the Manitoba flag. It is also used in the official coat of arms of the Royal Canadian Mounted Police.\nSeveral American coins feature the bison, most famously on the reverse side of the \"buffalo nickel\" from 1913 to 1938. In 2005, the United States Mint coined a nickel with a new depiction of the bison as part of its \"Westward Journey\" series. The Kansas and North Dakota state quarters, part of the \"50 State Quarter\" series, each feature bison. The Kansas state quarter has only the bison and does not feature any writing, while the North Dakota state quarter has two bison. The Montana state quarter prominently features a bison skull over a landscape. The Yellowstone National Park quarter also features a bison standing next to a geyser.\nOther institutions which have adopted the bison as a symbol or mascot include:\n", "categories": ["Category:All articles with unsourced statements", "Category:American frontier", "Category:Articles containing Arapaho-language text", "Category:Articles containing Lakota-language text", "Category:Articles containing video clips", "Category:Articles with 'species' microformats", "Category:Articles with BNF identifiers", "Category:Articles with BNFdata identifiers", "Category:Articles with J9U identifiers", "Category:Articles with LCCN identifiers"]}, {"docid": 49725, "title": "American bison", "text": "The American bison (: bison) (Bison bison), also called the American buffalo or simply buffalo (not to be confused with true buffalo), is a species of bison native to North America. It is one of two extant species of bison, alongside the European bison. Its historical range, by 9000 BC, is described as the great bison belt, a tract of rich grassland that ran from Alaska to the Gulf of Mexico, east to the Atlantic Seaboard (nearly to the Atlantic tidewater in some areas), as far north as New York, south to Georgia, and according to some sources, further south to Florida, with sightings in North Carolina near Buffalo Ford on the Catawba River as late as 1750. \nOnce roaming in vast herds, the species nearly became extinct by a combination of commercial hunting and slaughter in the 19th century and introduction of bovine diseases from domestic cattle. With a population of 60 million in the late 18th century, the species was culled down to just 541 animals by 1889 as part of the subjugation of the Native Americans, because the American bison was a major resource for their traditional way of life (food source, hides for clothing and shelter, and horns and bones for tools). Recovery efforts expanded in the mid-20th century, with a resurgence to roughly 31,000 wild bison as of March 2019. For many years, the population was primarily found in a few national parks and reserves. Through multiple reintroductions, the species now freely roams wild in several regions in the United States, Canada, and Mexico, with it also being introduced to Yakutia in Russia.\nTwo subspecies or ecotypes have been described: the plains bison (\"B. b. bison\"), smaller in size and with a more rounded hump, and the wood bison (\"B. b. athabascae\")\u2014the larger of the two and having a taller, square hump. Furthermore, the plains bison has been suggested to consist of a northern plains (\"B. b. montanae\") and a southern plains (\"B. b. bison\") subspecies, bringing the total to three. However, this is generally not supported. The wood bison is one of the largest wild species of extant bovid in the world, surpassed only by the Asian gaur. Among extant land animals in North America, the bison is the heaviest and the longest, and the second tallest after the moose.\nSpanning back millennia, Native American tribes have had cultural and spiritual connections to the American bison. It is the national mammal of the United States of America.\nEtymology.\nIn American English, both \"buffalo\" and \"bison\" are considered correct terms for the American bison. However in British English, the word \"buffalo\" is reserved for the African buffalo and water buffalo and not used for the bison.\nIn English usage, the term \"buffalo\" was used to refer to the American mammal as early as 1625. The word \"bison\" was applied in the 1690s.\n\"Buffalo\" was applied to the American bison by Samuel de Champlain as the French word \"buffles\" in 1616 (published 1619), after seeing skins and a drawing. These were shown to him by members of the Nipissing First Nation, who said they travelled forty days (from east of Lake Huron) to trade with another nation who hunted the animals. \"Buffel\" in turn comes from Portuguese \"bufalo\" (water buffalo), which comes from Latin \"bufalus\" (an antelope, gazelle, or wild ox), from Greek \"boubalos\". From the same Greek word \"boubalos\" we also get the Bubal hartebeest.\n\"Bison\" was borrowed from French \"bison\" in the early 1600s, from Latin \"bison\" (aurochs), from a Proto-Germanic word similar to wisent.\nIn Plains Indian languages in general, male and female bison are distinguished, with each having a different designation rather than there being a single generic word covering both sexes. Thus:\nSuch a distinction is not a general feature of the language (for example, Arapaho possesses gender-neutral terms for other large mammals such as elk, mule deer, etc.), and so presumably is due to the special significance of the bison in Plains Indian life and culture.\nDescription.\nA bison has a shaggy, long, dark-brown winter coat, and a lighter-weight, lighter-brown summer coat. Male bison are significantly larger and heavier than females. Plains bison are often in the smaller range of sizes, and wood bison in the larger range. Head-rump lengths at maximum up to for males and for females long and the tail adding . Heights at withers in the species can reach up to for \"B. b. bison\" and \"B. b. athabascae\" respectively. Typically weights can range from , with medians of (\"B.b. bison\") and (\"B.b.athabascae\") in males, and with medians of in females, although the lowest weights probably representing typical weight around the age of sexual maturity at 2 to 3 years of age. \nThe heaviest wild bull for \"B.b.bison\" ever recorded weighed while there had been bulls estimated to be . \"B.b.athabascae\" is significantly larger and heavier on average than \"B.b.bison\" while the number of recorded samples for the former was limited after the rediscovery of a relatively pure herd. Elk Island National Park, which has wild populations of both wood and plains bison, has recorded maximum weights for bull bison of 1186\u00a0kg (plains) and 1099\u00a0kg (wood), but noted that 3/4 of all bison over 1000\u00a0kg were wood bison. When raised in captivity and farmed for meat, the bison can grow unnaturally heavy and the largest semidomestic bison weighed . The heads and forequarters are massive, and both sexes have short, curved horns that can grow up to long with to width, which they use in fighting for status within the herd and for defense.\nBison are herbivores, grazing on the grasses and sedges of the North American prairies. Their daily schedule involves two-hour periods of grazing, resting, and cud chewing, then moving to a new location to graze again. Sexually mature young bulls may try to start mating with cows by the age of two or three years, but if more mature bulls are present, they may not be able to compete until they reach five years of age.\nFor the first two months of life, calves are lighter in color than mature bison. One extremely rare condition is the white buffalo, in which the calf turns entirely white.\nEvolution.\nBison are members of the tribe Bovini. Genetic evidence from nuclear DNA indicates that the closest living relatives of bison are yaks, with bison being nested within the genus \"Bos,\" rendering \"Bos\" without including bison paraphyletic. While nuclear DNA indicates that the two living bison species are each others closest living relatives, the mitochondrial DNA of European bison is more closely related to that of domestic cattle and aurochs, which is either suggested to be the result of incomplete lineage sorting or ancient introgression. Bison first appeared in Asia during the Early Pleistocene, around 2.6 million years ago. Bison only arrived in North America 195,000 to 135,000 years ago, during the late Middle Pleistocene, descending from the widespread Siberian steppe bison (\"Bison priscus\"), which had migrated through Beringia. Following its first appearance in North America, the bison rapidly differentiated into new species such as the largest of all bison, the long-horned \"Bison latifrons\" as well as \"Bison antiquus\". The first appearance of bison in North America is considered to define the regional Rancholabrean faunal stage, due to its major impact on the ecology of the continent. Modern American bison are thought to have evolved from \"B. antiquus\" during the Late Pleistocene-Holocene transition via the intermediate form \"Bison occidentalis\".\nDifferences from European bison.\nAlthough they are superficially similar, the American and European bison exhibit a number of physical and behavioral differences. Adult American bison are slightly heavier on average because of their less rangy build and have shorter legs, which render them slightly shorter at the shoulder. American bison tend to graze more and browse less than their European relatives because their necks are set differently. Compared to the nose of the American bison, that of the European species is set farther forward than the forehead when the neck is in a neutral position. The body of the American bison is hairier, though its tail has less hair than that of the European bison. The horns of the European bison point forward through the plane of its face, making it more adept at fighting through the interlocking of horns in the same manner as domestic cattle, unlike the American bison, which favors charging. American bison are more easily tamed than the European and breed more readily with domestic cattle.\nCrossbreeding with cattle.\nDuring the population bottleneck, after the great slaughter of American bison during the 1800s, the number of bison remaining alive in North America declined to as low as 541. During that period, a handful of ranchers gathered remnants of the existing herds to save the species from extinction. These ranchers bred some of the bison with cattle in an effort to produce \"cattalo\" or \"beefalo\". Accidental crossings were also known to occur. Generally, male domestic bulls were crossed with bison cows, producing offspring of which only the females were fertile. The crossbred animals did not demonstrate any form of hybrid vigor, so the practice was abandoned. The proportion of cattle DNA that has been measured in introgressed individuals and bison herds today is typically quite low, ranging from 0.56 to 1.8%. In the United States, many ranchers are now using DNA testing to cull the residual cattle genetics from their bison herds. The U.S. National Bison Association has adopted a code of ethics which prohibits its members from deliberately crossbreeding bison with any other species.\nRange and population.\nPopulation estimates in 2010 ranged from 400,000 to 500,000, with approximately 20,500 animals in 62 conservation herds and the remainder in approximately 6,400 commercial herds. According to the IUCN, roughly 15,000 bison are considered wild, free-range bison not primarily confined by fencing.\nThe Nature Conservancy (TNC) has reintroduced bison to over a dozen nature preserves around the United States. In October 2016, TNC established its easternmost bison herd in the country, at Kankakee Sands nature preserve in Morocco, Newton County, Indiana. In 2014, U.S Tribes and Canadian First Nations signed a treaty to help with the restoration of bison, the first to be signed in nearly 150 years.\nHabitat and trails.\nAmerican bison live in river valleys, and on prairies and plains. Typical habitat is open or semiopen grasslands, as well as sagebrush, semiarid lands, and scrublands. Some lightly wooded areas are also known historically to have supported bison. Bison also graze in hilly or mountainous areas where the slopes are not steep. Though not particularly known as high-altitude animals, bison in the Yellowstone Park bison herd are frequently found at elevations above and the Henry Mountains bison herd is found on the plains around the Henry Mountains, Utah, as well as in mountain valleys of the Henry Mountains to an altitude of . Reintroduced plains bison in Banff National Park have been observed to roam mountainous areas including high ridges and steep drainages, and archaeological finds indicate some bison historically may have spent their lives within mountains while others may have migrated in and out of mountains.\nThose in Yukon, Canada, typically summer in alpine plateaus above treeline. The first thoroughfares of North America, except for the time-obliterated paths of mastodon or muskox and the routes of the mound builders, were the traces made by bison and deer in seasonal migration and between feeding grounds and salt licks. Many of these routes, hammered by countless hoofs instinctively following watersheds and the crests of ridges in avoidance of lower places' summer muck and winter snowdrifts, were followed by the aboriginal North Americans as courses to hunting grounds and as warriors' paths. They were invaluable to explorers and were adopted by pioneers.\nBison traces were characteristically north and south, but several key east\u2013west trails were used later as railways. Some of these include the Cumberland Gap through the Blue Ridge Mountains to upper Kentucky. A heavily used trace crossed the Ohio River at the Falls of the Ohio and ran west, crossing the Wabash River near Vincennes, Indiana. In Senator Thomas Hart Benton's phrase saluting these sagacious path-makers, the bison paved the way for the railroads to the Pacific.\nMexico.\nThe southern extent of the historic range of the American bison includes northern Mexico and adjoining areas in the United States as documented by archeological records and historical accounts from Mexican archives from 700\u00a0CE to the 19th century. The Janos-Hidalgo bison herd has ranged between Chihuahua, Mexico, and New Mexico, United States, since at least the 1920s. The persistence of this herd suggests that habitat for bison is suitable in northern Mexico. In 2009, genetically pure bison were reintroduced to the Janos Biosphere Reserve in northern Chihuahua adding to the Mexican bison population. In 2020, the second herd was formed in Maderas del Carmen. A private reserve named Jag\u00fcey de Ferniza has kept bisons since before the above-mentioned reintroductions in Coahuila.\nIntroductions to Siberia.\nSince 2006, an outherd of wood bison sent from Alberta's Elk Island National Park was established in Yakutia, Russia as a practice of pleistocene rewilding; wood bison are the most closely related to the extinct bison species. The bison are adapting well to the cold climate, and Yakutia's Red List officially registered the species in 2019; a second herd was formed in 2020. \nIn Pleistocene Park, there are also 24 plains bison as wood bison could not be acquired.\nBehavior and ecology.\nBison are migratory and herd migrations can be directional as well as altitudinal in some areas. Bison have usual daily movements between foraging sites during the summer. In the Hayden Valley, Wyoming, bison have been recorded traveling, on average, per day. The summer ranges of bison appear to be influenced by seasonal vegetation changes, interspersion and size of foraging sites, the rut, and the number of biting insects. The size of preserve and availability of water may also be a factor. Bison are largely grazers, eating primarily grasses and sedges. On shortgrass pasture, bison predominately consume warm-season grasses. On mixed prairie, cool-season grasses, including some sedges, apparently compose 79\u201396% of their diet. In montane and northern areas, sedges are selected throughout the year. Bison also drink water or consume snow on a daily basis.\nSocial behavior and reproduction.\nFemale bison live in maternal herds which include other females and their offspring. Male offspring leave their maternal herd when around three years old and either live alone or join other males in bachelor herds. Male and female herds usually do not mingle until the breeding season, which can occur from July through September. However, female herds may also contain a few older males. During the breeding season, dominant bulls maintain a small harem of females for mating. Individual bulls \"tend\" cows until allowed to mate, by following them around and chasing away rival males. The tending bull shields the female's vision with his body so she will not see any other challenging males. A challenging bull may bellow or roar to get a female's attention and the tending bull has to bellow/roar back. The most dominant bulls mate in the first 2\u20133 weeks of the season. More subordinate bulls mate with any remaining estrous cow that has not mated yet. Male bison play no part in raising the young.\nBison herds have dominance hierarchies that exist for both males and females. A bison's dominance is related to its birth date. Bison born earlier in the breeding season are more likely to be larger and more dominant as adults. Thus, bison are able to pass on their dominance to their offspring as dominant bison breed earlier in the season. In addition to dominance, the older bison of a generation also have a higher fertility rate than the younger ones.\nBison mate in August and September; gestation is 285 days. A single reddish-brown calf nurses until the next calf is born. If the cow is not pregnant, a calf will nurse for 18 months. Cows nurse their calves for at least 7 or 8 months, but most calves seem to be weaned before the end of their first year. At three years of age, bison cows are mature enough to produce a calf. The birthing period for bison in boreal biomes is protracted compared to that of other northern ungulates, such as moose and caribou.\nBison have a life expectancy around 15 years in the wild and up to 25 years in captivity. However, males and females from a hunted population also subject to wolf predation in northern Canada have been reported to live to 22 and 25 years of age, respectively.\nBison have been observed to display homosexual behaviors, males much more so than females. In the case of males, it is unlikely to be related to dominance, but rather to social bonding or gaining sexual experience.\nHorning.\nBison mate in late spring and summer in more open plain areas. During fall and winter, bison tend to gather in more wooded areas. During this time, bison partake in horning behaviors. They rub their horns against trees, young saplings, and even utility poles. Aromatic trees like cedars and pine seem to be preferred. Horning appears to be associated with insect defense, as it occurs most often in the fall when the insect population is at its highest. Cedar and pines emit an aroma after bison horn them and this seems to be used as a deterrent for insects.\nWallowing behavior.\nA bison wallow is a shallow depression in the soil, which bison use either wet or dry. Bison roll in these depressions, covering themselves with dust or mud. Past and current hypotheses to explain the purpose of wallowing include grooming associated with shedding, male-male interaction (typically rutting), social behavior for group cohesion, play, relief from skin irritation due to biting insects, reduction of ectoparasite (tick and lice) load, and thermoregulation. Bison wallowing has important ecosystem engineering effects and enhances plant and animal diversity on prairies.\nPredation.\nWhile often secure from predation because of their size and strength, in some areas, vulnerable individuals are regularly preyed upon by wolves. Wolf predation typically peaks in late winter, when elk migrates south and bison are distressed with heavy snows and shortages of food sources, with attacks usually being concentrated on weakened and injured cows and calves. Wolves more actively target herds with calves than those without. The length of a predation episode varies, ranging from a few minutes to over nine hours. Bison display five apparent defense strategies in protecting calves from wolves: running to a cow; running to a herd; running to the nearest bull; running in the front or center of a stampeding herd; entering water bodies, such as lakes or rivers. When fleeing wolves in open areas, cows with young calves take the lead, while bulls take to the rear of the herds to guard the cows' escape. Bison typically ignore wolves not displaying hunting behavior. Wolf packs specializing in bison tend to have more males because their larger size than females allows them to wrestle prey to the ground more effectively. Healthy, mature bulls in herds rarely fall prey.\nGrizzly bears are known to feed on carcass and may steal wolves' kills. While grizzlies can also pose a threat to calves and sometimes old, injured, or sick adult bison, direct killing of non-calves is rare even when targeting lone and injured young individuals; attacking healthy bison is risky for bears, who can be killed instead.\nDangers to humans.\nBison are among the most dangerous animals encountered by visitors to the various North American national parks and will attack humans if provoked. They appear slow because of their lethargic movements but can easily outrun humans; bison have been observed running as fast as for . Bison may approach people for curiosity. Close encounters, including to touch the animals, can be dangerous, and gunshots do not startle them.\nBetween 1980 and 1999, more than three times as many people in Yellowstone National Park were injured by bison than by bears. During this period, bison charged and injured 79 people, with injuries ranging from goring puncture wounds and broken bones to bruises and abrasions. Bears injured 24 people during the same time. Three people died from the injuries inflicted\u2014one person by bison in 1983, and two people by bears in 1984 and 1986.\nGenetics.\nA major problem that bison face today is a lack of genetic diversity due to the population bottleneck the species experienced during its near-extinction event. Another genetic issue is the entry of genes from domestic cattle into the bison population, through hybridization.\nOfficially, the \"American buffalo\" is classified by the United States government as a type of cattle, and the government allows private herds to be managed as such. This is a reflection of the characteristics that bison share with cattle. Though the American bison is a separate species and usually regarded as being in a separate genus from domestic cattle (\"Bos taurus\"), they have a lot of genetic compatibility with cattle. American bison can interbreed with cattle, although only the female offspring are fertile in the first generation. These female hybrids can be bred back to either bison or domestic bulls, resulting in either 1/4 or 3/4 bison young. Female offspring from this cross are also fertile, but males are not reliably fertile unless they are either bison or domestic. Moreover, when they do interbreed, crossbreed animals in the first generation tend to look very much like purebred bison, so appearance is completely unreliable as a means of determining what is a purebred bison and what is a crossbred cow. Many ranchers have deliberately crossbred their cattle with bison, and some natural hybridization could be expected in areas where cattle and bison occur in the same range. Since cattle and bison eat similar food and tolerate similar conditions, they have often been in the same range together in the past, and opportunity for crossbreeding may sometimes have been common.\nIn recent decades, tests were developed to determine the source of mitochondrial DNA in cattle and bison, and most private \"buffalo\" herds were actually crossbred with cattle, and even most state and federal buffalo herds had some cattle DNA. With the advent of nuclear microsatellite DNA testing, the number of herds known to contain cattle genes has increased. As of 2011, though about 500,000 bison existed on private ranches and in public herds, perhaps only 15,000 to 25,000 of these bison were pure and not actually bison-cattle hybrids. DNA from domestic cattle (\"Bos taurus\") has been found in almost all examined bison herds. \nSignificant public bison herds that do not appear to have hybridized domestic cattle genes are the Yellowstone Park bison herd, the Henry Mountains bison herd, which was started with bison taken from Yellowstone Park, the Wind Cave bison herd, and the Wood Buffalo National Park bison herd and subsidiary herds started from it, in Canada.\nA landmark study of bison genetics performed by James Derr of Texas A&M University corroborated this. The Derr study was undertaken in an attempt to determine what genetic problems bison might face as they repopulate former areas, and it noted that bison seem to be adapting successfully, despite their apparent genetic bottleneck. One possible explanation for this might be the small amount of domestic cattle genes that are now in most bison populations, though this is not the only possible explanation for bison success.\nIn the study, cattle genes were also found in small amounts throughout most national, state, and private herds. \"The hybridization experiments conducted by some of the owners of the five foundation herds of the late 1800s, have left a legacy of a small amount of cattle genetics in many of our existing bison herds,\" said Derr. \"All of the state owned bison herds tested (except for possibly one) contain animals with domestic cattle mtDNA.\" \nIt appears that the one state herd that had no cattle genes was the Henry Mountains bison herd; the Henry Mountain herd was started initially with transplanted animals from Yellowstone Park. However, the extension of this herd into the Book Cliffs of central Utah involved mixing the founders with additional bison from another source, so it is not known if the Book Cliffs extension of the herd is also free of cattle hybridization.\nA separate study by Wilson and Strobeck, published in \"Genome\", was done to define the relationships between different herds of bison in the United States and Canada, and to determine whether the bison at Wood Buffalo National Park in Canada and the Yellowstone Park bison herd were possibly separate subspecies. The Wood Buffalo Park bison were determined to actually be crossbreeds between plains and wood bison, but their predominant genetic makeup was that of the expected \"wood buffalo\". However, the Yellowstone Park bison herd was pure plains bison, and not any of the other previously suggested subspecies. Another finding was that the bison in the Antelope Island herd in Utah appeared to be more distantly related to other plains bison in general than any other plains bison group that was tested, though this might be due to genetic drift caused by the small size of only 12 individuals in the founder population. A side finding of this was that the Antelope Island bison herd appears to be most closely related to the Wood Buffalo National Park bison herd, though the Antelope Island bison are actually plains bison.\nIn order to bolster the genetic diversity of the American bison, the National Park Service alongside the Department of the Interior announced on May 7, 2020, the 2020 Bison Conservation Initiative. This initiative focuses on maintaining the genetic diversity of the metapopulation rather than individual herds. Small populations of bison are at considerably larger risk due to their decreased gene pool and are susceptible to catastrophic events more so than larger herds. The 2020 Bison Conservation Initiative aims to translocate up to three bison every five to ten years between the Department of the Interior's herds. Specific smaller herds will require a more intense management plan. Translocated bison will also be screened for any health defects such as infection of brucellosis bacteria as to not put the larger herd at risk.\nPopulation bottlenecking.\nBecause of the mass slaughtering of bison during the 1870s, the plains bison population went through a population bottleneck from an estimated 60 million individuals\u2013an estimation based on an observation made by Colonel R.I. Dodge along the Arkansas River in Kansas in 1871\u2013to a founding population of around 100 individuals, split into six herds, five of which were managed by private ranchers and one managed by the New York Zoological Park (now the Bronx Zoo). Additionally, a wild herd consisting of 25 individuals in Yellowstone National Park survived the bottleneck.\nEach of the privately ranched herds had an initial effective population size (Ne) of an estimated 5 to 7 individuals, for a total combined effective population size of between 30 and 50 individuals, from which all of the modern plains bison descend. While these herds have remained mostly isolated, some more than others, there has been some interbreeding between the herds over the past 150 years.\nThe conservation efforts and copious amounts of data taken on American bison populations allow for American bison to serve as a useful study case of population bottlenecking and its effects. This is especially true of the Texas State Bison Herd, which underwent very extreme genetic bottlenecking, with a founding population of only 5 individuals.\nTexas State Bison Herd.\nThe Texas State Bison Herd (TSBH), also known as the Goodnight herd, was established by Charles Goodnight in the mid-1880s with five wild-caught calves. In 1887, the herd consisted of 13 individuals; in 1910, the population consisted of 125 individuals; and in the 1920s, the population ranged from 200-250 individuals. In 1929, Goodnight died and the herd switched hands multiple times, leaving the population of the herd unknown from 1930 until the herd was donated to the State of Texas in 1997, with a population of 36 individuals, solely descended from the original five calves. By 2002, the population of the TSBH consisted of 40 individuals and had concerningly low birth rates and high rates of calf mortality. This led to extra attention being given to this herd by conservationists who then performed significant amounts of genetic testing.\nIt is also crucial to mention that Goodnight was an advocate for the hybridization of bison with cattle, in the hopes creating a stronger and healthier breed. When the herd was donated to the State of Texas in 1997, genetic testing revealed that 6 out of 36 individuals still carried cattle mitochondrial DNA.\nResearchers found that the average number of alleles per locus and the heterozygosity levels (a measure of genetic diversity, where high heterozygosity is representative of high genetic diversity) for the TSBH were significantly lower than that of the Yellowstone National Park bison population and the Theodore Roosevelt National Park bison population. Additionally, of the 54 nuclear microsatellites that were examined, the TSBH had 8 monomorphic loci (i.e., each loci had only one allele), whereas in both the Yellowstone and Theodore Roosevelt herds there was only one monomorphic locus, indicating a much lower level of genetic diversity in the TSBH. The Yellowstone herd had an average number of alleles per locus of 4.75, the Theodore Roosevelt National Park herd had an average of 4.15 alleles per locus, but the TSBH only had an average of 2.54 alleles per locus, statistically significantly lower than the others. The heterozygosity level of the Yellowstone, Theodore Roosevelt, and TSBH populations were 0.63, 0.57, and 0.38 respectively, with the TSBH again having a statistically significantly lower value. This low genetic diversity found in TSBH is likely due to the critically low starting population, several additional bottlenecks throughout the herd\u2019s history\u2013leading to inbreeding depression\u2013, and a continuously low population allowing for genetic drift to have a large effect. Before any addition of new individuals, the rate of loss of genetic diversity was estimated to be between 30-40% over the proceeding 50 years.\nThe inbreeding depression resulting from the multiple extreme population bottlenecks in the TSBH led to a coefficient of inbreeding of 0.367, equal to the level of inbreeding that results from two generations of full-siblings mating.\nThe Texas State Bison Herd is also a useful example of the deleterious effects of extreme population bottlenecking, with an average natality rate of 0.376 offspring per female and a 1st-year mortality rate of 52.6% from 1997 to 2002, compared to an average natality rate of 0.560 offspring per female and a 1st-year mortality rate of 4.2% for the other bison herds.\nAdditionally, if it were not for the intervention of conservationists, the Texas State Bison Herd would have most likely gone extinct, as the population bottleneck would have proven to be too severe. Multiple population models based on the genetics of the TSBH in the early 2000s predicted a 99% chance of extinction of the TSBH in less than 50 years, with an estimation in 2004 giving the TSBH a 99% chance of extinction in 41 years without the introduction of any outside individuals (Halbert et al. 2004). Importantly for conservation, another simulation predicted that the addition of multiple (3-9) outside male bison into the herd would increase genetic diversity enough to give the herd a 100% chance of surviving for another 100 years.\nConservation efforts have led the current TSBH population to be at the carrying capacity of their habitat, at around 300 individuals. \nYellowstone National Park Bison Herd.\nThe Yellowstone National Park Bison herd started with only 25 individuals, and there was evidence of two population bottlenecking events from 1896-1912, with a population ranging between 25 and 50 individuals during this time. In 1902, 18 female and 3 male bison from outside herds\u2013the Pablo-Allard herd and Goodnight (TSBH) herds respectively\u2013were introduced to the Yellowstone herd. After the addition of those individuals, the effective population size is estimated to have been Ne=7.2 individuals. The Yellowstone herd was kept completely isolated from 1902 to around 1920, and these previously mentioned founders contributed between 60-70% of the genetics of the current bison population at Yellowstone. \nSimilar to the Texas State Bison Herd, the introduction of new individuals into the population in 1902 likely was the savior of this herd, which now numbers around 5,900 individuals as of summer 2022.\nHunting.\nBuffalo hunting, i.e. hunting of the American bison, was an activity fundamental to the Indigenous peoples of the Great Plains, providing more than 150 uses for all parts of the animal, including being a major food source, hides for clothing and shelter, bones and horns as tools as well as ceremonial and adornment uses. Bison hunting was later adopted by American professional hunters, as well as by the U.S. government, in an effort to sabotage the central resource of some American Indian Nations during the later portions of the American Indian Wars, leading to the near-extinction of the species around 1890. For many tribes the buffalo was an integral part of life\u2014something guaranteed to them by the Creator. In fact, for some Plains indigenous peoples, bison are known as the first people. The concept of species extinction was foreign to many tribes. \nThus, when the U.S. government began to massacre the buffalo, it was particularly harrowing to the Indigenous people. As Crow chief Plenty Coups described it: \"When the buffalo went away the hearts of my people fell to the ground, and they could not lift them up again. After this nothing happened. There was little singing anywhere.\" Spiritual loss was rampant; bison were an integral part of traditional tribal societies, and they would frequently take part in ceremonies for each bison they killed to honor its sacrifice. In order to boost morale during this time, Sioux and other tribes took part in the Ghost Dance, which consisted of hundreds of people dancing until 100 persons were lying unconscious.\nToday, many conservation measures have been taken by Native Americans, with the Inter Tribal Bison Council being one of the most significant. It was formed in 1990, composed of 56 tribes in 19 states. These tribes represent a collective herd of more than 15,000 bison and focus on reestablishing herds on tribal lands in order to promote culture, revitalize spiritual solidarity, and restore the ecosystem. Some Inter Tribal Bison Council members argue that the bison's economic value is one of the main factors driving its resurgence. Bison serve as a low cost substitute for cattle, and can withstand the winters in the Plains region far easier than cattle.\nAs livestock.\nBison are increasingly raised for meat, hide, wool, and dairy products. The majority of American bison in the world are raised for human consumption or fur clothing. Bison meat is generally considered to taste very similar to beef, but is lower in fat and cholesterol, yet higher in protein than beef, which has led to the development of beefalo, a fertile hybrid of bison and domestic cattle. In 2005, about 35,000 bison were processed for meat in the U.S., with the National Bison Association and USDA providing a \"Certified American Buffalo\" program with birth-to-consumer tracking of bison via RFID ear tags. A market even exists for kosher bison meat; these bison are slaughtered at one of the few kosher mammal slaughterhouses in the U.S., and the meat is then distributed nationwide.\nBison are found in publicly and privately held herds. Custer State Park in South Dakota is home to 1,500 bison, one of the largest publicly held herds in the world, but some question the genetic purity of the animals. Wildlife officials believe that free roaming herds with minimal cattle introgression on public lands in North America can be found only in: the Yellowstone Park bison herd; the Henry Mountains bison herd at the Book Cliffs and Henry Mountains in Utah; at Wind Cave National Park in South Dakota; Fort Peck Indian Reservation in Montana; Mackenzie Bison Sanctuary in the Northwest Territories; Elk Island National Park and Wood Buffalo National Park in Alberta; Grasslands National Park and Prince Albert National Park in Saskatchewan. Another population, the Antelope Island bison herd on Antelope Island in Utah, consisting of 550 to 700 bison, is also one of the largest and oldest public herds in the United States, but the bison in that herd are considered to be only semifree roaming, since they are confined to the Antelope Island. In addition, recent genetic studies indicate that, like most bison herds, the Antelope Island bison herd has a small number of genes from domestic cattle. In 2002, the United States government donated some bison calves from South Dakota and Colorado to the Mexican government. Their descendants live in the Mexican nature reserves El Uno Ranch at Janos and Santa Elena Canyon, Chihuahua, and Boquillas del Carmen, Coahuila, located near the southern banks of the Rio Grande, and around the grassland state line with Texas and New Mexico.\nRecent genetic studies of privately owned herds of bison show that many of them include animals with genes from domestic cattle. For example, the herd on Santa Catalina Island, California, isolated since 1924 after being brought there for a movie shoot, were found to have cattle introgression. As few as 12,000 to 15,000 pure bison are estimated to remain in the world. The numbers are uncertain because the tests used to date\u2014mitochondrial DNA analysis\u2014indicate only if the maternal line (back from mother to mother) ever included domesticated bovines, thus say nothing about possible male input in the process. Most hybrids were found to look exactly like purebred bison; therefore, appearance is not a good indicator of genetics.\nThe size of the Canadian domesticated herd (genetic questions aside) grew dramatically through the 1990s and 2000s. The 2006 Census of Agriculture reported the Canadian herd at 195,728 head, a 34.9% increase since 2001. Of this total, over 95% were located in Western Canada, and less than 5% in Eastern Canada. Alberta was the province with the largest herd, accounting for 49.7% of the herd and 45.8% of the farms. The next-largest herds were in Saskatchewan (23.9%), Manitoba (10%), and British Columbia (6%). The main producing regions were in the northern parts of the Canadian prairies, specifically in the parkland belt, with the Peace River region (shared between Alberta and British Columbia) being the most important cluster, accounting for 14.4% of the national herd. Canada also exports bison meat, totaling in 2006.\nA proposal known as Buffalo Commons has been suggested by a handful of academics and policymakers to restore large parts of the drier portion of the Great Plains to native prairie grazed by bison. Proponents argue that current agricultural use of the shortgrass prairie is not sustainable, pointing to periodic disasters, including the Dust Bowl, and continuing significant human population loss over the last 60 years. However, this plan is opposed by some who live in the areas in question.\nDomestication.\nDespite being the closest relatives of domestic cattle native to North America, bison were never domesticated by Native Americans. Later attempts of domestication by Europeans prior to the 20th century met with limited success. Bison were described as having a \"wild and ungovernable temper\"; they can jump close to vertically, and run when agitated. This agility and speed, combined with their great size and weight, makes bison herds difficult to confine, as they can easily escape or destroy most fencing systems, including most razor wire. The most successful systems involve large, fences made from welded steel I beams sunk at least into concrete. These fencing systems, while expensive, require very little maintenance. Furthermore, making the fence sections overlap so the grassy areas beyond are not visible prevents the bison from trying to get to new range.\nAs a symbol.\nNative Americans.\nAmong many Native American tribes, especially the Plains Indians, the bison is considered a sacred animal and religious symbol. According to University of Montana anthropology and Native American studies professor S. Neyooxet Greymorning, \"The creation stories of where buffalo came from put them in a very spiritual place among many tribes. The buffalo crossed many different areas and functions, and it was utilized in many ways. It was used in ceremonies, as well as to make tipi covers that provided homes for people, utensils, shields, weapons and parts were used for sewing with the sinew.\" The Sioux consider the birth of a white buffalo to be the return of White Buffalo Calf Woman, their primary cultural prophet and the bringer of their \"Seven Sacred Rites\". Among the Mandan and Hidatsa, the White Buffalo Cow Society was the most sacred of societies for women.\nNorth America.\nThe American bison is often used in North America in official seals, flags, and logos. In 2016, the American bison became the national mammal of the United States. The bison is a popular symbol in the Great Plains states: Kansas, Oklahoma, and Wyoming have adopted the animal as their official state mammal, and many sports teams have chosen the bison as their mascot. In Canada, the bison is the official animal of the province of Manitoba and appears on the Manitoba flag. It is also used in the official coat of arms of the Royal Canadian Mounted Police.\nSeveral American coins feature the bison, most famously on the reverse side of the \"buffalo nickel\" from 1913 to 1938. In 2005, the United States Mint coined a nickel with a new depiction of the bison as part of its \"Westward Journey\" series. The Kansas and North Dakota state quarters, part of the \"50 State Quarter\" series, each feature bison. The Kansas state quarter has only the bison and does not feature any writing, while the North Dakota state quarter has two bison. The Montana state quarter prominently features a bison skull over a landscape. The Yellowstone National Park quarter also features a bison standing next to a geyser.\nOther institutions which have adopted the bison as a symbol or mascot include:\n", "categories": ["Category:All articles with unsourced statements", "Category:American frontier", "Category:Articles containing Arapaho-language text", "Category:Articles containing Lakota-language text", "Category:Articles containing video clips", "Category:Articles with 'species' microformats", "Category:Articles with BNF identifiers", "Category:Articles with BNFdata identifiers", "Category:Articles with J9U identifiers", "Category:Articles with LCCN identifiers"]}, {"docid": 15295535, "title": "Snow leopard", "text": "The snow leopard (Panthera uncia), commonly known as the ounce, is a species of large cat in the genus \"Panthera\" of the family Felidae. The species is native to the mountain ranges of Central and South Asia. It is listed as Vulnerable on the IUCN Red List because the global population is estimated to number fewer than 10,000 mature individuals and is expected to decline about 10% by 2040. It is mainly threatened by poaching and habitat destruction following infrastructural developments. It inhabits alpine and subalpine zones at elevations of , ranging from eastern Afghanistan, the Himalayas and the Tibetan Plateau to southern Siberia, Mongolia and western China. In the northern part of its range, it also lives at lower elevations.\nTaxonomically, the snow leopard was long classified in the monotypic genus \"Uncia\". Since phylogenetic studies revealed the relationships among \"Panthera\" species, it has since been considered a member of that genus. Two subspecies were described based on morphological differences, but genetic differences between the two have not yet been confirmed. It is therefore regarded as a monotypic species. The species is widely depicted in Kyrgyz culture.\nNaming and etymology.\nThe Old French word once, which was intended to be used for the Eurasian lynx (\"Lynx lynx\"), is where the Latin name \"uncia\" and the English word ounce both originate. Once is believed to have originated from a previous form of the word \"lynx\" through a process known as false splitting. The word once was originally considered to be pronounced as \"l'once\", where \"l\"' stands for the elided form of the word \"la\" ('the') in French. Once was then understood to be the name of the animal.\nThe word \"panther\" derives from the classical Latin \"panth\u0113ra\", itself from the ancient Greek \u03c0\u03ac\u03bd\u03b8\u03b7\u03c1 \"p\u00e1nth\u0113r\", which was used for spotted cats.\nTaxonomy and evolution.\n\"Felis uncia\" was the scientific name used by Johann Christian Daniel von Schreber in 1777 who described a snow leopard based on an earlier description by Georges-Louis Leclerc, Comte de Buffon, assuming that the cat occurred along the Barbary Coast, in Persia, East India and China. The genus name \"Uncia\" was proposed by John Edward Gray in 1854 for Asian cats with a long and thick tail. \"Felis irbis,\" proposed by Christian Gottfried Ehrenberg in 1830, was a skin of a female snow leopard collected in the Altai Mountains. He also clarified that several leopard (\"P. pardus\") skins were previously misidentified as snow leopard skins. \"Felis uncioides\" proposed by Thomas Horsfield in 1855 was a snow leopard skin from Nepal in the collection of the Museum of the East India Company.\n\"Uncia uncia\" was used by Reginald Innes Pocock in 1930 when he reviewed skins and skulls of \"Panthera\" species from Asia. He also described morphological differences between snow leopard and leopard skins.\n\"Panthera baikalensis-romanii\" proposed by a Russian scientist in 2000 was a dark brown snow leopard skin from the Petrovsk-Zabaykalsky District in southern Transbaikal.\nThe snow leopard was long classified in the monotypic genus \"Uncia\".\nThey were subordinated to the genus \"Panthera\" based on results of phylogenetic studies.\nUntil spring 2017, there was no evidence available for the recognition of subspecies. Results of a phylogeographic analysis indicate that three subspecies should be recognised: \nThis view has been both contested and supported by different researchers.\nAdditionally, an extinct subspecies \"Panthera uncia pyrenaica\" was described in 2022 based on material found in France.\nEvolution.\nBased on the phylogenetic analysis of the DNA sequence sampled across the living Felidae, the snow leopard forms a sister group with the tiger (\"P. tigris\"). The genetic divergence time of this group is estimated at . The snow leopard and the tiger probably diverged between . \"Panthera\" originates most likely in northern Central Asia. \"Panthera blytheae\" excavated in western Tibet's Ngari Prefecture is the oldest known \"Panthera\" species and exhibits skull characteristics similar to the snow leopard.\nThe mitochondrial genomes of the snow leopard, the leopard and the lion (\"P. leo\") are more similar to each other than their nuclear genomes, indicating that their ancestors hybridised at some point in their evolution.\nCharacteristics.\nThe snow leopard's fur is whitish to grey with black spots on the head and neck, with larger rosettes on the back, flanks and bushy tail. Its muzzle is short, its forehead domed, and its nasal cavities are large. The fur is thick with hairs measuring in length, and its underbelly is whitish. They are stocky, short-legged, and slightly smaller than other cats of the genus \"Panthera\", reaching a shoulder height of , and ranging in head to body size from . Its tail is long. Males average , and females . Occasionally, large males reaching have been recorded, and small females under .\nIts canine teeth are long and are more slender than those of the other \"Panthera\" species.\nIn relation to the length of their skull and width of their palate, they have large nasal openings, which allow for increasing the volume of air inhaled with each breath, and at the same time for warming and humidifying cold dry air. They are not especially adapted to high-altitude hypoxia.\nThe snow leopard shows several adaptations for living in a cold, mountainous environments. Its small rounded ears help to minimize heat loss. Their broad paws well distribute the body weight for walking on snow, and have fur on their undersides to enhance the grip on steep and unstable surfaces; they also help to minimize heat loss. Its long and flexible tail helps to balance the cat in the rocky terrain. The tail is very thick due to fat storage, and is covered in a thick layer of fur, which allows the cat to use it like a blanket to protect its face when asleep.\nThe snow leopard differs from the other \"Panthera\" species by a shorter muzzle, an elevated forehead, a vertical chin and a less developed posterior process of the lower jaw. They cannot roar despite its partly ossified hyoid bone, as their short vocal folds provide little resistance to airflow.\nDistribution and habitat.\nThe snow leopard is distributed from the west of Lake Baikal through southern Siberia, in the Kunlun Mountains, Altai Mountains, Sayan and Tannu-Ola Mountains, in the Tian Shan, through Tajikistan, Kyrgyzstan, Uzbekistan and Kazakhstan to the Hindu Kush in eastern Afghanistan, Karakoram in northern Pakistan, in the Pamir Mountains, the Tibetan Plateau and in the high elevations of the Himalayas in India, Nepal and Bhutan. In Mongolia, they inhabit the Mongolian and Gobi Altai Mountains and the Khangai Mountains. In Tibet, they occur up to the Altyn-Tagh in the north.\nThey inhabit alpine and subalpine zones at elevations of , but also lives at lower elevations in the northern part of their range.\nPotential snow leopard habitat in the Indian Himalayas is estimated at less than in Jammu and Kashmir, Ladakh, Uttarakhand, Himachal Pradesh, Sikkim and Arunachal Pradesh, of which about is considered good habitat, and 14.4% is protected. In the beginning of the 1990s, the Indian snow leopard population was estimated at 200\u2013600 individuals living across about 25 protected areas.\nIn summer, the snow leopard usually lives above the tree line on alpine meadows and in rocky regions at elevations of . In winter, they descend to elevations around . They prefer rocky, broken terrain, and can move in deep snow, but prefers to use existing trails made by other animals.\nSnow leopards were recorded by camera traps at 16 locations in northeastern Afghanistan's isolated Wakhan Corridor.\nBehavior and ecology.\nThe snow leopard's vocalizations include meowing, grunting, prusten and moaning. They can purr when exhaling.\nIt is solitary and mostly active at dawn till early morning, and again in afternoons and early evenings. They mostly rest near cliffs and ridges that provide vantage points and shade. In Nepal's Shey Phoksundo National Park, the home ranges of five adult radio-collared snow leopards largely overlapped, though they rarely met. Their individual home ranges ranged from . Males moved between per day, and females between , measured in straight lines between survey points. Since they often zigzagged in the precipitous terrain, they actually moved up to in a single night.\nUp to 10 individuals inhabit an area of ; in habitats with sparse prey, an area of usually supports only five individuals.\nA study in the Gobi Desert from 2008 to 2014 revealed that adult males used a mean home range of , while adult females ranged in areas of . Their home ranges overlapped less than 20%. These results indicate that about 40% of the 170 protected areas in their range countries are smaller than the home range of a single male snow leopard.\nSnow leopards leave scent marks to indicate their territories and common travel routes. They scrape the ground with the hind feet before depositing urine or feces, but also spray urine onto rocks. Their urine contains many characteristic low molecular weight compounds with diverse functional groups including pentanol, hexanol, heptanol, 3-octanone, nonanal and indole, which possibly play a role in chemical communication.\nHunting and diet.\nThe snow leopard is a carnivore and actively hunts its prey. Its preferred wild prey species are Himalayan blue sheep (\"Pseudois nayaur\"), Himalayan tahr (\"Hemitragus jemlahicus\"), argali (\"Ovis ammon\"), markhor (\"Capra falconeri\") and wild goat (\"C. aegagrus\"). They also prey on domestic livestock. They prefer prey ranging in weight from , but also hunts smaller mammals such as Himalayan marmot (\"Marmota himalayana\"), pika and vole species. Its diet depends on prey availability and varies across its range and season. In the Himalayas, it preys mostly on Himalayan blue sheep, Siberian ibex (\"C. sibirica\"), white-bellied musk deer (\"Moschus leucogaster\") and wild boar (\"Sus scrofa\"). In the Karakoram, Tian Shan, Altai and Mongolia's Tost Mountains, its main prey consists of Siberian ibex, Thorold's deer (\"Cervus albirostris\"), Siberian roe deer (\"Capreolus pygargus\") and argali. Snow leopard feces collected in northern Pakistan also contained remains of rhesus macaque (\"Macaca mulatta\"), masked palm civet (\"Paguma larvata\"), Cape hare (\"Lepus capensis\"), house mouse (\"Mus musculus\"), Kashmir field mouse (\"Apodemus rusiges\"), grey dwarf hamster (\"Cricetulus migratorius\") and Turkestan rat (\"Rattus pyctoris\"). In 2017, a snow leopard was photographed carrying a freshly killed woolly flying squirrel (\"Eupetaurus cinereus\") near Gangotri National Park. In Mongolia, domestic sheep comprises less than 20% of its diet, although wild prey has been reduced and interactions with people are common.\nSnow leopards actively pursue prey down steep mountainsides, using the momentum of their initial leap to chase animals for up to . They drag the prey to a safe location and consume all edible parts of the carcass. They can survive on a single Himalayan blue sheep for two weeks before hunting again, and one adult individual apparently needs 20\u201330 adult blue sheep per year. Snow leopards have been recorded to hunt successfully in pairs, especially mating pairs.\nThe snow leopard is capable of killing most animals in its range, with the probable exception of the adult male yak. They also eat a significant amount of vegetation, including grass and twigs. They have not been reported to attack humans, and is easily driven away from livestock and readily abandons kills, often without defending themselves.\nReproduction and life cycle.\nSnow leopards become sexually mature at two to three years, and normally live for 15\u201318 years in the wild. In captivity they can live for up to 25 years. Oestrus typically lasts five to eight days, and males tend not to seek out another partner after mating, probably because the short mating season does not allow sufficient time. Paired snow leopards mate in the usual felid posture, from 12 to 36 times a day. They are unusual among large cats in that they have a well-defined birth peak. They usually mate in late winter, marked by a noticeable increase in marking and calling. Females have a gestation period of 90\u2013100 days, and the cubs are born between April and June. \nA litter usually consists of two to three cubs, in exceptional cases there can be up to seven.\nThe female gives birth in a rocky den or crevice lined with fur shed from her underside. The cubs are born blind and helpless, although already with a thick coat of fur, and weigh . Their eyes open at around seven days, and the cubs can walk at five weeks and are fully weaned by 10 weeks. The cubs leave the den when they are around two to four months of age. Three radio-collared snow leopards in Mongolia's Tost Mountains gave birth between late April and late June. Two female cubs started to part from their mothers at the age of 20 to 21 months, but reunited with them several times for a few days over a period of 4\u20137 months. One male cub separated from its mother at the age of about 22 months, but stayed in her vicinity for a month and moved out of his natal range at 23 months of age.\nThe snow leopard has a generation length of eight years.\nThreats.\nMajor threats to the population include poaching and illegal trade of its skins and body parts. Between 1999 and 2002, three live snow leopard cubs and 16 skins were confiscated, 330 traps were destroyed and 110 poachers were arrested in Kyrgyzstan. Undercover operations in the country revealed an illegal trade network with links to Russia and China via Kazakhstan. The major skin trade center in the region is the city of Kashgar in Xinjiang. In Tibet and Mongolia, skins are used for traditional dresses, and meat in traditional Tibetan medicine to cure kidney problems; bones are used in traditional Chinese and Mongolian medicine for treating rheumatism, injuries and pain of human bones and tendons. Between 1996 and 2002, 37 skins were found in wildlife markets and tourist shops in Mongolia. Between 2003 and 2016, 710 skins were traded, of which 288 skins were confiscated. In China, an estimated 103 to 236 animals are poached every year, in Mongolia between 34 and 53, in Pakistan between 23 and 53, in India from 21 to 45, and in Tajikistan 20 to 25. In 2016, a survey of Chinese websites revealed 15 advertisements for 44 snow leopard products; the dealers offered skins, canine teeth, claws and a tongue. In September 2014, nine snow leopard skins were found during a market survey in Afghanistan.\nGreenhouse gas emissions will likely cause a shift of the treeline in the Himalayas and a shrinking of the alpine zone, which may reduce snow leopard habitat by an estimate 30%.\nWhere snow leopards prey on domestic livestock, they are subject to human\u2013wildlife conflict. \nThe loss of natural prey due to overgrazing by livestock, poaching, and defense of livestock are the major drivers for the ever decreasing snow leopard population. Livestock also cause habitat degradation, which, alongside the increasing use of forests for fuel, reduces snow leopard habitat.\nConservation.\nThe snow leopard is listed in CITES Appendix I. They have been listed as threatened with extinction in Schedule I of the Convention on the Conservation of Migratory Species of Wild Animals since 1985.\nHunting snow leopards has been prohibited in Kyrgyzstan since the 1950s. In India, the snow leopard is granted the highest level of protection under the Wildlife Protection Act, 1972, and hunting is sentenced with imprisonment of 3\u20137 years. In Nepal, they have been legally protected since 1973, with penalties of 5\u201315 years in prison and a fine for poaching and trading them.\nSince 1978, they have been listed in the Soviet Union\u2019s Red Book and is still inscribed today in the Red Data Book of the Russian Federation as threatened with extinction. Hunting snow leopards is only permitted for the purposes of conservation and monitoring, and to eliminate a threat to the life of humans and livestock. Smuggling of snow leopard body parts is punished with imprisonment and a fine.\nHunting snow leopards has been prohibited in Afghanistan since 1986.\nIn China, they have been protected by law since 1989; hunting and trading snow leopards or their body parts constitute a criminal offence that is punishable by the confiscation of property, a fine and a sentence of at least 10 years in prison.\nThey have been protected in Bhutan since 1995.\nAt the end of 2020, 35 cameras were installed on the outskirts of Almaty, Kazakhstan in hopes to catch footage of snow leopards. In November 2021, it was announced by the Russian World Wildlife Fund (WWF) that snow leopards were spotted 65 times on these cameras in the Trans-Ili Alatau mountains since the cameras were installed. \nGlobal Snow Leopard Forum.\nIn 2013, government leaders and officials from all 12 countries encompassing the snow leopard's range (Afghanistan, Bhutan, China, India, Kazakhstan, Kyrgyzstan, Mongolia, Nepal, Pakistan, Russia, Tajikistan, and Uzbekistan) came together at the Global Snow Leopard Forum (GSLF) initiated by the then-President of Kyrgyzstan Almazbek Atambayev, and the State Agency on Environmental Protection and Forestry under the government of Kyrgyzstan. The meeting was held in Bishkek, and all countries agreed that the snow leopard and the high mountain habitat need trans-boundary support to ensure a viable future for snow leopard populations, and to safeguard its fragile environment. The event brought together many partners, including NGOs like the Snow Leopard Conservancy, the Snow Leopard Trust, and the Nature and Biodiversity Conservation Union. Also supporting the initiative were the Snow Leopard Network, the World Bank's Global Tiger Initiative, the United Nations Development Programme, the World Wild Fund for Nature, the United States Agency for International Development, and Global Environment Facility.\nAt the GSLF meeting, the 12 range countries signed the Bishkek Declaration, which stated: \"[We] acknowledge that the snow leopard is an irreplaceable symbol of our nations' natural and cultural heritage and an indicator of the health and sustainability of mountain ecosystems; and we recognize that mountain ecosystems inhabited by snow leopards provide essential ecosystem services, including storing and releasing water from the origins of river systems benefitting one-third of the world\u2019s human population; sustaining the pastoral and agricultural livelihoods of local communities which depend on biodiversity for food, fuel, fodder, and medicine; and offering inspiration, recreation, and economic opportunities.\"\nIn captivity.\nThe Moscow Zoo exhibited the first captive snow leopard in 1872 that had been caught in Turkestan. In Kyrgyzstan, 420 live snow leopards were caught between 1936 and 1988 and exported to zoos around the world. The Bronx Zoo housed a live snow leopard in 1903; this was the first ever specimen exhibited in a North American zoo. The first captive bred snow leopard cubs were born in the 1990s in the Beijing Zoo.\nThe Snow Leopard Species Survival Plan was initiated in 1984; by 1986, American zoos held 234 individuals.\nCultural significance.\nThe snow leopard is widely used in heraldry and as an emblem in Central Asia. They have long been used as a political symbol, the \"Aq Bars\" ('White Leopard'), by Tatars, Kazakhs, and Bulgars. A snow leopard is depicted on the official seal of Almaty and on the former 10,000 Kazakhstani tenge banknote. A mythical winged \"Aq Bars\" is depicted on the national coat of arms of Tatarstan, the seal of the city of Samarqand, Uzbekistan and the old coat of arms of Nur-Sultan. In Kyrgyzstan, they have been used in highly stylized form in the modern emblem of the capital Bishkek, and the same art has been integrated into the badge of the Kyrgyzstan Girl Scouts Association. They are also considered to be a sacred creature by the Kyrgyz people. A crowned snow leopard features in the arms of Shushensky District in Russia. It is the state animal of Ladakh and Himachal Pradesh in India.", "categories": ["Category:All articles with dead external links", "Category:Apex predators", "Category:Articles with 'species' microformats", "Category:Articles with BNF identifiers", "Category:Articles with BNFdata identifiers", "Category:Articles with GND identifiers", "Category:Articles with J9U identifiers", "Category:Articles with LCCN identifiers", "Category:Articles with dead external links from July 2022", "Category:Articles with short description"]}, {"docid": 32587, "title": "Veganism", "text": "Veganism is the practice of abstaining from the use of animal product\u2014particularly in diet\u2014and an associated philosophy that rejects the commodity status of animals. An individual who follows the diet or philosophy is known as a vegan.\nDistinctions may be made between several categories of veganism. Dietary vegans, also known as \"strict vegetarians\", refrain from consuming meat, eggs, dairy products, and any other animal-derived substances. An ethical vegan is someone who not only excludes animal products from their diet but also tries to avoid using animals, animal products, and animal-tested products wherever practical. Another term is \"environmental veganism\", which refers to the avoidance of animal products on the premise that the industrial farming of animals is environmentally damaging and unsustainable. Further motivations for vegan diets include concerns about animal welfare.\nWell-planned vegan diets are regarded as appropriate for all stages of life, including infancy and pregnancy, as said by the American Academy of Nutrition and Dietetics, the Australian National Health and Medical Research Council, the British Dietetic Association, Dietitians of Canada, the New Zealand Ministry of Health, and the Italian Society of Human Nutrition. The German Society for Nutritionwhich is a non-profit organisation and not an official health agencydoes not recommend vegan diets for children or adolescents, or during pregnancy and breastfeeding. The components of a whole-foods plant-based vegan diet including legumes, whole grains, fruits, vegetables, and nuts\u2014along with little to no consumption of refined foods and animal products, are widely acknowledged to be highly beneficial for both avoiding and treating type 2 diabetes, also known as metabolic syndrome; some evidence suggests that a vegan diet can help with weight loss, especially in the short term. Vegan diets tend to be higher in dietary fiber, magnesium, folic acid, vitamin C, vitamin E, iron, and phytochemicals, and lower in dietary energy, saturated fat, cholesterol, omega-3 fatty acid, vitamin D, calcium, zinc, and vitamin B12. As a result of the elimination of all animal products, a poorly-planned vegan diet can lead to particular nutritional deficiencies that counteract its beneficial effects and may cause serious health issues, some of which can only be prevented with fortified foods or dietary supplements. Vitamin B12 supplementation is important because its deficiency can cause blood disorders and potentially irreversible neurological damage; this danger is also one of the most common in poorly-planned non-vegan diets.\nThe word \"vegan\" was coined by Donald Watson and his later wife Dorothy Morgan in 1944. Interest in veganism increased significantly in the 2010s.\nOrigins.\n\"Vegetarian\" etymology.\nThe term \"vegetarian\" has been in use since around 1839 to refer to what was previously described as a vegetable regimen or diet. Its origin is an irregular compound of \"vegetable\" and the suffix \"-arian\" (in the sense of \"supporter, believer\" as in \"humanitarian\"). The earliest known written use is attributed to actress, writer and abolitionist Fanny Kemble, in her \"Journal of a Residence on a Georgian plantation in 1838\u20131839\".\nHistory.\nVegetarianism can be traced to Indus Valley civilization in 3300\u20131300\u00a0BCE in the Indian subcontinent, particularly in northern and western ancient India. Early vegetarians included Indian philosophers such as Parshavnatha, Mahavira, Acharya Kundakunda, Umaswati, Samantabhadra, and Valluvar; the Indian emperors Chandragupta Maurya and Ashoka; Greek philosophers such as Empedocles, Theophrastus, Plutarch, Plotinus, and Porphyry; and the Roman poet Ovid and the playwright Seneca the Younger. The Greek sage Pythagoras may have advocated an early form of strict vegetarianism, but his life is so obscure that it is disputed whether he ever advocated any form of vegetarianism at all. He almost certainly prohibited his followers from eating beans and from wearing woolen garments. Eudoxus of Cnidus, a student of Archytas and Plato, writes that \"Pythagoras was distinguished by such purity and so avoided killing and killers that he not only abstained from animal foods, but even kept his distance from cooks and hunters\". One of the earliest known vegans was the Arab poet al-Ma\u02bfarri, famous for his poem \"I No Longer Steal From Nature\". (). Their arguments were based on health, the transmigration of souls, animal welfare, and the view\u2014espoused by Porphyry in (\"On Abstinence from Animal Food\", )\u2014that if humans deserve justice, then so do animals.\nVegetarianism established itself as a significant movement in 19th-century Britain and the United States. A minority of vegetarians avoided animal food entirely. In 1813, the poet Percy Bysshe Shelley published \"A Vindication of Natural Diet\", advocating \"abstinence from animal food and spirituous liquors\", and in 1815, William Lambe, a London physician, stated that his \"water and vegetable diet\" could cure anything from tuberculosis to acne. Lambe called animal food a \"habitual irritation\", and argued that \"milk eating and flesh-eating are but branches of a common system and they must stand or fall together\". Sylvester Graham's meatless Graham diet\u2014mostly fruit, vegetables, water, and bread made at home with stoneground flour\u2014became popular as a health remedy in the 1830s in the United States. Several vegan communities were established around this time. In Massachusetts, Amos Bronson Alcott, father of the novelist Louisa May Alcott, opened the Temple School in 1834 and Fruitlands in 1844, and in England, James Pierrepont Greaves founded the Concordium, a vegan community at Alcott House on Ham Common, in 1838.\nVegetarian Society.\nIn 1843, members of Alcott House created the British and Foreign Society for the Promotion of Humanity and Abstinence from Animal Food, led by Sophia Chichester, a wealthy benefactor of Alcott House. Alcott House also helped to establish the UK Vegetarian Society, which held its first meeting in 1847 in Ramsgate, Kent. \"The Medical Times and Gazette\" in London reported in 1884:\nAn article in the Society's magazine, the \"Vegetarian Messenger\", in 1851 discussed alternatives to shoe leather, which suggests the presence of vegans within the membership who rejected animal use entirely, not only in diet. By the 1886 publication of Henry S. Salt's \"A Plea for Vegetarianism and Other Essays\", he asserts that, \"It is quite true that most\u2014not all\u2014Food Reformers admit into their diet such animal food as milk, butter, cheese, and eggs...\" Russell Thacher Trall's \"The Hygeian Home Cook-Book\" published in 1874 is the first known vegan cookbook in America. The book contains recipes \"without the employment of milk, sugar, salt, yeast, acids, alkalies, grease, or condiments of any kind.\" An early vegan cookbook, Rupert H. Wheldon's \"No Animal Food: Two Essays and 100 Recipes\", was published by C. W. Daniel in 1910. The consumption of milk and eggs became a battleground over the following decades. There were regular discussions about it in the \"Vegetarian Messenger\"; it appears from the correspondence pages that many opponents of veganism came from vegetarians.\nDuring a visit to London in 1931, Mahatma Gandhi\u2014who had joined the Vegetarian Society's executive committee when he lived in London from 1888 to 1891\u2014gave a speech to the Society arguing that it ought to promote a meat-free diet as a matter of morality, not health. Lacto-vegetarians acknowledged the ethical consistency of the vegan position but regarded a vegan diet as impracticable and were concerned that it might be an impediment to spreading vegetarianism if vegans found themselves unable to participate in social circles where no non-animal food was available. This became the predominant view of the Vegetarian Society, which in 1935 stated: \"The lacto-vegetarians, on the whole, do not defend the practice of consuming the dairy products except on the ground of expediency.\"\n\"Vegan\" etymology.\nIn August 1944, several members of the Vegetarian Society asked that a section of its newsletter be devoted to non-dairy vegetarianism. When the request was turned down, Donald Watson, secretary of the Leicester branch, set up a new quarterly newsletter in November 1944, priced tuppence. He called it \"The Vegan News\". The word \"vegan\" was invented by Watson and Dorothy Morgan, a schoolteacher he would later marry. The word is based on \"the first three and last two letters of 'vegetarian because it marked, in Mr Watson's words, \"the beginning and end of vegetarian\". \"The Vegan News\" asked its readers if they could think of anything better than \"vegan\" to stand for \"non-dairy vegetarian\". They suggested \"allvega\", \"neo-vegetarian\", \"dairyban\", \"vitan\", \"benevore\", \"sanivores\", and \"beaumangeur\".\nThe first edition attracted more than 100 letters, including from George Bernard Shaw, who resolved to give up eggs and dairy. The new Vegan Society held its first meeting in early November at the Attic Club, 144 High Holborn, London. Those in attendance were Donald Watson, Elsie B. Shrigley, Fay K. Henderson, Alfred Hy Haffenden, Paul Spencer and Bernard Drake, with Mme Pataleewa (Barbara Moore, a Russian-British engineer) observing. World Vegan Day is held every 1 November to mark the founding of the Society and the month of November is considered by the Society to be World Vegan Month.\n\"The Vegan News\" changed its name to \"The Vegan\" in November 1945, by which time it had 500 subscribers. It published recipes and a \"vegan trade list\" of animal-free products, such as toothpastes, shoe polishes, stationery and glue. Vegan books appeared, including \"Vegan Recipes\" by Fay K. Henderson (1946) and \"Aids to a Vegan Diet for Children\" by Kathleen V. Mayo (1948).\nThe Vegan Society soon made clear that it rejected the use of animals for any purpose, not only in diet. In 1947, Watson wrote: \"The vegan renounces it as superstitious that human life depends upon the exploitation of these creatures whose feelings are much the same as our own\u00a0...\". From 1948, \"The Vegan\"s front page read: \"Advocating living without exploitation\", and in 1951, the Society published its definition of \"veganism\" as \"the doctrine that man should live without exploiting animals\". In 1956, its vice-president, Leslie Cross, founded the Plantmilk Society; and in 1965, as Plantmilk Ltd and later Plamil Foods, it began production of one of the first widely distributed soy milks in the Western world.\nThe first vegan society in the United States was founded in 1948 by Catherine Nimmo and Rubin Abramowitz in California, who distributed Watson's newsletter. In 1960, H. Jay Dinshah founded the American Vegan Society (AVS), linking veganism to the concept of \"ahimsa\", \"non-harming\" in Sanskrit. According to Joanne Stepaniak, the word \"vegan\" was first published independently in 1962 by the \"Oxford Illustrated Dictionary\", defined as \"a vegetarian who eats no butter, eggs, cheese, or milk\".\nDefinition.\nSince 1988, The Vegan Society gives two definitions of veganism:\nThe first definition by The Vegan Society is accepted among ethical and environmental vegans and the second definition by The Vegan Society is accepted among dietary vegans.\nThe European Commission was granted the power to adopt an implementing act on food information related to suitability of a food for vegans by the European Parliament and the Council of the European Union in article 36 of Regulation (EU) No 1169/2011. The German consumer protection minister conference approved a definition for food suitable for vegans on 22 April 2016. The European Vegetarian Union adopted this text for a proposal for a legally binding definition based on Regulation (EU) No 1169/2011 in July 2019.\nIn 2021, the International Organization for Standardization published standard ISO 23662 on \"definitions and technical criteria for foods and food ingredients suitable for vegetarians or vegans and for labelling and claims\". ISO 23662 was rejected by Nederlandse Vereniging voor Veganisme who found the standard inconsistent with their vision.\nIncreasing interest.\nAlternative food movements.\nIn the 1960s and 1970s, a vegetarian food movement emerged as part of the counterculture in the United States that focused on concerns about diet, the environment, and a distrust of food producers, leading to increasing interest in organic gardening. One of the most influential vegetarian books of that time was Frances Moore Lapp\u00e9's 1971 text, \"Diet for a Small Planet\". It sold more than three million copies and suggested \"getting off the top of the food chain\".\nThe following decades saw research by a group of scientists and doctors in the United States, including physicians Dean Ornish, Caldwell Esselstyn, Neal D. Barnard, John A. McDougall, Michael Greger, and biochemist T. Colin Campbell, who argued that diets based on animal fat and animal protein, such as the Western pattern diet, were detrimental to health. They produced a series of books that recommend vegan or vegetarian diets, including McDougall's \"The McDougall Plan\" (1983), John Robbins's \"Diet for a New America\" (1987), which associated meat eating with environmental damage, and \"Dr. Dean Ornish's Program for Reversing Heart Disease\" (1990). In 2003 two major North American dietitians' associations indicated that well-planned vegan diets were suitable for all life stages. This was followed by the film \"Earthlings\" (2005), Campbell's \"The China Study\" (2005), Rory Freedman and Kim Barnouin's \"Skinny Bitch\" (2005), Jonathan Safran Foer's \"Eating Animals\" (2009), and the film \"Forks over Knives\" (2011).\nIn the 1980s, veganism became associated with punk subculture and ideologies, particularly straight edge hardcore punk in the United States; and anarcho-punk in the United Kingdom. This association continues on into the 21st century, as evinced by the prominence of vegan punk events such as Fluff Fest in Europe.\nInto the mainstream.\nThe vegan diet became increasingly mainstream in the 2010s, especially in the latter half. \"The Economist\" declared 2019 \"the year of the vegan\". Chain restaurants began marking vegan items on their menus and supermarkets improved their selection of vegan-processed food.\nThe global mock-meat market increased by 18 percent between 2005 and 2010, and in the United States by eight percent between 2012 and 2015, to $553\u00a0million a year. The Vegetarian Butcher (), the first known vegetarian butcher shop, selling mock meats, opened in the Netherlands in 2010, while America's first vegan butcher, the Herbivorous Butcher, opened in Minneapolis in 2016. Since 2017, more than 12,500 chain restaurant locations have begun offering Beyond Meat and Impossible Foods products including Carl's Jr. outlets offering Beyond Burgers and Burger King outlets serving Impossible Whoppers. Plant-based meat sales in the U.S grew 37% between 2017 and 2019.\nIn 2011, Europe's first vegan supermarkets appeared in Germany: Veganz in Berlin and Vegilicious in Dortmund. In 2013, the Oktoberfest in Munich (traditionally a meat-heavy event) offered vegan dishes for the first time in its 200-year history.\nBy 2016, 49% of Americans were drinking plant milk, and 91% still drank dairy milk. In the United Kingdom, the plant milk market increased by 155 percent in two years, from 36\u00a0million litres (63\u00a0million imperial pints) in 2011 to 92\u00a0million (162\u00a0million imperial pints) in 2013. There was a 185% increase in new vegan products between 2012 and 2016 in the UK. In 2017, the United States School Nutrition Association found 14% of school districts across the country were serving vegan school meals compared to 11.5% of schools offering vegan lunch in 2016, reflecting a change happening in many parts of the world, including Brazil and England.\nIn total, , the largest share of vegan consumers globally currently reside in Asia Pacific with nine percent of people following a vegan diet. In 2017, veganism rose in popularity in Hong Kong and China, particularly among millennials. China's vegan market was estimated to rise by more than 17% between 2015 and 2020, which is expected to be \"the fastest growth rate internationally in that period\". This exceeds the projected growth in the second and third fastest-growing vegan markets internationally in the same period, the United Arab Emirates (10.6%) and Australia (9.6%) respectively.\nIn 2018, the book \"The End of Animal Farming\" by Jacy Reese Anthis argued that veganism will completely replace animal-based food by 2100. The book was featured in \"The Guardian\", \"The New Republic\", and \"Forbes\", among other newspapers and magazines.\nThe growth of schools serving vegan school meals has increased in recent years with the lunches added by Los Angeles, California in 2018, Portland, Maine in 2019, and New York City in 2022.\nIn January 2021, 582,538 people from 209 countries and territories signed up for Veganuary, breaking the previous year's record of 400,000. That same month, ONA in France became the first vegan restaurant in the country to receive a Michelin star. Throughout the year, a further 79 plant-based restaurants around the world received Michelin stars. At the end of the year, a poll conducted by \"The Guardian\" showed that a new high of 36% of the British public were interested in veganism.\nPrevalence by country.\nThe city with the most vegan restaurants per resident in 2021 according to data collected from HappyCow was Chiang Mai (Thailand), followed by Ubud (Bali, Indonesia), Phuket (Thailand), Tel Aviv (Israel), and Lisbon (Portugal).\nVegan diets, substitutions, and meat analogues.\nVegan diets are based on grains and other seeds, legumes (particularly beans), fruits, vegetables, edible mushrooms, and nuts.\nMeat substitutes.\nVegan meat alternatives are commonly sold in forms like vegetarian sausage, mince, or veggie burgers. They are often made from soybeans, seitan (wheat gluten), beans, lentils, rice, mushrooms or vegetables. Meat substitutes have been made in China since at least the Tang dynasty (618 to 907 common era), including mock duck made from seitan. They are much newer to Western countries. Some famous Western producers of vegan meat alternatives include Impossible Foods and Beyond Meat. However, in the late 2010s many meat producers and supermarkets also started making their own brands of vegan meat substitutes.\nPlant milk and dairy product alternatives.\nPlant milks\u2014such as soy milk, almond milk, cashew milk, grain milks (oat milk, flax milk and rice milk), hemp milk, and coconut milk\u2014are used in place of cows' or goats' milk. Soy milk provides around 7\u00a0g (oz) of protein per cup (240\u00a0mL or 8\u00a0fl\u00a0oz), compared with 8\u00a0g (2/7oz) of protein per cup of cow's milk. Almond milk is lower in dietary energy, carbohydrates, and protein. Soy milk should not be used as a replacement for breast milk for babies. Babies who are not breastfed may be fed commercial infant formula, normally based on cows' milk or soy. The latter is known as soy-based infant formula or SBIF.\nButter and margarine can be replaced with alternate vegan products. Vegan cheeses are made from seeds, such as sesame and sunflower; nuts, such as cashew, pine nut, and almond; and soybeans, coconut oil, nutritional yeast, tapioca, and rice, among other ingredients; and can replicate the meltability of dairy cheese. Nutritional yeast is a common substitute for the taste of cheese in vegan recipes. Cheese substitutes can be made at home, including from nuts, such as cashews. Yoghurt and cream products can be replaced with plant-based products such as soy yoghurt.\nVarious types of plant cream have been created to replace dairy cream, and some types of imitation whipped cream are non-dairy.\nIn the 2010s and 2020s, a number of companies have genetically engineered yeast to produce cow milk proteins, whey, or fat, without the use of cows. These include Perfect Day, Novacca, Motif FoodWorks, Remilk, Final Foods, Imagindairy, Nourish Ingredients, and Circe.\nEgg replacements.\nAs of 2019 in the United States, there were numerous vegan egg substitutes available, including products used for \"scrambled\" eggs, cakes, cookies, and doughnuts. Baking powder, silken (soft) tofu, mashed potato, bananas, flaxseeds, and aquafaba from chickpeas can also be used as egg substitutes. Which one of these works depends on the egg property the replacement is meant to emulate. Scrambled tofu for instance replaces scrambled eggs, but tofu does not act as a binding agent for cakes like raw eggs, flaxseeds or bananas do.\nRaw veganism.\nRaw veganism, combining veganism and raw foodism, excludes all animal products and food cooked above . A raw vegan diet includes vegetables, fruits, nuts, grain and legume sprouts, seeds, and sea vegetables. There are many variations of the diet, including fruitarianism.\nAnimal products.\nGeneral.\nWhile vegans broadly abstain from animal products, there are many ways in which animal products are used, and different individuals and organizations that identify with the practice of veganism may use some limited animal products based on philosophy, means or other concerns.\nPhilosopher Gary Steiner argues that it is not possible to be entirely vegan, because animal use and products are \"deeply and imperceptibly woven into the fabric of human society\".\n\"Animal Ingredients A to Z\" (2004) and \"Veganissimo A to Z\" (2013) list which ingredients might be animal-derived. The British Vegan Society's sunflower logo and PETA's bunny logo mean the product is certified vegan, which includes no animal testing. The Leaping Bunny logo signals no animal testing, but it might not be vegan. The Vegan Society criteria for vegan certification are that the product contain no animal products, and that neither the finished item nor its ingredients have been tested on animals by, or on behalf of, the manufacturer or by anyone over whom the manufacturer has control. Its website contains a list of certified products, as does Australia's Choose Cruelty Free (CCF). The British Vegan Society will certify a product only if it is free of animal involvement as far as possible and practical, including animal testing, but \"recognises that it is not always possible to make a choice that avoids the use of animals\", an issue that was highlighted in 2016 when it became known that the UK's newly introduced \u00a35 note contained tallow.\nMeat, eggs and dairy.\nLike vegetarians, vegans do not eat meat (including beef, pork, poultry, fowl, game, animal seafood). The main difference between a vegan and vegetarian diet is that vegans exclude dairy products and eggs.\nClothing.\nMany clothing products may be made of animal products such as silk, wool (including lambswool, shearling, cashmere, angora, mohair, and a number of other fine wools), fur, feathers, pearls, animal-derived dyes, leather, snakeskin, or other kinds of skin or animal product. While dietary vegans might use animal products in clothing, toiletries, and similar, ethical veganism extends not only to matters of food but also to the wearing or use of animal products, and rejects the commodification of animals altogether. Most leather clothing is made from cow skins. Unlike ethical vegans, dietary vegans do not oppose the use of leather itself and may continue to wear leather they had bought before adopting the diet on the grounds that they are not financially supporting the meat industry. Ethical vegans may wear clothing items and accessories made of non-animal-derived materials such as hemp, linen, cotton, canvas, polyester, artificial leather (pleather), rubber, and vinyl. Leather alternatives can come from materials such as cork, pi\u00f1a\u00a0(from pineapples), cactus, and mushroom leather. Some vegan clothes, in particular leather alternatives, are made of petroleum-based products, which has triggered criticism because of the environmental damage involved in their production.\nToiletries.\nVegans replace personal care products and household cleaners containing animal products with products that are vegan. Animal ingredients are ubiquitous because they are relatively inexpensive. After animals are slaughtered for meat, the leftovers are put through a rendering process and some of that material, particularly the fat, is used in toiletries.\nCommon animal-derived ingredients include: tallow in soap; collagen-derived glycerine, which used as a lubricant and humectant in many haircare products, moisturizers, shaving foams, soaps and toothpastes; lanolin from sheep's wool is often found in lip balm and moisturizers; stearic acid is a common ingredient in face creams, shaving foam and shampoos, (as with glycerine, it can be plant-based, but is usually animal-derived); Lactic acid, an alpha-hydroxy acid derived from animal milk, is used in moisturizers; allantoin\u2014 from the comfrey plant or cows' urine \u2014is found in shampoos, moisturizers and toothpaste; and carmine from scale insects, such as the female cochineal, is used in food and cosmetics to produce red and pink shades;\nBeauty Without Cruelty, founded as a charity in 1959, was one of the earliest manufacturers and certifiers of animal-free personal care products.\nInsect products.\nVegan groups disagree about insect products. Neither the Vegan Society nor the American Vegan Society considers honey, silk, and other insect products as suitable for vegans. Some vegans believe that exploiting the labor of bees and harvesting their energy source is immoral, and that commercial beekeeping operations can harm and even kill bees. Insect products can be defined much more widely, as commercial bees are used to pollinate about 100 different food crops.\nPet food.\nSome environmental vegans do not use meat-based pet food to feed their pets due to its environmental impact and ethical vegans do not use meat-based pet food to feed their pets due to it being an animal product. This is particularly true for domesticated cats and dogs, for which vegan pet food is both available and nutritionally complete, such as Vegepet.\nThis practice has been met with caution and criticism, especially regarding vegan cat diets because, unlike omnivorous dogs, felids are obligate carnivores. Nutritionally complete vegan pet diets are comparable to meat-based ones for cats and dogs. A 2015 study found that 6 out of 24 commercial vegan pet food brands do not meet the Association of American Feed Control Officials (AAFCO) labeling regulations for amino acid adequacy. A 2023 Systematic review concluded that pet dogs and cats can remain healthy on a vegan diet.\nOther products and farming practices.\nA concern is the case of medications, which are routinely tested on animals to ensure they are effective and safe, and may also contain animal ingredients, such as lactose, gelatine, or stearates. There may be no alternatives to prescribed medication or these alternatives may be unsuitable, less effective, or have more adverse side effects. Experimentation with laboratory animals is also used for evaluating the safety of vaccines, food additives, cosmetics, household products, workplace chemicals, and many other substances. Vegans may avoid certain vaccines, such as the flu vaccine, which is commonly produced in chicken eggs. An effective alternative, Flublok, is widely available in the United States.\nFarming of fruits and vegetables may include fertilizing the soil with animal manure even on organic farms, possibly causing a concern to vegans for ethical or environmental reasons. \"Vegan\" (or \"animal-free\") farming uses plant compost only.\nResearch and guidance.\nA 2023 review found that vegetarian diets, including vegan diets, are associated with lower risk for vascular disease, obesity, dyslipidemia, hypertension, type 2 diabetes.\nA 2022 review indicated that a vegan diet may be effective for reducing body weight, lowering the risk of cancer, and providing a lower risk of all-cause mortality. People on a vegan diet with diabetes or cardiovascular diseases may have lower levels of disease biomarkers.\nA 2022 meta-analysis found moderate evidence that adhering to a vegan diet for at least 12\u2009weeks may be effective in individuals with overweight or type 2 diabetes to induce a meaningful decrease in body weight and improve glycemia.\nA 2021 Cochrane review of randomized controlled trials found that there is \"currently insufficient information to draw conclusions about the effects of vegan dietary interventions on cardiovascular disease risk factors\". A 2018 meta-analysis of observational studies concluded that \"In most countries, a vegan diet is associated with a more favourable cardio-metabolic profile compared to an omnivorous diet\". A 2022 meta-analysis of prospective cohort studies concluded that vegan diets are associated with reduced risk of Ischemic Heart Disease, but no clear association was found for cardiovascular disease and stroke.\nA 2020 review of inflammation biomarkers found that a vegan diet was associated with lower levels of C-reactive protein compared to omnivores. There is inconsistent evidence for vegan diets providing an effect on metabolic syndrome. There is tentative evidence of an association between vegan diets and a reduced risk of cancer. A vegan diet without caloric restriction may reduce high blood pressure similarly to diets recommended by medical societies and portion-controlled diets. Vegans may be at risk of low bone mineral density.\nPositions of dietetic and government associations.\nThe Academy of Nutrition and Dietetics and Dietitians of Canada state that properly planned vegetarian or vegan diets are appropriate for all life stages, including pregnancy and lactation. The Australian National Health and Medical Research Council similarly recognizes a well-planned vegan diet as viable for any age, as does the British Dietetic Association, British National Health Service and the Canadian Pediatric Society.\nThe does not recommend a vegan diet for babies, children and adolescents, or for pregnancy or breastfeeding.\nAs of 2022, 45% of government nutritional guidelines discuss vegan meat or milk alternatives (or both).\nPregnancy, infants and children.\nThe Academy of Nutrition and Dietetics and Dietitians of Canada consider well-planned vegetarian and vegan diets \"appropriate for individuals during all stages of the lifecycle, including pregnancy, lactation, infancy, childhood, and adolescence, and for athletes\". The German Society for Nutrition cautioned against a vegan diet for pregnant women, breastfeeding women, babies, children, and adolescents. The position of the Canadian Pediatric Society is that \"well-planned vegetarian and vegan diets with appropriate attention to specific nutrient components can provide a healthy alternative lifestyle at all stages of fetal, infant, child and adolescent growth. It is recommended that attention should be given to nutrient intake, particularly protein, vitamins B12 and D, essential fatty acids, iron, zinc, and calcium.\nNutrients and potential deficiencies.\nVegan diets tend to be high in dietary fiber, folate, vitamins C and E, potassium, magnesium, and unsaturated fats. However, consuming no animal products increases the risk of deficiencies of vitamins B12 and D, calcium, iron, and omega-3 fatty acids.\nThe American Academy of Nutrition and Dietetics states that special attention may be necessary to ensure that a vegan diet will provide adequate amounts of vitamin B12, omega-3 fatty acids, vitamin D, calcium, iodine, iron, and zinc. It also states that concern that vegans and vegan athletes may not consume an adequate amount and quality of protein is unsubstantiated.\nThese nutrients are available in plant foods, with the exception of vitamin B12, which can be obtained only from B12-fortified vegan foods or supplements. Iodine may also require supplementation, such as using iodized salt. Vitamin B12 deficiency occurs in up to 80% of all vegans in some Asian countries.\nFor information on the impact of meat on the diet, see this article.\nPhilosophy.\nEthical veganism.\nEthical veganism is based on opposition to speciesism, the assignment of value to individuals based on (animal) species membership alone. Divisions within animal rights theory include the utilitarian, protectionist approach, which pursues improved conditions for animals. It also pertains to the rights-based abolitionism, which seeks to end human ownership of non-humans, including as pets. Abolitionists argue that protectionism serves only to make the public feel that animal use can be morally unproblematic (the \"happy meat\" position).\nDonald Watson, co-founder of The Vegan Society, stated in response to a question on why he was an ethical vegan, \"If an open-minded, honest person pursues a course long enough, and listens to all the criticisms, and in one's own mind can satisfactorily meet all the criticisms against that idea, sooner or later one's resistance against what one sees as evil tradition has to be discarded.\" On bloodsports, he has said that \"to kill creatures for fun must be the very dregs,\" and that vivisection and animal experimentation \"is probably the cruelest of all Man's attack on the rest of Creation.\" He has also stated that \"vegetarianism, whilst being a necessary stepping-stone, between meat eating and veganism, is only a stepping stone.\"\nAlex Hershaft, co-founder of the Farm Animal Rights Movement and Holocaust survivor, states he \"was always bothered by the idea of hitting a beautiful, living, innocent animal over the head, cutting him up into pieces, then shoving the pieces into [his] mouth,\" and that his experiences in the Nazi Holocaust allowed him \"to empathize with the conditions of animals in factory farms, auction yards, and slaughterhouses\" because he \"knows firsthand what it's like to be treated like a worthless object.\" Several animal rights activists including Isaac Bashevis Singer, Gary Yourofsky and Karen Davis have compared the cruel treatment of animals in CAFOs and slaughterhouses to the Holocaust.\nLaw professor Gary Francione, an abolitionist, argues that all sentient beings should have the right not to be treated as property, and that adopting veganism must be the baseline for anyone who believes that non-humans have intrinsic moral value. Philosopher Tom Regan, also a rights theorist, argues that animals possess value as \"subjects-of-a-life\", because they have beliefs, desires, memory and the ability to initiate action in pursuit of goals. The right of subjects-of-a-life not to be harmed can be overridden by other moral principles, but Regan argues that pleasure, convenience and the economic interests of farmers are not weighty enough. Philosopher Peter Singer, a protectionist and utilitarian, argues that there is no moral or logical justification for failing to count animal suffering as a consequence when making decisions, and that killing animals should be rejected unless necessary for survival. Despite this, he writes that \"ethical thinking can be sensitive to circumstances\", and that he is \"not too concerned about trivial infractions\".\nAn argument proposed by Bruce Friedrich, also a protectionist, holds that strict adherence to veganism harms animals, because it focuses on personal purity, rather than encouraging people to give up whatever animal products they can. For Francione, this is similar to arguing that, because human-rights abuses can never be eliminated, we should not defend human rights in situations we control. By failing to ask a server whether something contains animal products, we reinforce that the moral rights of animals are a matter of convenience, he argues. He concludes from this that the protectionist position fails on its own consequentialist terms.\nPhilosopher Val Plumwood maintained that ethical veganism is \"subtly human-centred\", an example of what she called \"human/nature dualism\" because it views humanity as separate from the rest of nature. Ethical vegans want to admit non-humans into the category that deserves special protection, rather than recognize the \"ecological embeddedness\" of all. Plumwood wrote that animal food may be an \"unnecessary evil\" from the perspective of the consumer who \"draws on the whole planet for nutritional needs\"\u2014and she strongly opposed factory farming\u2014but for anyone relying on a much smaller ecosystem, it is very difficult or impossible to be vegan.\nBioethicist Ben Mepham, in his review of Francione and Garner's book \"The Animal Rights Debate: Abolition or Regulation?\", concludes that \"if the aim of ethics is to choose the right, or best, course of action in specific circumstances 'all things considered', it is arguable that adherence to such an absolutist agenda is simplistic and open to serious self-contradictions. Or, as Farlie puts it, with characteristic panache: 'to conclude that veganism is the \"only ethical response\" is to take a big leap into a very muddy pond'.\" He cites as examples the adverse effects on animal wildlife derived from the agricultural practices necessary to sustain most vegan diets and the ethical contradiction of favoring the welfare of domesticated animals but not that of wild animals; the imbalance between the resources that are used to promote the welfare of animals as opposed to those destined to alleviate the suffering of the approximately one billion human beings who undergo malnutrition, abuse, and exploitation; the focus on attitudes and conditions in western developed countries, leaving out the rights and interests of societies whose economy, culture and, in some cases, survival rely on a symbiotic relationship with animals.\nDavid Pearce, a transhumanist philosopher, has argued that humanity has a \"hedonistic imperative\" to not merely avoid cruelty to animals or abolish the ownership of non-human animals, but also to redesign the global ecosystem such that wild animal suffering ceases to exist. In the pursuit of abolishing suffering itself, Pearce promotes predation elimination among animals and the \"cross-species global analogue of the welfare state\". Fertility regulation could maintain herbivore populations at sustainable levels, \"a more civilised and compassionate policy option than famine, predation, and disease\". The increasing number of vegans and vegetarians in the transhumanism movement has been attributed in part to Pearce's influence.\nA growing political philosophy that incorporates veganism as part of its revolutionary praxis is veganarchism, which seeks \"total abolition\" or \"total liberation\" for all animals, including humans. Veganarchists identify the state as unnecessary and harmful to animals, both human and non-human, and advocate for the adoption of a vegan lifestyle within a stateless society. The term was popularized in 1995 with Brian A. Dominick's pamphlet \"Animal Liberation and Social Revolution\", described as \"a vegan perspective on anarchism or an anarchist perspective on veganism\".\nDirect action is a common practice among veganarchists (and anarchists generally) with groups like the Animal Liberation Front (ALF), the Animal Rights Militia (ARM), the Justice Department (JD) and Revolutionary Cells \u2013 Animal Liberation Brigade (RCALB) often engaging in such activities, sometimes criminally, to further their goals. Steven Best, animal rights activist and professor of philosophy at the University of Texas at El Paso, is an advocate of this approach, and has been critical of vegan activists like Francione for supporting animal liberation, but not total liberation, which would include not only opposition to \"the property status of animals\", but also \"a serious critique of capitalism, the state, property relations, and commodification dynamics in general.\" In particular, he criticizes the focus on the simplistic and apolitical \"Go Vegan\" message directed mainly at wealthy Western audiences, while ignoring people of color, the working class and the poor, especially in the developing world, noting that \"for every person who becomes vegan, a thousand flesh eaters arise in China, India and Indonesia.\" The \"faith in the singular efficacy of conjectural education and moral persuasion,\" Best writes, is no substitute for \"direct action, mass confrontation, civil disobedience, alliance politics, and struggle for radical change.\" Donald Watson has stated that he \"respects the people enormously who do it, believing that it's the most direct and quick way to achieve their ends.\" Sociologist David Nibert of Wittenberg University posits that any movement towards global justice would necessitate not only the abolition of animal exploitation, particularly as a food source for humans, but also transitioning towards a socioeconomic alternative to the capitalist system, both of which dovetail into what he refers to as the animal\u2013industrial complex.\nSome vegans also embrace the philosophy of anti-natalism, as they see the two as complementary in terms of \"harm reduction\" to animals and the environment.\nVegan social psychologist Melanie Joy described the ideology in which people support the use and consumption of animal products as carnism, as a sort of opposite to veganism.\nExploitation concerns.\nThe Vegan Society has written, \"by extension, [veganism] promotes the development and use of animal-free alternatives for the benefit of humans.\" Many ethical vegans and vegan organizations cite the poor working conditions of slaughterhouse workers as a reason to reject animal products. The first vegan activist, Donald Watson, has stated, \"If these butchers and vivisectors weren't there, could we perform the acts that they are doing? And, if we couldn't, we have no right to expect them to do it on our behalf. Full stop! That simply compounds the issue. It means that we're not just exploiting animals; we're exploiting human beings.\"\nDietary veganism.\nSome people only follow the diet that fits to a vegan way of living. Brenda Davis and Vesanto Melina perceive a focus on the diet as a precursor to a vegan way of living. Authors like Richard Twine and Breeze Harper argue that this can not be described as veganism, as veganism is more than the diet. Gary L. Francione argued that the promotion of \"dietary veganism\" lacks the moral imperative that was expressed in the words of Leslie J. Cross, an early and influential vice-president of The Vegan Society, who described in 1949 that veganism was \"the abolition of the exploitation of animals by man\".\nEnvironmental veganism.\nEnvironmental vegans focus on conservation, rejecting the use of animal products on the premise that fishing, hunting, trapping and farming, particularly factory farming, are environmentally unsustainable.\nAccording to a 2006 United Nations Food and Agriculture Organization report, \"Livestock's Long Shadow\", around 26% of the planet's terrestrial surface is devoted to livestock grazing. The UN report also concluded that livestock farming (mostly of cows, chickens and pigs) affects the air, land, soil, water, biodiversity and climate change. Livestock consumed 1,174\u00a0million tonnes of food in 2002\u2014including 7.6\u00a0million tonnes of fishmeal and 670\u00a0million tonnes of cereals, one-third of the global cereal harvest. Paul Watson of the Sea Shepherd Conservation Society called pigs and chicken \"major aquatic predators\", because livestock eat 40 percent of the fish that are caught.\nA 2010 UN report, \"Assessing the Environmental Impacts of Consumption and Production\", argued that animal products \"in general require more resources and cause higher emissions than plant-based alternatives\". It proposed a move away from animal products to reduce environmental damage.\nA 2015 study determined that significant biodiversity loss can be attributed to the growing demand for meat, which is a significant driver of deforestation and habitat destruction, with species-rich habitats being converted to agriculture for livestock production. A 2017 study by the World Wildlife Fund found that 60% of biodiversity loss can be attributed to the vast scale of feed crop cultivation needed to rear tens of billions of farm animals, which puts an enormous strain on natural resources resulting in an extensive loss of lands and species. In November 2017, 15,364 world scientists signed a warning to humanity calling for, among other things, \"promoting dietary shifts towards mostly plant-based foods\".\nA 2018 study found that global adoption of plant-based diets would reduce agricultural land use by 76% (3.1\u00a0billion hectares, an area the size of Africa) and cut total global greenhouse gas emissions by 28%. Half of this emissions reduction came from avoided emissions from animal production including methane and nitrous oxide, and half came from trees re-growing on abandoned farmland which remove carbon dioxide from the air. The authors conclude that avoiding meat and dairy is the \"single biggest way\" to reduce one's impact on Earth.\nThe 2019 IPBES \"Global Assessment Report on Biodiversity and Ecosystem Services\" found that industrial agriculture and overfishing are the primary drivers of the extinction crisis, with the meat and dairy industries having a substantial impact. On 8 August 2019, the IPCC released a summary of the 2019 special report which asserted that a shift towards plant-based diets would help to mitigate and adapt to climate change.\nA 2022 study found that for high-income nations alone 100 billion tons of carbon dioxide could be removed from the air by the end of the century through a shift to plant-based diets and re-wilding of farmland. The researchers coined the term \"double climate dividend\" to describe the effect that re-wilding after a diet shift can have. However, the researchers note that \"We don't have to be purist about this, even just cutting animal intake would be helpful. If half of the public in richer regions cut half the animal products in their diets, you're still talking about a massive opportunity in environmental outcomes and public health\".\nFeminist veganism.\nPioneers.\nOne of the leading activists and scholars of feminist animal rights is Carol J. Adams. Her premier work, \"The Sexual Politics of Meat: A Feminist-Vegetarian Critical Theory\" (1990), noted the relationship between feminism and meat consumption. Since the release of \"The Sexual Politics of Meat\", Adams has published several other works, including essays, books, and keynote addresses. In one of her speeches, \"Why feminist-vegan now?\"\u2014adapted from her original address at the \"Minding Animals\" conference in Newcastle, Australia (2009)\u2014Adams stated that \"the idea that there was a connection between feminism and vegetarianism came to [her] in October 1974\", illustrating that the concept of feminist veganism has been around for nearly half a century. Other authors have echoed Adams' ideas while also expanding on them. Feminist scholar Angella Duvnjak stated in \"Joining the Dots: Some Reflections on Feminist-Vegan Political Practice and Choice\" that she was met with opposition when she pointed out the connection between feminist and vegan ideals, even though the connection seemed more than obvious to her and other scholars (2011).\nAnimal and human abuse parallels.\nOne of the central concepts that animates feminist veganism is the idea that there is a connection between the oppression of women and the oppression of animals. For example, Marjorie Spiegal compared the consumption or servitude of animals for human gain to slavery. This connection is further mirrored by feminist vegan writers like Carrie Hamilton, who pointed out that violent \"rapists sometimes exhibit behavior that seems to be patterned on the mutilation of animals\" suggesting there is a parallel between the violence of rape and animal cruelty.\nCapitalism and feminist veganism.\nFeminist veganism also relates to feminist thought through the common critique of the capitalist means of production. In an interview with Carol J. Adams, she highlighted \"meat eating as the ultimate capitalist product, because it takes so much to make the product, it uses up so many resources\". This extensive use of resources for meat production is discouraged in favor of using that productive capacity for other food products that have a less detrimental impact on the environment.\nReligious veganism.\nStreams within a number of religious traditions encourage veganism, sometimes on ethical or environmental grounds.\u00a0 Scholars have especially noted the growth in the twenty-first century of Jewish veganism and Jain veganism. Some interpretations of Christian vegetarianism, Hindu vegetarianism, and Buddhist vegetarianism also recommend or mandate a vegan diet.\nDonald Watson argued, \"If Jesus were alive today, he'd be an itinerant vegan propagandist instead of an itinerant preacher of those days, spreading the message of compassion, which, as I see it, is the only useful part of what religion has to offer and, sad as it seems, I doubt if we have to enroll our priest as a member of the Vegan Society.\"\nBlack veganism.\nIn the US, Black veganism is a social and political philosophy as well as a diet. It connects the use of non-human animals with other social justice concerns such as racism, and with the lasting effects of slavery, such as the subsistence diets of enslaved people enduring as familial and cultural food traditions. Dietary changes caused by the Great Migration also meant former farmers, who had previously been able to grow or forage their own vegetables, became reliant on processed foods.\nAccording to AshEL Eldridge, an Oakland activist, the movement is about the Black community reclaiming its food sovereignty and \"decolonizing\" the diet of Black Americans. According to Shah, the area where most vegans of color feel the greatest rift with mainstream veganism is in mainstream veganism's failure to recognize the intersectionality with other social justice issues such as food access.\nPETA columnist Zachary Tolivar noted he had often heard Black veganism called \"a revolutionary act\" because it often involves rejecting both family tradition and systemic oppression. Amirah Mercer described it as \"revoking my own Black card\" and said that for US Blacks, choosing veganism was an act of protest against disenfranchisement by governmental health care and food policy.\nPolitics and activism.\nIn 2021, vegan climate activist Greta Thunberg called for more vegan food production and consumption worldwide. Parties like Tierschutzpartei in Germany and PACMA in Spain have pro-vegan agendas. They cooperate via Animal Politics EU. In the European Union, meat producers and vegans argue whether vegan food products should be allowed to use labels like \"sausages\" or \"burgers\" for vegan food. The EU currently bans labeling with dairy-related words like \"almond milk\", a rule instated in 2017. , six countries in Europe apply higher value-added tax (VAT) rates to vegan plant milk than to cows' milk, which pro-vegan activists have called discrimination.\nDemographics.\nIn the United States, 1 out of 10 Americans over the age of 18 consider themselves vegan or vegetarian as of January 2022.\nIn the below chart, polls with larger sample sizes are preferred over those with smaller sample size.\nVegan rights.\nIn some countries, vegans have some rights to meals and legal protections against discrimination.\nSymbols.\nMultiple symbols have been developed to represent veganism. Several are used on consumer packaging, including the Vegan Society trademark and the Vegan Action logo, to indicate products without animal-derived ingredients. Various symbols may also be used by members of the vegan community to represent their identity and in the course of animal rights activism, such as a vegan flag.\nMedia depictions.\nVeganism is often misrepresented in media. Some argue that veganism has been dismissed in news media or that clickbait culture often portrays feminists and vegans as \"irrational extremists.\" This is because in Western societies, \"meat-based diets are the norm\" with those who avoid meat still representing \"a small minority,\" with more women than men as vegan and vegetarian, with women being \"under-represented in the mass media,\" the latter influencing more to be vegetarians. Others have noted those who are vegetarian and vegan are met with \"acceptance, tolerance, or hostility\" after they divulge they are vegetarian or vegan. There are a number of vegan stereotypes, including claims they hate meat-eaters, are always hungry, weak, angry, or moralistic. The hatred of vegans has been termed as vegaphobia by some individuals. Farhad Manjoo, in 2019, stated that \"preachy vegans are something of a myth,\" and argued that in pop culture, and generally, it is \"still widely acceptable to make fun of vegans.\"\nLiterature.\nOften vegan or vegetarian characters are portrayed as fringe characters, although other novels cast them as protagonists or encourage people to become vegetarians or vegans. Some have argued that there are more vegan cookbooks than \"vegan literature\" There also books which introduce \"vegan identity to children\" or encourage people to \"write for\" animals. Also, Bruce Banner in \"Ultimate Wolverine vs. Hulk\" and Karolina Dean in \"Runaways\", who is also known as Lucy in the Sky or L.S.D., are vegans. The latter is a lesbian, a vegan, and \"an ardent animal lover...committed to a life completely free of meat and dairy.\"\nTV shows.\nJessica Cruz / Green Lantern, a lead character in the animated series, \"DC Super Hero Girls\" is not only pacifist, but also a vegan and environmentalist, resulting in her becoming friends with Pam Isley. She often professes her commitment to the environment and plant-based meals.\nThe recent series \"City of Ghosts\" featured a chef, Sonya, who runs a vegan cafe in Leimert Park, Los Angeles. Draculaura in \"Monster High\" has also been described as \"one of the very few outspoken vegan cartoon characters out there\".\nSocial media.\nBy the 2010s, social media sites like Instagram became prominent in the promotion of veganism, more than a fad, with people trying to \"change the world by being vegan\" as stated by various media outlets.\nEconomics of veganism.\nThe 2014 documentary film \"Cowspiracy\" estimates that a vegan, over the course of one year, will save 1.5\u00a0million litres of water, 6,607\u00a0kg of grain, 1,022 square metres of forest cover, 3,322\u00a0kg of , and 365 animal lives compared to the average U.S. diet. According to a 2016 study, if everyone in the U.S. switched to a vegan diet, the country would save $208.2\u00a0billion in direct health-care savings, $40.5\u00a0billion in indirect health-care savings, $40.5\u00a0billion in environmental savings, and $289.1\u00a0billion in total savings by 2050. The study also found that if everybody in the world switched to a vegan diet, the global economy would save $684.4\u00a0billion in direct health-care savings, $382.6\u00a0billion in indirect health-care savings, $569.5\u00a0billion in environmental savings, and $1.63\u00a0trillion in total savings by 2050.\nIn his 2015 book \"Doing Good Better\", William MacAskill stated the following (citing numbers from a 2011 book, \"Compassion by the pound\"):", "categories": ["Category:1944 introductions", "Category:All Wikipedia articles in need of updating", "Category:All articles containing potentially dated statements", "Category:All articles lacking reliable references", "Category:All articles with dead external links", "Category:All articles with unsourced statements", "Category:Applied ethics", "Category:Articles containing Dutch-language text", "Category:Articles containing Latin-language text", "Category:Articles containing potentially dated statements from 2013"]}, {"docid": 48664, "title": "Yosemite National Park", "text": "Yosemite National Park ( ) is an American national park in the state of California, surrounded on the southeast by Sierra National Forest and on the northwest by Stanislaus National Forest. The park is managed by the National Park Service and covers an area of in four countiescentered in Tuolumne and Mariposa, extending north and east to Mono and south to Madera County. Designated a World Heritage Site in 1984, Yosemite is internationally recognized for its cliffs, waterfalls, clear streams, giant sequoia groves, lakes, mountains, meadows, glaciers, and biological diversity. Almost 95 percent of the park is designated wilderness. Yosemite is one of the largest and least fragmented habitat blocks in the Sierra Nevada, and the park supports a diversity of plants and animals.\nThe geology of the Yosemite area is characterized by granite rocks and remnants of older rock. About 10\u00a0million years ago, the Sierra Nevada was uplifted and tilted to form its unique slopes, which increased the steepness of stream and river beds, resulting in the formation of deep, narrow canyons. About one million years ago glaciers formed at higher elevations which eventually melted and moved downslope, cutting and sculpting the U-shaped valley that attracts so many visitors to its scenic vistas.\nEuropean American settlers first entered Yosemite Valley itself in 1851. There are earlier instances of other travelers entering the Valley but James D. Savage is credited with discovering the area that became Yosemite National Park. Despite Savage and others claiming their discovery of Yosemite, the region and Valley itself have been inhabited for nearly 4,000 years, although humans may have visited the area as long as 8,000 to 10,000 years ago.\nYosemite was critical to the development of the national park idea. Galen Clark and others lobbied to protect Yosemite Valley from development, ultimately leading to President Abraham Lincoln's signing of the Yosemite Grant of 1864 which declared Yosemite as federally preserved land. It was not until 1890 that John Muir led a successful movement which had Congress establish Yosemite Valley and its surrounding areas as a National Park. This helped pave the way for the National Park System. Yosemite draws about four million visitors each year, and most visitors spend the majority of their time in the of Yosemite Valley. The park set a visitation record in 2016, surpassing five million visitors for the first time in its history. The park began requiring reservations to access the park during peak periods starting in 2020 as a response to the rise in visitors.\nToponym.\nThe word \"Yosemite\" (meaning \"killer\" in Miwok) historically referred to the name that the Miwok gave to the Ahwahneechee People, an Indigenous tribe driven out of Yosemite Valley by the Mariposa Battalion. Previously, the region had been called \"Ahwahnee\" (\"big mouth\") by its only Indigenous inhabitants, the Ahwahneechee. The term \"Yosemite\" in Miwok is easily confused with a similar term for \"grizzly bear\", and is still a common misconception.\nHistory.\nAhwahneechee and the Mariposa Wars.\nThe indigenous natives of Yosemite called themselves the Ahwahneechee, meaning \"dwellers\" in Ahwahnee. The Ahwahneechee People was the only tribe that lived in the boundaries of Yosemite National Park but other tribes lived in its surrounding areas, together they formed a larger Indigenous population in California, called the Southern Sierra Miwok. They are related to the Northern Paiute and Mono tribes. Other tribes like the Central Sierra Miwoks and the Yokuts, who both lived in the San Joaquin Valley and central California, visited Yosemite to trade and intermarry with the Ahwahneechee. This resulted in a blending of culture which helped preserve Indigenous people's presence in Yosemite after early American settlements and urban development threatened their survival. Vegetation and game in the region were similar to modern times; acorns were a staple to their diet, as well as other seeds and plants, salmon and deer.\nA major event impacting the native population of Yosemite and all of California in the mid-19th century was the California Gold Rush, which drew more than 90,000 European Americans to the area in less than two years, causing competition for resources between gold miners and the local Natives. Before large amounts of European settlers arrived in California, about 70 years before the Gold Rush, the Indigenous population was estimated to be 300,000, once the Gold Rush started it dropped down to 150,000, and just ten years later, only about 50,000 remained. The reason for such a decline in the Native American population results from numerous reasons including disease, birth rate decreases, starvation, and the conflicts from the American Indian Wars. The conflict in Yosemite is known as the Mariposa War, it started in December 1850 when California funded a state militia to drive Native people from contested territory, also known as Indigenous traditional and sacred homelands; the goal was to suppress Native American resistance to American expansion.\nIn retaliation to the extermination and domestication of their people, and loss of their lands and resources, Yosemite Indian tribes often stole from settlers and miners, sometimes killing them, both actions seen as tribute for the great losses they experienced. The War and formation of the Mariposa Battalion was partially the result of a single incident involving James Savage, a trader in Fresno, California whose trading post was attacked in December, 1850. After the incident, Savage rallied other miners and gained the support of local officials to pursue revenge and a full out war against the Natives, that is how he was appointed United States Army Major and leader the Mariposa Battalion in the beginning of 1851. He and Captain John Boling were responsible for pursuing the Ahwahneechee people that were being led by Chief Tenaya and driving them as far west as possible, out of Yosemite. In March 1851 under the command of Savage, the Mariposa Battalion captured about 70 Ahwahneechee and planned to take them to a reservation in Fresno, but they all managed to escape. Later in May, under the command of Boling, the battalion captured 35 Ahwahneechee including Chief Tenaya and marched them to the reservation but most were allowed to eventually leave and the rest escaped. Tenaya and others fled across the Sierra Nevada and settled with the Mono Lake Paiutes. Tenaya and some of his companions were ultimately killed in 1853 either over stealing horses or a gambling conflict and the survivors of Tenaya's group and other Ahwahneechee were absorbed into the Mono Lake Paiute tribe.\nAccounts from this battalion were the first well-documented reports of ethnic Europeans entering Yosemite Valley. Attached to Savage's unit was Doctor Lafayette Bunnell, who later wrote about his awestruck impressions of the valley in \"The Discovery of the Yosemite\". Bunnell is credited with naming Yosemite Valley, based on his interviews with Chief Tenaya. Bunnell wrote that Chief Tenaya was the founder of the Ahwahnee colony. Bunnell falsely believed that the word \"Yosemite\" meant \"full-grown grizzly bear.\" In fact, \"Yosemite\" was derived from the Miwok term for the Ahwaneechee people: \"yohhe'meti,\" meaning \"they are killers\".\nIndigenous peoples' presence post war and since.\nAfter the Mariposa War, a number of Native Americans continued to live in the Yosemite area, despite their overall population being severely decreased in the present-day park's boundary. The remaining Yosemite Ahwahneechee tribe members there were forced to relocate to an Indian village constructed in 1851 by the state government . They learned to live within this camp and their limited rights, adapting to the changing environment by taking advantage of the growing tourism industry through employment opportunities and creating small businesses from selling goods and providing services. Despite the integration of Indigenous people into the growing American settlement and tourism industry, their villages were destroyed and their people were forced to relocate four different times throughout the park's history. The U.S. Army was responsible for the village's destruction in 1851 and 1906, and the National Park Service was responsible for it in 1929 and 1969. In 1969, the National Park Service evicted the remaining Native people from their residences and destroyed their village as part of a fire-fighting exercise. A reconstructed \"Indian Village of Ahwahnee\" has been erected behind the Yosemite Museum, located next to the Yosemite Valley Visitor Center.\nBy the late 19th century, the population of all native inhabitants in Yosemite was difficult to determine, estimates ranged from smaller numbers, such as thirty individuals, to several hundred. The Ahwahneechee people and their descendants were even harder to identify. The last full-blooded Ahwahneechee died in 1931, her name was Totuya, or Maria Lebrado, she was the granddaughter of Chief Tenaya and one of many forced out of her ancestral homelands in Yosemite National Park. Now the Ahwahneechee live through the memory of their descendants, their fellow Yosemite Natives, and through museums like the Yosemite, California museum exhibit in the Smithsonian and the Yosemite Museum. As a method of self preservation and resilience, the Indigenous people of California proposed treaties in 1851 and 1852 which would have established land reservations for them but Congress refused to sign them. The quest for justice and sovereignty by Yosemite Natives has been ongoing for well over a hundred years. The Southern Sierra Miwuk Nation is still seeking tribal sovereignty and federal recognition, which is critical for their wellbeing and cultural preservation. Progress has been made in terms of the relationship between the U.S. government and tribal governments with the National Park Service creating policies to protect Indigenous sacred sites and allow Natives to return to their homelands and use National Park resources.\nEarly tourists.\n \nIn 1855, entrepreneur James Mason Hutchings, artist Thomas Ayres and two others were the first to tour the area. Hutchings and Ayres were responsible for much of the earliest publicity about Yosemite, writing articles and special magazine issues about the Valley. Ayres' style in art was highly detailed with exaggerated angularity. His works and written accounts were distributed nationally, and an art exhibition of his drawings was held in New York City. Hutchings' publicity efforts between 1855 and 1860 led to an increase in tourism to Yosemite. A number of Natives in Yosemite supported the growing tourism industry by working as laborers or maids. Later, they became part of the tourism industry itself by performing dances for tourists, being guides, and selling handcrafted goods, most notably woven baskets. The Indian village and its peoples were of immense interest to visitors, especially James Hutchings who was a large advocate for Yosemite tourism, he and many others considered the Indigenous presence as one of Yosemite's greatest attractions.\nWawona was an early Indian encampment for Nuchu and Ahwahneechee Natives that were captured and relocated to a reservation on the Fresno River by the Mariposa Battalion and James Savage in March 1851. Settler Galen Clark discovered the Mariposa Grove of giant sequoia in Wawona in 1857. He had simple lodgings built, and roads to the area. In 1879, the Wawona Hotel was built to serve tourists visiting Mariposa Grove. As tourism increased, so did the number of trails and hotels developed by people intending to build on the trade.\nThe Wawona Tree, also known as the Tunnel Tree, was a famous giant sequoia that stood in the Mariposa Grove. It was tall, and was in circumference. When a carriage-wide tunnel was cut through the tree in 1881, it became even more popular as a tourist photo attraction. Everything from horse-drawn carriages in the late 19th century, to automobiles in the first part of the 20th century, traveled the road which passed through that tree. The tree was permanently weakened by the tunnel, and the Wawona Tree fell in 1969 under a heavy load of snow. It was estimated to have been 2,100 years old.\nYosemite's first concession was established in 1884 when John Degnan and his wife established a bakery and store. In 1916, the National Park Service granted a 20-year concession to the Desmond Park Service Company. It bought out or built hotels, stores, camps, a dairy, a garage, and other park services. The Hotel Del Portal was completed in 1908 by a subsidiary corporation of the Yosemite Valley Railroad. It was located at El Portal, California just outside of Yosemite. Desmond changed its name to the Yosemite National Park Company in December 1917 and was reorganized in 1920.\nThe Curry Company had been started in 1899 by David and Jennie Curry to provide concessions in the park. They also founded Camp Curry, formerly known as Half Dome Village, now restored back to Curry Village.\nAdministrators in the National Park Service felt that limiting the number of concessionaires in each national park would be more financially sound. The Curry Company and its rival, the Yosemite National Park Company, were forced to merge in 1925 to form the Yosemite Park & Curry Company (YP&CC). The company built the Ahwahnee Hotel in 1926\u201327.\nYosemite Grant.\nConcerned by the effects of commercial interests, prominent citizens including Galen Clark and Senator John Conness advocated for protection of the area. A park bill was prepared with the assistance of the General Land Office in the Interior Department. The bill passed both houses of the 38th United States Congress, and was signed by President Abraham Lincoln on June 30, 1864, creating the Yosemite Grant. This is the first instance of park land being set aside specifically for preservation and public use by action of the U.S. federal government, and set a precedent for the 1872 creation of Yellowstone as the first national park. Yosemite Valley and the Mariposa Grove were ceded to California as a state park, and a board of commissioners was proclaimed two years later.\nGalen Clark was appointed by the commission as the Grant's first guardian, but neither Clark nor the commissioners had the authority to evict homesteaders (which included Hutchings). The issue was not settled until 1872 when the homesteader land holdings were invalidated by the U.S. Supreme Court. Clark and the reigning commissioners were ousted in 1880, this dispute also reaching the Supreme Court in 1880. The two Supreme Court decisions affecting management of the Yosemite Grant are considered important precedents in land management law. Hutchings became the new park guardian.\nAccess to the park by tourists improved in the early years of the park, and conditions in the Valley were made more hospitable. Tourism significantly increased after the First transcontinental railroad was completed in 1869, but the long horseback ride to reach the area was a deterrent. Three stagecoach roads were built in the mid-1870s to provide better access for the growing number of visitors to Yosemite Valley.\nJohn Muir was a Scottish-born American naturalist and explorer. It was because of Muir that many National Parks were left untouched, such as Yosemite Valley National Park. One of the most significant camping trips Muir took was in 1903 with then-president Theodore Roosevelt. This trip persuaded Roosevelt to return \"Yosemite Valley and Mariposa Grove to federal protection as part of Yosemite National Park\".\nMuir wrote articles popularizing the area and increasing scientific interest in it. Muir was one of the first to theorize that the major landforms in Yosemite Valley were created by large alpine glaciers, bucking established scientists such as Josiah Whitney, who regarded Muir as an amateur. Muir wrote scientific papers on the area's biology. Landscape architect Frederick Law Olmsted emphasized the importance of conservation of Yosemite Valley.\nIncreased protection efforts.\nOvergrazing of meadows (especially by sheep), logging of giant sequoia, and other damage caused Muir to become an advocate for further protection. Muir convinced prominent guests of the importance of putting the area under federal protection; one such guest was Robert Underwood Johnson, editor of \"Century Magazine\". Muir and Johnson lobbied Congress for the Act that created Yosemite National Park on October 1, 1890. The State of California, however, retained control of Yosemite Valley and Mariposa Grove. Muir's writings raised awareness about the damage caused by sheep grazing, and he actively campaigned to virtually eliminate grazing from the Yosemite's high-country ecosystem.\nThe newly created national park came under the jurisdiction of the United States Army's Troop I of the 4th Cavalry on May 19, 1891, which set up camp in Wawona with Captain Abram Epperson Wood as acting superintendent. By the late 1890s, sheep grazing was no longer a problem, and the Army made other improvements. The cavalry could not intervene to ease the worsening condition of Yosemite Valley and Mariposa Grove. From 1899 to 1913, cavalry regiments of the Western Department, including the all Black 9th Cavalry (known as the \"Buffalo Soldiers\") and the 1st Cavalry, stationed two troops at Yosemite.\nMuir and his Sierra Club continued to lobby the government and influential people for the creation of a unified Yosemite National Park. In May 1903, President Theodore Roosevelt camped with Muir near Glacier Point for three days. On that trip, Muir convinced Roosevelt to take control of Yosemite Valley and Mariposa Grove away from California and return it to the federal government. In 1906, Roosevelt signed a bill that did precisely that.\nNational Park Service.\nThe National Park Service was formed in 1916, and Yosemite was transferred to that agency's jurisdiction. Tuolumne Meadows Lodge, Tioga Pass Road, and campgrounds at Tenaya and Merced lakes were also completed in 1916. Automobiles started to enter the park in ever-increasing numbers following the construction of all-weather highways to the park. The Yosemite Museum was founded in 1926 through the efforts of Ansel Franklin Hall. In the 1920s, the museum featured Native Americans practicing traditional crafts, and many of the Southern Sierra Miwok continued to live in Yosemite Valley until they were completely evicted from Yosemite National Park in the 1960s. Although the National Park Service helped create the Yosemite Museum which showcased some Indigenous presence at the time, its early actions and organizational values were detrimental to the Yosemite Natives and the Ahwahneechee. The National Park Service in the early 20th century criticized and even restricted the expression of Indigenous culture and behavior in Yosemite, for instance Park officials penalized Natives for playing games and drinking during the Indian Field Days of 1924. The NPS had more direct and devastating impacts on the Yosemite Natives though. In 1929, Park Superintendent Charles G. Thomson concluded that the Indian village was aesthetically unpleasant and was limiting white settler development. Thomson eventually ordered the camp be burned down. In 1969, many Natives in the Indian village were forced to leave in search of work as a result of the decline in tourism. The NPS demolished those empty houses, evicted the remaining people from their homes, and destroyed the entire village. This was the last Indigenous settlement to exist within Yosemite's Valley and the National Park, effectively removing all the Ahwahneechee People and other Yosemite Natives from their traditional homelands.\nIn 1903, a dam in the northern portion of the park was proposed. Located in the Hetch Hetchy Valley, its purpose was to provide water and hydroelectric power to San Francisco. Muir and the Sierra Club opposed the project, while others, including Gifford Pinchot, supported it. In 1913, the U.S. Congress authorized the O'Shaughnessy Dam through passage of the Raker Act.\nIn 1918, Clare Marie Hodges was hired as the first female Park Ranger in Yosemite. Following Hodges in 1921, Enid Michael was hired as seasonal Park Ranger at a rate of $80 per month. Enid Michael continued to serve in that seasonal position for 20 years.\nIn the late 1920s a bid for Yosemite for the 1932 Winter Olympics was put forward. Ultimately, the 1932 Winter Olympics were awarded to Lake Placid, New York. In 1937, conservationist Rosalie Edge, head of the Emergency Conservation Committee (ECC), successfully lobbied Congress to purchase about 8,000 acres of old-growth sugar pines on the perimeter of Yosemite National Park that were to be logged.\nIn 1984, preservationists persuaded Congress to designate , or about 89 percent of the park, as the Yosemite Wilderness\u2014a highly protected wilderness area. The Park Service has reduced artificial inducements to visit the park, such as the \"Firefall\", in which red-hot embers were pushed off a cliff near Glacier Point at night. Traffic congestion and parking in Yosemite Valley during the summer months has become a concern.\nIn 2016, The Trust for Public Land purchased Ackerson Meadow, a 400-acre tract on the western edge of Yosemite National Park, for $2.3\u00a0million in order to preserve habitat and protect the area from development. Ackerson Meadow was originally included in the proposed 1890 park boundary but never acquired by the federal government. The purchase and donation of the meadow was made possible through a cooperative effort by the Trust for Public Land, the National Park Service, and Yosemite Conservancy. On September 7, 2016, the National Park Service accepted the donation of the land, making the meadow the largest addition to Yosemite since 1949.\nGeography.\nYosemite National Park is located in the central Sierra Nevada of California. Three wilderness areas are adjacent to Yosemite: the Ansel Adams Wilderness to the southeast, the Hoover Wilderness to the northeast, and the Emigrant Wilderness to the north.\nThe park is roughly the size of the U.S. state of Rhode Island and contains thousands of lakes and ponds, of streams, of hiking trails, and of roads. Two federally designated Wild and Scenic Rivers, the Merced and the Tuolumne, begin within Yosemite's borders and flow westward through the Sierra foothills, into the Central Valley of California. On average, about 4\u00a0million people visit the park each year, with most visitor use concentrated in the seven-square-mile (18\u00a0km2) area of Yosemite Valley.\nRocks and erosion.\nAlmost all of the landforms in the Yosemite area are cut from the granitic rock of the Sierra Nevada Batholith (a batholith is a large mass of intrusive igneous rock that formed deep below the surface). About five percent of the park's landforms (mostly in its eastern margin near Mount Dana) are metamorphosed volcanic and sedimentary rocks. These rocks are called \"roof pendants\" because they were once the roof of the underlying granitic rock.\nErosion acting upon different types of uplift-generated joint and fracture systems is responsible for producing the valleys, canyons, domes, and other features. These joints and fracture systems do not move, and are therefore not faults. Spacing between joints is controlled by the amount of silica in the granite and granodiorite rocks; more silica tends to form a more resistant rock, resulting in larger spaces between joints and fractures.\nPillars and columns, such as Washington Column and Lost Arrow, are generated by cross joints. Erosion acting on master joints is responsible for shaping valleys and later canyons. The single most erosive force over the last few million years has been large alpine glaciers, which have turned the previously V-shaped river-cut valleys into U-shaped glacial-cut canyons (such as Yosemite Valley and Hetch Hetchy Valley). Exfoliation (caused by the tendency of crystals in plutonic rocks to expand at the surface) acting on granitic rock with widely spaced joints is responsible for producing domes such as Half Dome and North Dome and inset arches like Royal Arches.\nPopular features.\nYosemite Valley represents only one percent of the park area, but this is where most visitors arrive and stay. The Tunnel View is the first view of the Valley for many visitors and is extensively photographed. El Capitan, a prominent granite cliff that looms over Yosemite Valley, is one of the most popular rock climbing destinations in the world because of its diverse range of climbing routes in addition to its year-round accessibility. Granite domes such as Sentinel Dome and Half Dome rise , respectively, above the valley floor. The park contains dozens of other granite domes.\nThe high country of Yosemite contains beautiful areas such as Tuolumne Meadows, Dana Meadows, the Clark Range, the Cathedral Range, and the Kuna Crest. The Sierra crest and the Pacific Crest Trail run through Yosemite, with peaks of red metamorphic rock, such as Mount Dana and Mount Gibbs, and granite peaks, such as Mount Conness. Mount Lyell is the highest point in the park, standing at . The Lyell Glacier is the largest glacier in Yosemite National Park and is one of the few remaining in the Sierra Nevada.\nThe park has three groves of ancient giant sequoia (\"Sequoiadendron giganteum\") trees; the Mariposa Grove (200 trees), the Tuolumne Grove (25 trees), and the Merced Grove (20 trees). This species grows larger in volume than any other and is one of the tallest and longest-lived.\nWater and ice.\nThe Tuolumne and Merced River systems originate along the crest of the Sierra Nevada in the park and have carved river canyons deep. The Tuolumne River drains the entire northern portion of the park, an area of approximately . The Merced River begins in the park's southern peaks, primarily the Cathedral and Clark Ranges, and drains an area of approximately .\nHydrologic processes, including glaciation, flooding, and fluvial geomorphic response, have been fundamental in creating landforms in the park. The park also contains approximately 3,200 lakes (greater than 100 m2), two reservoirs, and of streams, all of which help form these two large watersheds. Wetlands in Yosemite occur in valley bottoms throughout the park, and are often hydrologically linked to nearby lakes and rivers through seasonal flooding and groundwater movement. Meadow habitats, distributed at elevations from in the park, are generally wetlands, as are the riparian habitats found on the banks of Yosemite's numerous streams and rivers.\nYosemite is famous for its high concentration of waterfalls in a small area. Numerous sheer drops, glacial steps and hanging valleys in the park provide many places for waterfalls to exist, especially during April, May, and June (the snowmelt season). Located in Yosemite Valley, the Yosemite Falls is the highest in North America at . Also in Yosemite Valley is the much lower volume Ribbon Falls, which has the highest single vertical drop, . Perhaps the most prominent of the Yosemite Valley waterfalls is Bridalveil Fall, which is the waterfall seen from the Tunnel View viewpoint at the east end of the Wawona Tunnel. Wapama Falls in Hetch Hetchy Valley is another notable waterfall. Hundreds of ephemeral waterfalls can become active in the park after heavy rains or melting snowpack.\nAll glaciers in the park are relatively small glaciers that occupy areas that are in almost permanent shade, such as north- and northeast-facing cirques. Lyell Glacier is the largest glacier in Yosemite (the Palisades Glaciers are the largest in the Sierra Nevada) and covers . None of the Yosemite glaciers are a remnant of the Ice Age alpine glaciers responsible for sculpting the Yosemite landscape. Instead, they were formed during one of the neoglacial episodes that have occurred since the thawing of the Ice Age (such as the Little Ice Age). Many Yosemite glaciers, such as the Black Mountain Glacier that was discovered in 1871 and gone by the mid-1980s, have disappeared. Yosemite's final two glaciers \u2013 the Lyell and Maclure glaciers \u2013 have receded over the last 100 years and are expected by scientists to eventually disappear as a result of natural melting and climate change.\nClimate.\nYosemite has a Mediterranean climate (K\u00f6ppen climate classification \"Csa\"), meaning most precipitation falls during the mild winter, and the other seasons are nearly dry (less than three percent of precipitation falls during the long, hot summers). Because of orographic lift, precipitation increases with elevation up to where it slowly decreases to the crest. Precipitation amounts vary from at elevation to at . Snow does not typically persist on the ground until November in the high country. It accumulates all winter and into March or early April.\nMean daily temperatures range from to at Tuolumne Meadows at . At the Wawona Entrance (elevation ), mean daily temperature ranges from . At the lower elevations below , temperatures are hotter; the mean daily high temperature at Yosemite Valley (elevation ) varies from . At elevations above , the hot, dry summer temperatures are moderated by frequent summer thunderstorms, along with snow that can persist into July. The combination of dry vegetation, low relative humidity, and thunderstorms results in frequent lightning-caused fires as well.\nAt the park headquarters, with an elevation of , January averages , while July averages , though in summer the nights are much cooler than the hot days. There are an average of 45.5 days with highs of or higher and an average of 105.6 nights with freezing temperatures. Freezing temperatures have been recorded in every month of the year. The record high temperature was on July 22 and July 24, 1915, while the record low temperature was on January 1, 2009. Average annual precipitation is nearly , falling on 67 days. The wettest year was 1983 with and the driest year was 1976 with . The most precipitation in one month was in December 1955 and the most in one day was on December 23, 1955. Average annual snowfall is . The snowiest winter was 1948\u20131949 with . The most snow in one month was in January 1993.\nGeology.\nTectonic and volcanic activity.\nThe area of the park was astride a passive continental margin during the Precambrian and early Paleozoic. Sediment was derived from continental sources and was deposited in shallow water. These rocks have since been deformed and metamorphosed.\nHeat generated from the Farallon Plate subducting below the North American Plate led to the creation of an island arc of volcanoes on the west coast of proto-North America between the late Devonian and Permian periods. Material accreted onto the western edge of North America, and mountains were raised to the east in Nevada.\nThe first phase of regional plutonism started 210\u00a0million years ago in the late Triassic and continued throughout the Jurassic to about 150\u00a0million years before present (BP). Around the same time, the Nevadan orogeny built the Nevadan mountain range (also called the Ancestral Sierra Nevada) to a height of . This was directly part of the creation of the Sierra Nevada Batholith, and the resulting rocks were mostly granitic in composition and emplaced about below the surface. The second major pluton emplacement phase lasted from about 120\u00a0million to 80\u00a0million years ago during the Cretaceous. This was part of the Sevier orogeny.\nStarting 20\u00a0million years ago (in the Cenozoic) and lasting until 5\u00a0million years ago, a now-extinct extension of Cascade Range volcanoes erupted, bringing large amounts of igneous material in the area. These igneous deposits blanketed the region north of the Yosemite region. Volcanic activity persisted past 5\u00a0million years BP east of the current park borders in the Mono Lake and Long Valley areas.\nUplift and erosion.\nStarting 10\u00a0million years ago, vertical movement along the Sierra fault started to uplift the Sierra Nevada. Subsequent tilting of the Sierra block and the resulting accelerated uplift of the Sierra Nevada increased the gradient of western-flowing streams. The streams consequently ran faster and thus cut their valleys more quickly. Additional uplift occurred when major faults developed to the east, especially the creation of Owens Valley from Basin and Range-associated extensional forces. Uplift of the Sierra accelerated again about two million years ago during the Pleistocene.\nThe uplifting and increased erosion exposed granitic rocks in the area to surface pressures, resulting in exfoliation (responsible for the rounded shape of the many domes in the park) and mass wasting following the numerous fracture joint planes (cracks; especially vertical ones) in the now solidified plutons. Pleistocene glaciers further accelerated this process, while glacial meltwater transported the resulting talus and till from valley floors.\nNumerous vertical joint planes controlled where and how fast erosion took place. Most of these long, linear and very deep cracks trend northeast or northwest and form parallel, often regularly spaced sets.\nSculpting by glaciers.\nA series of glaciations further modified the region starting about 2 to 3\u00a0million years ago and ending sometime around 10,000 BP. At least four major glaciations have occurred in the Sierra Nevada, locally called the Sherwin (also called the pre-Tahoe), Tahoe, Tenaya, and Tioga. The Sherwin glaciers were the largest, filling Yosemite and other valleys, while later stages produced much smaller glaciers. A Sherwin-age glacier was almost surely responsible for the major excavation and shaping of Yosemite Valley and other canyons in the area.\nGlacial systems reached depths of up to and left their marks in the Yosemite area. The longest glacier in the Yosemite area ran down the Grand Canyon of the Tuolumne River for , passing well beyond Hetch Hetchy Valley. Merced Glacier flowed out of Yosemite Valley and into the Merced River Gorge. Lee Vining Glacier carved Lee Vining Canyon and emptied into Lake Russel (the much-enlarged ice age version of Mono Lake). Only the highest peaks, such as Mount Dana and Mount Conness, were not covered by glaciers. Retreating glaciers often left recessional moraines that impounded lakes such as the long Lake Yosemite (a shallow lake that periodically covered much of the floor of Yosemite Valley).\nEcology.\nHabitats.\nThe park has an elevation range from and contains five major vegetation zones: chaparral and oak woodland, lower montane forest, upper montane forest, subalpine zone, and alpine. Of California's 7,000 plant species, approximately 50 percent occur in the Sierra Nevada and more than 20 percent are within Yosemite. The park contains suitable habitat for more than 160 rare plants, with rare local geologic formations and unique soils characterizing the restricted ranges many of these plants occupy.\nWith its scrubby sun-baked chaparral, stately groves of pine, fir, and sequoia, and expanses of alpine woodlands and meadows, Yosemite National Park preserves a Sierra Nevada landscape as it prevailed before Euro-American settlement. In contrast to surrounding lands, which have been significantly altered by logging, the park still contains some of old-growth forest. Taken together, the park's varied habitats support over 250 species of vertebrates, which include fish, amphibians, reptiles, birds, and mammals.\nMuch of Yosemite's western boundary has habitats dominated by mixed coniferous forests of ponderosa pine, sugar pine, incense cedar, white fir, Douglas fir, and a few stands of giant sequoia, interspersed by areas of black oak and canyon live oak. A relatively high diversity of wildlife species is supported by these habitats, because of relatively mild, lower-elevation climate and the mixture of habitat types and plant species. Wildlife species typically found in these habitats include black bear, coyote, raccoon, mountain kingsnake, Gilbert's skink, white-headed woodpecker, bobcat, river otter, gray fox, red fox, brown creeper, two species of skunk, cougar, spotted owl, and a wide variety of bat species.\nGoing higher in elevation, the coniferous forests become purer stands of red fir, western white pine, Jeffrey pine, lodgepole pine, and the occasional foxtail pine. Fewer wildlife species tend to be found in these habitats, because of their higher elevation and lower complexity. Species likely to be found include golden-mantled ground squirrel, chickaree, fisher, Steller's jay, hermit thrush, and northern goshawk. Reptiles are not common, but include rubber boa, western fence lizard, and northern alligator lizard.\nAs the landscape rises, trees become smaller and more sparse, with stands broken by areas of exposed granite. These include lodgepole pine, whitebark pine, and mountain hemlock that, at highest elevations, give way to vast expanses of granite as treeline is reached. The climate in these habitats is harsh and the growing season is short, but species such as pika, yellow-bellied marmot, white-tailed jackrabbit, Clark's nutcracker, and black rosy finch are adapted to these conditions. Also, the treeless alpine habitats are the areas favored by Sierra Nevada bighorn sheep. This species, however, is now found in the Yosemite area only around Tioga Pass, where a small, reintroduced population exists.\nAt a variety of elevations, meadows provide important, productive habitat for wildlife. Animals come to feed on the green grasses and use the flowing and standing water found in many meadows. Predators, in turn, are attracted to these areas. The interface between meadow and forest is also favored by many animal species because of the proximity of open areas for foraging and cover for protection. Species that are highly dependent upon meadow habitat include great grey owl, willow flycatcher, Yosemite toad, and mountain beaver.\nManagement issues.\nThe black bears of Yosemite were once famous for breaking into parked cars to steal food. They were also an encouraged tourist sight for many years at the park's garbage dumps, where bears congregated to eat park visitors' garbage and tourists gathered to photograph the bears. Increasing encounters between bears and humans and increasing damage to property led to an aggressive campaign to discourage bears from relying on human food or interacting with people and their property. The open-air dumps were closed; all trash receptacles were replaced with bear-proof receptacles; all campgrounds were equipped with bear-proof food lockers so that people would not leave food in their vehicles, which were easy targets for the powerful and resourceful bears. Because bears who show aggression towards people usually are eventually destroyed, park personnel have continued to come up with innovative ways to have bears associate humans and their property with unpleasant experiences, such as being hit with rubber bullets. , about 30 bears a year are captured and ear-tagged and their DNA is sampled so that, when bear damage occurs, rangers can ascertain which bear is causing the problem.\nDespite the richness of high-quality habitats in Yosemite, the brown bear, California condor, and least Bell's vireo have become extinct in the park within historical time, and another 37 species currently have special status under either California or federal endangered species legislation. The most serious current threats to Yosemite's wildlife and the ecosystems they occupy include loss of a natural fire regime, exotic species, air pollution, habitat fragmentation, and climate change. On a more local basis, factors such as road kills and the availability of human food have affected some wildlife species.\nYosemite National Park has documented more than 130 non-native plant species within park boundaries. These non-native plants were introduced into Yosemite following the migration of early Euro-American settlers in the late 1850s. Natural and human-caused disturbances, such as wildland fires and construction activities, have contributed to a rapid increase in the spread of non-native plants. A number of these species aggressively invade and displace the native plant communities, resulting in impacts on the park's resources. Non-native plants can bring about significant changes in park ecosystems by altering the native plant communities and the processes that support them. Some non-native species may cause an increase in the fire frequency of an area or increase the available nitrogen in the soil that may allow more non-native plants to become established. Many non-native species, such as yellow star thistle (\"Centaurea solstitialis\"), are able to produce a long tap root that allows them to out-compete the native plants for available water.\nBull thistle (\"Cirsium vulgare\"), common mullein (\"Verbascum thapsus\"), and Klamath weed (\"Hypericum perforatum\") have been identified as noxious pests in Yosemite since the 1940s. Additional species that have been recognized more recently as aggressive and requiring control are yellow star thistle (\"Centaurea solstitialis\"), sweet clover (\"Melilot\" spp.), Himalayan blackberry (\"Rubus armeniacus\"), cut-leaved blackberry (\"Rubus laciniatus\") and large periwinkle (\"Vinca major\").\nIncreasing ozone pollution is causing tissue damage to the massive giant sequoia trees in the park, making them more vulnerable to insect infestation and disease. Since the cones of these trees require fire-touched soil to germinate, historic fire suppression has reduced these trees' ability to reproduce. The current policy of setting prescribed fires is expected to help the germination issue.\nWildfires.\nNatives to Yosemite traditionally and intentionally set small fires in the valley in the early 1860s and much earlier before that to clear the ground of brush as part as their farming practices, resulting in easier crop growth and faster cultivation. These fires that Yosemite Natives lit are comparable to contemporary practices like controlled burns which are done by the U.S. Forest Service and other environmental experts. Although it was not their primary concern for setting these fires, the Ahwahneechee and other Yosemite Natives helped preserve local biodiversity and ecosystem resilience by lighting these small fires. Native Americans used fire as an early wildlife management tool to keep certain lands clear, resulting in more food for large animals and decreasing the chance of large forest fires which devastate forest ecosystems in modern times. Some early uncontrolled forest fires were set accidentally by the militia group led by Major John Savage when the group burned down the Ahwahneechee camp in an attempt to remove them from the land. The houses that they lit on fire eventually caught a large section of the forest on fire and the militia group ended up having to abandon their raid to save their own camp from the wildfire they started.\nForest fires seasonally clear the park of dead vegetation, making way for new growth. These fires damage the income generated by tourism. During late July and early August, 2018, sections of the park, including the Valley, were temporarily closed due to the Ferguson Fire at its western boundary. The closing was the largest in almost thirty years at the park.\nActivities.\nCamping and public access.\nYosemite Valley is open year-round and numerous activities are available through the National Park Service, Yosemite Conservancy, and Aramark at Yosemite, including nature walks, photography and art classes, stargazing programs, tours, bike rentals, rafting, mule and horseback rides, and rock climbing classes. Many people enjoy short walks and longer hikes to waterfalls in Yosemite Valley, or walks among giant sequoias in the Mariposa, Tuolumne, or Merced Groves. Others like to drive or take a tour bus to Glacier Point (summer\u2013fall) to see views of Yosemite Valley and the high country, or drive along the scenic Tioga Road to Tuolumne Meadows (May\u2013October) and go for a walk or hike.\nMost park visitors stay just for the day, and visit only those locations within Yosemite Valley that are easily accessible by automobile. There is a US$35 per automobile user fee to enter the park, which is valid for 7 consecutive days. Traffic congestion in the valley is a serious problem during peak season, in summer. A free shuttle bus system operates year-round in the valley, and park rangers encourage people to use this system since parking within the valley during the summer is often nearly impossible to find. Transit options are available from Fresno and Merced. Yosemite also has 13 official campgrounds where visitors can camp. \nIn addition to exploring the natural features of the park, visitors can also learn about the natural and cultural history of Yosemite Valley at a number of facilities in the valley: the Yosemite Valley Visitor Center, the adjoining Yosemite Museum, and the Nature Center at Happy Isles. There are also two National Historic Landmarks: the Sierra Club's LeConte Memorial Lodge (Yosemite's first public visitor center), and the Ahwahnee Hotel. Camp 4 was added to the National Register of Historic Places in 2003.\nIn the winter, it is snowed in, but the area of Tuolumne Meadows has a great deal of hiking, rock climbing, and mountain climbing; see also the highest mountains of Yosemite National Park.\nHiking.\nOver of trails are available to hikers\u2014everything from an easy stroll to a challenging mountain hike, or an overnight backpack trip. One of the most popular trails leads to the summit of Half Dome and requires an advance permit from Memorial Day weekend in late May, to Columbus Day in early October. A maximum of 300 hikers, selected by lottery, are permitted to advance beyond the base of the subdome each day, including 225 day hikers and 75 backpackers.\nThe park can be divided into five sections for the day-user\u2014Yosemite Valley, Wawona/Mariposa Grove/Glacier Point, Tuolumne Meadows, Hetch Hetchy, and Crane Flat/White Wolf. Numerous books describe park trails, and free information is available from the National Park Service in Yosemite. Park rangers encourage visitors to experience portions of the park in addition to Yosemite Valley.\nBetween late spring and early fall, much of the park can be accessed for multiple-day backpacking trips. All overnight trips into the back country require a wilderness permit and most require approved bear-resistant food storage.\nDriving destinations.\nWhile some locations in Yosemite require hiking, other locations can be reached via automobile transportation. Driving locations also allow guests to observe the night sky in locations other than their campsite or lodge. All of the roads in Yosemite are scenic, but the most famous is the Tioga Road, typically open from late May or early June through November.\nAs an alternative to driving, bicycles are allowed on the roads. However, bicycles are allowed off-road on only of paved trails in Yosemite Valley itself; mountain biking is not allowed.\nClimbing.\nRock climbing is an important part of Yosemite. In particular Yosemite Valley, which is surrounded by famous summits like Half Dome and El Capitan. Camp 4, a walk-in campground in the Valley, was instrumental in the development of rock climbing as a sport, and is listed on the National Register of Historic Places. Climbers can generally be spotted in the snow-free months on anything from ten-foot-high (3\u00a0m) boulders to the face of El Capitan. Classes on rock climbing are offered by numerous groups.\nWinter activities.\nYosemite Valley is open all year, although some roads within the park close in winter. Downhill skiing is available at the Badger Pass Ski Area\u2014the oldest downhill skiing area in California, offering downhill skiing from mid-December through early April. Much of the park is open to cross-country skiing and snowshoeing, with several backcountry ski huts open for use. Wilderness permits are required for backcountry overnight ski trips.\nThe Bracebridge dinner is an annual holiday event, held since 1927 at the Ahwahnee Hotel, inspired by Washington Irving's descriptions of Squire Bracebridge and English Christmas traditions of the 18th century in his \"Sketch Book\". Between 1929 and 1973, the show was organized by Ansel Adams.\nOther.\nBicycle rentals are available in Yosemite Valley spring through fall. Over of paved bike paths are available in Yosemite Valley. In addition, bicyclists can ride on regular roads. Helmets are required by law for children under 18 years of age. Off-trail riding and mountain biking are not permitted in Yosemite National Park.\nWater activities are plentiful during warmer months. Rafting can be done through the Yosemite Valley on the Merced River from late May to July. There are also swimming pools available at Yosemite Lodge and Curry Village.\nIn 2010, Yosemite National Park was honored with its own quarter under the America the Beautiful Quarters program.\nHorsetail Fall.\nHorsetail Fall flows over the eastern edge of El Capitan in Yosemite Valley. This small waterfall usually flows only during winter and is easy to miss. On rare occasions during mid- to late February, it can glow orange when it's backlit by sunset. This unique lighting effect happens only on evenings with a clear sky when the waterfall is flowing. Even some haze or minor cloudiness can greatly diminish or eliminate the effect. Although entirely natural, the phenomenon is reminiscent of the human-caused Firefall that historically occurred from Glacier Point.\nIn popular culture.\nThe opening scenes of \"\" (1989) were filmed in Yosemite National Park. Films such as \"The Last of the Mohicans\" (1920) and \"Maverick\" (1994) have also been shot here. The 2014 documentary \"Valley Uprising\" is centered around Yosemite Valley and its history with an emphasis on the climbing culture. The Academy Award-winning 2018 documentary \"Free Solo\" was filmed in Yosemite. \"The Dawn Wall,\" a 2017 documentary, was also filmed in Yosemite.", "categories": ["Category:1890 establishments in California", "Category:All Wikipedia articles in need of updating", "Category:All Wikipedia articles written in American English", "Category:All articles containing potentially dated statements", "Category:Articles containing potentially dated statements from 2001", "Category:Articles with GND identifiers", "Category:Articles with ISNI identifiers", "Category:Articles with J9U identifiers", "Category:Articles with LCCN identifiers", "Category:Articles with NARA identifiers"]}, {"docid": 20041526, "title": "Overpopulation", "text": "Overpopulation or overabundance is a phenomenon in which a species' population becomes larger than the carrying capacity of its environment. This may be caused by increased birth rates, lowered mortality rates, reduced predation or large scale migration, leading to an overabundant species and other animals in the ecosystem competing for food, space, and resources. The animals in an overpopulated area may then be forced to migrate to areas not typically inhabited, or die off without access to necessary resources.\nJudgements regarding overpopulation always involve both facts and values. Animals often are judged overpopulated when their numbers cause impacts that people find dangerous, damaging, expensive, or otherwise harmful. Societies may be judged overpopulated when their human numbers cause impacts that degrade ecosystem services, decrease human health and well-being, or crowd other species out of existence.\nBackground.\nIn ecology, overpopulation is a concept used primarily in wildlife management. Typically, an overpopulation causes the entire population of the species in question to become weaker, as no single individual is able to find enough food or shelter. As such, overpopulation is thus characterized by an increase in the diseases and parasite-load which live upon the species in question, as the entire population is weaker. Other characteristics of overpopulation are lower fecundity, adverse effects on the environment (soil, vegetation or fauna) and lower average body weights. Especially the worldwide increase of deer populations, which usually show irruptive growth, is proving to be of ecological concern. Ironically, where ecologists were preoccupied with conserving or augmenting deer populations only a century ago, the focus has now shifted in the direct opposite, and ecologists are now more concerned with limiting the populations of such animals.\nSupplemental feeding of charismatic species or interesting game species is a major problem in causing overpopulation, as is too little hunting or trapping of such species. Management solutions are increasing hunting by making it easier or cheaper for (foreign) hunters to hunt, banning supplemental feeding, awarding bounties, forcing landowners to hunt or contract professional hunters, using immunocontraception, promoting the harvest of venison or other wild meats, introducing large predators (rewilding), poisonings or introducing diseases.\nA useful tool in wildlife culling is the use of mobile freezer trailers in which to store carcasses. The harvest of meat from wild animals is a sustainable method of creating a circular economy.\nImmunocontraception is a non-lethal method of regulating wild-animal population growth. Immunocontraception has been successfully used or tested in a variety of wild-animal populations including those of bison, deer, elephants, gray squirrels, pigeons, rats and wild horses. Among the limitations of injectable immunocontraceptives are a relatively long time between vaccine administration and a reduction in population size (although stabilization of population size occurs faster) and the need to be in close proximity with animals for injection. Oral vaccines do not have the latter limitation, but they are still not as well developed as injectable vaccines.\nJudgements about overpopulation of wildlife or domestic animals typically are made in terms of human purposes and interests; since these vary, such judgements may vary, too. Judgements about human overpopulation are even more contentious, since the purposes and interests involved may be very important, even rising to the level of existence itself. Nevertheless, all people and every society have an interest in preserving a habitable biosphere, which may be compromised or degraded by too may people. In the context of rapid climate change, mass species extinction and other global environmental problems, discussions regarding human overpopulation are inevitable.\nRecent scientific evidence from many sources suggests Earth may be overpopulated currently. Evidence of rapidly declining ecosystem services was presented in detail in the Millennium Ecosystem Assessment of 2005, a collaborative effort involving more than 1,360 experts worldwide. More recent scientific accounts are provided by ecological footprint accounting and interdisciplinary research on planetary boundaries for safe human use of biosphere. The Sixth Assessment Report on Climate Change from the IPCC and the First Assessment Report on Biodiversity and Ecosystem Services by the IPBES, large international summaries of the state of scientific knowledge regarding climate disruption and biodiversity loss, also support the view that unprecedented human numbers are contributing to global ecological decline. Recent estimates of a sustainable global human population run between two and four billion people.\nJudgements about human or animal overpopulation hinge partly on whether people feel a moral obligation to leave sufficient habitat and resources to preserve viable populations of other species. Recent biodiversity losses show that humanity's success in supporting larger human populations over the past century has depended on reducing the populations of many of Earth's other species. This is a special example of the competitive exclusion principle in ecology, which states that two species which compete for the same limited resource cannot coexist at constant population values. Today humanity essentially competes with other species everywhere on Earth. We thus face choices regarding whether to preserve populations of other species and limit our own, or not. These essentially ethical choices \u00a0will make a difference in future judgements about overpopulation.\nWell studied species.\nDeer.\nIn Scotland the program of having landowners privately cull the overpopulation of red deer in the highlands has proved an abject failure. Scotland's deer are stunted, emaciated, and frequently starve in the Spring. As of 2016 the population is now so high, that 100,000 deer would need to be culled each year only to maintain the current population. A number of landowners have proven unwilling to accede to the law, requiring government intervention anyway. It has been necessary to contract professional hunters in order to satisfy landowner legislation regarding the annual cull. Millions of pounds of taxpayers' cash is spent on the annual cull. As of 2020, 100,000 deer are shot each year. Compounding the problem, some landowners have used supplemental feeding at certain shooting blinds in order to ease sport hunting.\nOverpopulation can have effects on forage plants, eventually causing a species to alter the greater environment. Natural ecosystems are extremely complex. The overpopulation of deer in Britain has been caused by legislation making hunting more difficult, but another reason may be the proliferation of forests, used by different deer species to breed and shelter. Forests and parks have caused Britain to be much more forested than it was in recent history, and may thus perversely be causing biodiversity loss, conversion of heath habitat to grassland, extirpation of grassland and woodland plants due to overgrazing and the changing of the habitat structure. Examples are bluebells and primroses. Deer open up the forest and reduce the amount of brambles, which then has knock-on effects on dormice and certain birds which nest near the ground, such as the capercaillie, dunnock, nightingale, song thrush, willow warbler, marsh tit, willow tit and bullfinch. Populations of the nightingale and the European turtle dove are believed to be primarily impacted by muntjac. Grouse populations suffer due to smashing into the fencing needed to protect against deer.\nA significant amount of the environmental destruction in Britain is caused by an overabundance of deer. Besides ecological effects, overpopulation of deer causes economic effects due to browsing on crops, expensive fencing needed to combat this and protect new afforestation planting and coppice growth, and increasing numbers of road traffic incidents. High populations cause stripping of the bark of trees, eventually destroying forests. Protecting forests from deer costs on average three times as much as planting the forest in the first place. The NGO Trees for Life spent weeks planting native trees in Scotland, aiming to rebuild the ancient Caledonian Forest. After winter snowdrifts in 2014/2015 flattened the deer fences, more than a decade's growth was lost in a matter of weeks. In 2009 \u2013 2010 the cost of forest protection in Scotland ran to \u00a310.5m.\nSome animals, such as muntjac, are too small and boring for most hunters to shoot, which poses additional management problems.\nIn the United States the exact same problem is seen with white-tailed deer, where populations have exploded and become invasive species in some areas. The state of Wisconsin has an estimated population of 1.9 million White tail deer, measured in 2020. In continental Europe roe deer pose a similar problem, although the populations were formerly much less, they have swelled in the 20th century so that although two and a half million are shot each year by hunters in Western Europe alone, as of 1998, the population still appears to be increasing, causing problems for forestry and traffic. In an experiment where roe deer on a Norwegian island were freed from human harvest and predators, the deer showed a doubling of the population each year or two. In the Netherlands and southern England roe deer were extirpated from the entirety of the country except for a few small areas around 1875. In the 1970s the species was still completely absent from Wales, but as of 2013, it has colonized the entire country. As new forests were planted in the Netherlands in the 20th century, the population began to expand rapidly. As of 2016 there are some 110,000 deer in the country.\nBirds.\nAquaculture operations, recreation angling and populations of endangered fish such as the schelly are impacted by cormorant populations. Open aquaculture ponds provide winter or year-round homes and food for cormorants. Cormorants' effect on the aquaculture industry is significant, with a dense flock capable of consuming an entire harvest. Cormorants are estimated to cost the catfish industry in Mississippi alone between $10 million and $25 million annually. Cormorant culling is commonly achieved by sharp-shooting, nest destruction, roost dispersal and oiling the eggs.\nGeese numbers have also been called overpopulated. In the Canadian Arctic region, snow geese, Ross's geese, greater white-fronted geese and some populations of Canada geese have been increasing significantly over the past decades. Lesser snow geese populations have increased to over three million, and continue to increase by some 5% per year. Giant Canada geese have grown from near extinction to nuisance levels, in some areas. Average body sizes have decreased and parasite loads are higher. Before the 1980s, Arctic geese populations had boom and bust cycles (see above) thought to be based on food availability, although there are still some bust years, this no longer seems the case.\nIt is difficult to know what the numbers of geese were before the 20th century, before human impact presumably altered them. There are a few anecdotal claims from that time of two or three million, but these are likely exaggerations, as that would imply a massive die-off or vast amounts harvested, for which there is no evidence. More likely estimates from the period of 1500 to 1900 are a few hundred thousand animals, which implies that with the exception of Ross's geese, modern populations of geese are many millions more than in pre-industrial levels.\nHumans are blamed as the ultimate cause for the increase, directly and indirectly, due to management legislation limiting hunting introduced specifically in order to protect bird populations, but most importantly due to the increase in agriculture and large parks, which has had the effect of creating vast amounts of unintentional sanctuaries filled with food. Urban geese flocks have increased enormously. City ordinances generally prohibit discharging firearms, keeping such flocks safe, and there is abundant food. Geese profit from agricultural grain crops, and seem to be shifting their habitat preferences to such farmlands. Reduction of goose hunting in the US since the 1970s seems to have further had the effect of protecting populations. In Canada hunting has also decreased dramatically, from 43.384% harvest rates in the 1960s to 8% in the 1990s. Nonetheless, when kill rates were compared to populations, hunting alone does not seems to be solely responsible for the increase -weather or a not yet completed shift in habitat preference to agricultural land may also be factors. Although hunting may have formerly been the main factor in maintaining stable populations, ecologists no longer consider it a practical management solution, as public interest in the practice has continued to wane, and the population is now so large that the massive culls needed are unrealistic to ask from the public. Climate change in the Arctic would appear to be an obvious cause for the increase, but when subpopulations are correlated with local climatic increases, this does not seem to hold true, and furthermore, breeding regions seem to be shifting southwards anyway, irrespective of climate change.\nThe nutrient subsidy provided by foraging in agricultural land may have made the overall landscape use by geese unsustainable. Where such geese congregate local plant communities have been substantially altered; these chronic effects are cumulative, and have been considered a threat to the Arctic ecosystems, due to knock-on effects on native ducks, shorebirds and passerines. Grubbing and overgrazing by geese completely denudes the tundra and marshland, in combination with abiotic processes, this creates large desert expanses of hypersaline, anoxic mud which continue to increase each year. Biodiversity drops to only one or two species which are inedible for geese, such as \"Senecio congestus\", \"Salicornia borealis\" and \"Atriplex hastata\". Because grazing occurs in serial stages, with biodiversity decreasing at each stage, floral composition may be used as an indicator of the degree of goose foraging at a site. Other effects are destruction of the vegetation holding dunes in place, the shift from sedge meadows and grassy swards with herbaceous plants to moss fields, which can eventually give way to bare ground called 'peat barrens', and the erosion of this bare peat until glacial gravel and till is bared. In the High Arctic research is less developed: \"Eriophorum scheuchzeri\" and \"E. angustifolium\" fens appear to be affected, and are being replaced by carpets of moss, whereas meadows covered in \"Dupontia fisheri\" appear to be escaping destruction. There does not appear to be the damage found at lower latitudes in the Arctic. There is little proper research in effects on other birds. The yellow rail (\"Coturnicops noveboracensis\") appears to be extirpated from areas of Manitoba due habitat loss caused by the geese, whereas on the other hand the semipalmated plover (\"Charadrius semipalmatus\") appears to be taking advantage of the large areas of dead willows as a breeding ground.\nIn the wintering grounds in continental USA, effects are much less pronounced. Experimentally excluding geese by means of fencing in North Carolina has found heavily affected areas can regenerate after only two years. Bulrush stands (\"Schoenoplectus americanus\") are still an important component of the diet, but there are indications the bulrush is being impacted, with soft mudflats gradually replacing areas where it grows.\nDamage to agriculture is primarily to seedlings, winter wheat and hay production. Changing the species composition to species less palatable to geese, such as \"Lotus\" may alleviate losses in hay operations. Geese also feed on agricultural land without causing economic loss, gleaning seeds from corn, soya or other grains and feeding on wheat, potato and corn stubble. In Qu\u00e9bec crop damage insurance for the hay industry began in 1992 and claims increased yearly; actual compensation paid by the government, including administrative costs, amount to some half a million dollars a year.\nThe fact that Arctic regions are remote, there is little public understanding for combatting the problem, and ecologists as yet do not have any effective solutions for combatting the problem anyway. In Canada, the most important hunters of geese are the Cree people around Hudson Bay, members of the Mushkegowuk Harvesters Association, with an average kill rate of up to 60.75 birds per species per hunter in the 1970s. Kill rates have dropped, with hunters taking only half as much in the 1990s. However, total numbers of kills have increased, i.e. there are more hunters, but they are killing less per person. Nonetheless, per household the kills are approximately the same, at 100 birds. This indicates that stimulating an increase in native hunting might be difficult to achieve. The Cree population has increased. Elders say the taste of the birds has gotten worse, and they are thinner, both possibly effects due to the overpopulation. Elders also say that hunting has gotten more difficult, because there are less young and goslings, which are more likely to fall for decoys. Inuit and other people in the north do much less hunting of geese, with kill rates of 1 to 24 per species per hunter. Per kilogram, hunters save some $8.14 to $11.40 from buying poultry at stores. Total kill numbers from hunters elsewhere in the US and southern Canada has been falling steadily. This is blamed on a decline in people interested in hunting, more feeding areas for the birds, and larger flocks with more experienced adult birds which makes decoying difficult. Individual hunters are bagging higher numbers, compensating lower hunter numbers.\nManagement strategies in the USA include increasing the bag limit and the number of open hunting days, goose egg addling, trapping and relocation, and egg and nest destruction, managing habitat to make it less attractive to geese, harassment and direct culling. In Denver, Colorado, during moulting season biologists rounded up 300Canada geese (of 5,000 in the city), ironically on Canada Day, killing them and distributing the meat to needy families (as opposed to sending it to a landfill), to try to curb the number of geese, following such programs in New York, Pennsylvania, Oregon and Maryland. Complaints about the birds were that they had taken over the golf courses, pooped all over the place, devoured native plants and scared citizens. Such culls have proven socially controversial, with intense backlash by some citizens. Park officials had tried dipping eggs in oil, using noise-makers and planting tall plants, but this was not sufficient.\nIn Russia, the problem does not seem to exist, likely due to human harvest and local long-term cooling climate trends in the Russian Far East and Wrangel Island.\nIt is also possible that the population growth is completely natural, and that when the carrying capacity of the environment is reached the population will stop growing. For organisations such as Ducks Unlimited, the resurgence of goose populations in North America can be called one of the greatest success story in wildlife management. By 2003 the US goose harvest was approaching 4 million, three times the numbers 30 years previously.\nPets.\nIn the United States, over half of the households own a dog or a cat. Even with so much pet ownership there is still an issue with pet overpopulation, especially seen in shelters. Because of this problem it is estimated that between 10 and 25 percent of dogs and cats are killed yearly. The animals are killed humanely, but the goal is to greatly lower and eventually completely avoid this. Estimating the overpopulation of pets, especially cats and dogs, is a difficult task, but it has been a continuous problem. It has been hard to determine the number of shelters and animals in each shelter around even just the US. Animals are constantly being moved around or euthanized, so it is difficult to keep track of those numbers across the country. It is becoming universally agreed upon that sterilization is a tool that can help reduce population size so that less offspring are produced in the future With less offspring, pet populations can start to decrease which reduces the amount that get killed each year.\nPopulation cycles.\nIn the wild, rampant population growth of prey species often causes growth in the populations of predators. Such predator-prey relationships can form cycles, which are usually mathematically modelled as Lotka\u2013Volterra equations.\nIn natural ecosystems, predator population growth lags just behind the prey populations. After the prey population crashes, the overpopulation of predators causes the entire population to be subjected to mass starvation. The population of the predator drops, as less young are able to survive into adulthood. This could be considered a perfect time for wildlife managers to allow hunters or trappers to harvest as much of these animals as necessary, for example lynx in Canada, although on the other hand this may impact the ability of the predator to rebound when the prey population begins to exponentially increase again. Such mathematical models are also crucial in determining the amount of fish which may be sustainably harvested in fisheries, this is known as the maximum sustainable yield.\nPredator population growth has the effect of controlling the prey population, and can result in the evolution of prey species in favour of genetic characteristics that render it less vulnerable to predation (and the predator may co-evolve, in response).\nIn the absence of predators, species are bound by the resources they can find in their environment, but this does not necessarily control overpopulation, at least in the short term. An abundant supply of resources can produce a population boom followed by a population crash. Rodents such as lemmings and voles have such population cycles of rapid growth and subsequent decrease. Snowshoe hares populations similarly cycle dramatically, as did those of one of their predators, the lynx. Another example is the cycles among populations of grey wolves and moose in Isle Royale National Park. For some still unexplained reason, such patterns in mammal population dynamics are more prevalent in ecosystems found at more arctic latitudes.\nSome species such as locusts experience large natural cyclic variations, experienced by farmers as plagues.\nDetermining population size/density.\nWhen determining whether a population is overpopulated a variety of factors must be looked at. Given the complexity of the issue, scientists and wildlife managers often differ in judging such claims. In many cases scientists will look to food sources and living space to gauge the abundance of a species in a particular area. National parks collect extensive data on the activities and quality of the environment they are established in. This data can be used to track whether a specific species is consuming larger amounts of their desired food source over time.\nThis is done typically in four ways, the first being \"total counting\". Researchers will use aerial photography to count large populations in a specific area such as deer, waterfowl, and other \"flocking\" or \"herd\" animals. Incomplete counts involve counting a small subsection of a population and extrapolating the data across the whole area. This method will take into account the behavior of the animals such as how much territory a herd may cover, the density of the population, and other potential factors that may come into question.\nThe third method is \"indirect counts\"; this is done by looking at the environment for signs of animal presence. Typically done by counting fecal matter or dens/nesting of a particular animal. This method is not as accurate as direct counting, but gives general counts of a population in a specific locale.\nLastly the method of mark-recapture is used extensively to determine general population sizes. This method involves the trapping of animals after which some form of tag is placed on the animal and it is released back into the wild. After which, other trappings will determine population size based on the number of marked versus unmarked animals.\nFish populations.\nSimilar methods can be used to determine the population of fish however some key differences arise in the extrapolation of data. Unlike many land animals in-land fish populations are divided into smaller population sizes. Factors such as migration may not be relevant when determining population in a specific locales while more important for others such as the many species of salmon or trout. Monitoring of waterways and isolated bodies of water provide more frequently updated information on the populations in specific areas. This is done using similar methods to the mark-recapture methods of many land animals.\nIntroduced species.\nThe introduction of a foreign species has often caused ecological disturbance, such as when deer and trout were introduced into Argentina, or when rabbits were introduced to Australia and predators were introduced in turn to attempt to control the rabbits.\nWhen an introduced species is so successful that its population begins to increase exponentially and causes deleterious effects to farmers, fisheries, or the natural environment, these introduced species are called invasive species.\nIn the case of the Mute swan, \"Cygnus olor\", their population has rapidly spread across much of North America as well as parts of Canada and western Europe. This species of swan has caused much concern for wildlife management as they damage aquatic vegetation, and harass other waterfowl, displacing them. The population of the Mute swan has seen an average increase of around 10-18% per year which further threatens to impact the areas they inhabit. Management of the species comes in a variety of ways. Similar to overpopulated or invasive species, hunting is one of the most effective methods of population control. Other methods may involve trapping, relocation, or euthanasia.\nCriticism.\nIn natural ecosystems, populations naturally expand until they reach the carrying capacity of the environment; if the resources on which they depend are exhausted, they naturally collapse. According to the animal rights movement, calling this an 'overpopulation' is more an ethics question than a scientific fact. Animal rights organisations are commonly critics of ecological systems and wildlife management. Animal rights activists and locals earning income from commercial hunts counter that scientists are outsiders who do not know wildlife issues, and that any slaughter of animals is evil.\nVarious case studies indicate that use of cattle as 'natural grazers' in many European nature parks due to absence of hunting, culling or natural predators (such as wolves),may cause an overpopulation because the cattle do not migrate. This has the effect of reducing plant biodiversity, as the cattle consume native plants. Because such cattle populations begin to starve and die in the winter as available forage drops, this has caused animal rights activists to advocate supplemental feeding, which has the effect of exacerbating the ecological effects, causing nitrification and eutrophication due to excess faeces, deforestation as trees are destroyed, and biodiversity loss.\nDespite the ecological effects of overpopulation, wildlife managers may want such high populations in order to satisfy public enjoyment of seeing wild animals. Others contend that introducing large predators such as lynx and wolves may have similar economic benefits, even if tourists rarely actually catch glimpses of such creatures.\nIn regards to population size, most of the methods used give estimates that vary in accuracy to the actual size and density of the population. Criticisms of theses methods generally fall onto the efficacy of methods used.\nHuman overpopulation.\nOverpopulation can result from an increase in births, a decline in mortality rates against the background of high fertility rates. It is possible for very sparsely populated areas to be overpopulated if the area has a meagre or non-existent capability to sustain life (e.g. a desert). Advocates of population moderation cite issues like quality of life and risk of starvation and disease and human pressures on the environment as a basis to argue against continuing high human population growth and for population decline.", "categories": ["Category:All articles covered by WikiProject Wikify", "Category:All articles with unsourced statements", "Category:All pages needing cleanup", "Category:Articles covered by WikiProject Wikify from January 2021", "Category:Articles with excerpts", "Category:Articles with short description", "Category:Articles with unsourced statements from April 2021", "Category:Articles with unsourced statements from April 2022", "Category:CS1: Julian\u2013Gregorian uncertainty", "Category:CS1 errors: missing periodical"]}, {"docid": 2607068, "title": "Giant otter", "text": "The giant otter or giant river otter (Pteronura brasiliensis) is a South American carnivorous mammal. It is the longest member of the weasel family, Mustelidae, a globally successful group of predators, reaching up to . Atypical of mustelids, the giant otter is a social species, with family groups typically supporting three to eight members. The groups are centered on a dominant breeding pair and are extremely cohesive and cooperative. Although generally peaceful, the species is territorial, and aggression has been observed between groups. The giant otter is diurnal, being active exclusively during daylight hours. It is the noisiest otter species, and distinct vocalizations have been documented that indicate alarm, aggression, and reassurance.\nThe giant otter ranges across north-central South America; it lives mostly in and along the Amazon River and in the Pantanal. Its distribution has been greatly reduced and is now discontinuous. Decades of poaching for its velvety pelt, peaking in the 1950s and 1960s, considerably diminished population numbers. The species was listed as endangered in 1999 and wild population estimates are typically below 5,000. The Guianas are one of the last real strongholds for the species, which also enjoys modest numbers \u2013 and significant protection \u2013 in the Peruvian Amazonian basin. It is one of the most endangered mammal species in the Neotropics. Habitat degradation and loss is the greatest current threat. The giant otter is also rare in captivity; in 2003, only 60 animals were being held.\nThe giant otter shows a variety of adaptations suitable to an amphibious lifestyle, including exceptionally dense fur, a wing-like tail, and webbed feet. The species prefers freshwater rivers and streams, which are usually seasonally flooded, and may also take to freshwater lakes and springs. It constructs extensive campsites close to feeding areas, clearing large amounts of vegetation. The giant otter subsists almost exclusively on a diet of fish, particularly characins and catfish, but may also eat crabs, turtles, snakes and small caimans. It has no serious natural predators other than humans, although it must compete with other predators, such as the Neotropical otter and various crocodilian species, for food resources.\nName.\nThe giant otter has a handful of other names. In Brazil it is known as \"ariranha\", from the Tup\u00ed word , meaning water jaguar (). In Spanish, river wolf () and water dog () are used occasionally (though the latter also refers to several different animals) and may have been more common in the reports of explorers in the 19th and early 20th centuries. All four names are in use in South America, with a number of regional variations. \"Giant otter\" translates literally as and in Spanish and Portuguese, respectively. Among the Achuar people, they are known as \"wankanim\", among the Sanum\u00e1 as \"hadami\" and among the Makushi as \"turara\". The genus name, \"Pteronura\", is derived from the Ancient Greek words (, feather or wing) and (, tail), a reference to its distinctive, wing-like tail.\nTaxonomy and evolution.\nThe otters form the subfamily Lutrinae within the mustelids and the giant otter is the only member of the genus \"Pteronura\". Two subspecies are currently recognized by the canonical \"Mammal Species of the World\", \"P. b. brasiliensis\" and \"P. b. paraguensis\". Incorrect descriptions of the species have led to multiple synonyms (the latter subspecies is often \"P. b. paranensis\" in the literature). \"P. b. brasiliensis\" is distributed across the north of the giant otter range, including the Orinoco, Amazon, and Guianas river systems; to the south, \"P. b. paraguensis\" has been suggested in Paraguay, Uruguay, southern Brazil, and northern Argentina, although it may be extinct in the last three of these four. The International Union for Conservation of Nature (IUCN) considers the species' presence in Argentina and Uruguay uncertain. In the former, investigation has shown thinly distributed population remnants. \"P. b. paraguensis\" is supposedly smaller and more gregarious, with different dentition and skull morphology. Carter and Rosas, however, rejected the subspecific division in 1997, noting the classification had only been validated once, in 1968, and the \"P. b. paraguensis\" type specimen was very similar to \"P. b. brasiliensis\". Biologist Nicole Duplaix calls the division of \"doubtful value\".\nAn extinct genus, \"Satherium\", is believed to be ancestral to the present species, having migrated to the New World during the Pliocene or early Pleistocene. The giant otter shares the South American continent with three of the four members of the New World otter genus \"Lontra\": the Neotropical river otter, the southern river otter, and the marine otter. (The North American river otter (\"Lontra canadensis\") is the fourth \"Lontra\" member.) The giant otter seems to have evolved independently of \"Lontra\" in South America, despite the overlap. The smooth-coated otter (\"Lutrogale perspicillata\") of Asia may be its closest extant relative; similar behaviour, vocalizations, and skull morphology have been noted. Both species also show strong pair bonding and paternal engagement in rearing cubs. Giant otter fossil remains have been recovered from a cave in the Brazilian Mato Grosso.\nPhylogenetic analysis by Koepfli and Wayne in 1998 found the giant otter has the highest divergence sequences within the otter subfamily, forming a distinct clade that split away 10 to 14\u00a0million years ago. They noted that the species may be the basal divergence among the otters or fall outside of them altogether, having split even before other mustelids, such as the ermine, polecat, and mink. Later gene sequencing research on the mustelids, from 2004, places the divergence of the giant otter somewhat later, between five and 11\u00a0million years ago; the corresponding phylogenetic tree locates the \"Lontra\" divergence first among otter genera, and \"Pteronura\" second, although divergence ranges overlap.\nPhysical characteristics.\nThe giant otter is clearly distinguished from other otters by morphological and behavioural characteristics. It has the greatest body length of any species in the mustelid family, although the sea otter may be heavier. Males are between in length from head to tail and females between . The animal's well-muscled tail can add a further to the total body length. Early reports of skins and living animals suggested exceptionally large males of up to ; intensive hunting likely reduced the occurrence of such massive specimens. Weights are between for males and for females.\nThe giant otter has the shortest fur of all otter species; it is typically chocolate brown, but may be reddish or fawn, and appears nearly black when wet. The fur is extremely dense, so much so that water cannot penetrate to the skin. Guard hairs trap water and keep the inner fur dry; the guard hairs are approximately 8\u00a0millimetres (one-third of an inch) in length, about twice as long as the fur of the inner coat. Its velvety feel makes the animal highly sought after by fur traders and has contributed to its decline. Unique markings of white or cream fur color the throat and under the chin, allow individuals to be identified from birth.\nGiant otter muzzles are short and sloping and give the head a ball-shaped appearance. The ears are small and rounded. The nose (or rhinarium) is completely covered in fur, with only the two slit-like nostrils visible. The giant otter's highly sensitive whiskers (vibrissae) allow the animal to track changes in water pressure and currents, which aids in detecting prey. The legs are short and stubby and end in large webbed feet tipped with sharp claws. Well suited for an aquatic life, it can close its ears and nose while underwater.\nAt the time of Carter and Rosas' writing, vision had not been directly studied, but field observations show the animal primarily hunts by sight; above water, it is able to recognize observers at great distances. The fact that it is exclusively active during the day further suggests its eyesight should be strong, to aid in hunting and predator avoidance. In other otter species, vision is generally normal or slightly myopic, both on land and in water. The giant otter's hearing is acute and its sense of smell is excellent.\nThe species possesses 2n\u00a0= 38 chromosomes.\nBiology and behaviour.\nThe giant otter is large, gregarious, and diurnal. Early travelers' reports describe noisy groups surrounding explorers' boats, but little scientific information was available on the species until Duplaix's groundbreaking work in the late 1970s. Concern over this endangered species has since generated a body of research.\nVocalizations.\nThe giant otter is an especially noisy animal, with a complex repertoire of vocalizations. All otters produce vocalizations, but by frequency and volume, the giant otter may be the most vocal. Duplaix identified nine distinct sounds, with further subdivisions possible, depending on context. Quick \"hah\" barks or explosive snorts suggest immediate interest and possible danger. A wavering scream may be used in bluff charges against intruders, while a low growl is used for aggressive warning. Hums and coos are more reassuring within the group. Whistles may be used as advance warning of nonhostile intent between groups, although evidence is limited. Newborn pups squeak to elicit attention, while older young whine and wail when they begin to participate in group activities. An analysis published in 2014 cataloged 22 distinct types of vocalization in adults and 11 in neonates. Each family of otters was shown to have its own unique audio signature.\nSocial structure.\nThe giant otter is a highly social animal and lives in extended family groups. Group sizes are anywhere from two to 20 members, but likely average between three and eight. (Larger figures may reflect two or three family groups temporarily feeding together.)\nGroup members share roles, structured around the dominant breeding pair. The species is territorial, with groups marking their ranges with latrines, gland secretions, and vocalizations. At least one case of a change in alpha relationship has been reported, with a new male taking over the role; the mechanics of the transition were not determined. Duplaix suggests a division between \"residents\", who are established within groups and territories, and nomadic and solitary \"transients\"; the categories do not seem rigid, and both may be a normal part of the giant otter life cycle. One tentative theory for the development of sociality in mustelids is that locally abundant but unpredictably dispersed prey causes groups to form.\nAggression within the species (\"intraspecific\" conflict) has been documented. Defence against intruding animals appears to be cooperative: while adult males typically lead in aggressive encounters, cases of alpha females guarding groups have been reported. One fight was directly observed in the Brazilian Pantanal in which three animals violently engaged a single individual near a range boundary. In another instance in Brazil, a carcass was found with clear indications of violent assault by other otters, including bites to the snout and genitals, an attack pattern similar to that exhibited by captive animals. While not rare among large predators in general, intraspecific aggression is uncommon among otter species; Ribas and Mour\u00e3o suggest a correlation to the animal's sociability, which is also rare among other otters.\nA capacity for aggressive behavior should not be overstated with the giant otter. Researchers emphasize that even between groups, conflict avoidance is generally adopted. Within groups, the animals are extremely peaceful and cooperative. Group hierarchies are not rigid and the animals easily share roles.\nReproduction and life cycle.\nGiant otters build dens, which are holes dug into riverbanks, usually with multiple entrances and multiple chambers inside. They give birth within these dens during the dry season. In Cant\u00e3o State Park, otters dig their reproductive dens on the shores of oxbow lakes starting around July, when waters are already quite low. They give birth between August and September, and the young pups emerge for the first time in October and November, which are the months of lowest water when fish concentrations in the dwindling lakes and channels are at their peak. This makes it easier for the adults to catch enough fish for the growing young, and for the pups to learn how to catch fish. The entire group, including nonreproductive adults, which are usually older siblings to that year's pups, collaborates to catch enough fish for the young.\nDetails of giant otter reproduction and life cycle are scarce, and captive animals have provided much of the information. Females appear to give birth year round, although in the wild, births may peak during the dry season. The estrous cycle is 21 days, with females receptive to sexual advances between three and 10 days. Study of captive specimens has found only males initiate copulation. At Tierpark Hagenbeck in Germany, long-term pair bonding and individualized mate selection were seen, with copulation most frequently taking place in water. Females have a gestation period of 65 to 70 days, giving birth to one to five pups, with an average of two. Research over five years on a breeding pair at the Cali Zoo in Colombia found the average interval between litters was six to seven months, but as short as 77 days when the previous litter did not survive. Other sources have found greater intervals, with as long as 21 to 33 months suggested for otters in the wild.\nMothers give birth to furred and blind cubs in an underground den near the river shore and fishing sites. Males actively participate in rearing cubs and family cohesion is strong; older, juvenile siblings also participate in rearing, although in the weeks immediately after birth, they may temporarily leave the group. Pups open their eyes in their fourth week, begin walking in their fifth, and are able to swim confidently between 12 and 14 weeks old. They are weaned by nine months and begin hunting successfully soon after. The animal reaches sexual maturity at about two years of age and both male and female pups leave the group permanently after two to three years. They then search for new territory to begin a family of their own.\nStudies of giant otters in captivity have given indications about the environment necessary to both maintain a physically and behaviorally healthy population and allow successful cub-rearing. These include providing at least the minimum recommended land-to-water area ratio, and that all enclosure land surfaces (both artificial and natural) are nearly entirely covered with the recommended substrate conditions (e.g. tree-bark mulch and soft pebble-free sand/soil). Ensuring that the animals have sufficient privacy from human disturbances (visual and acoustic, from zoo staff or visitors) at parturition and during cub-rearing is also essential, but not sufficient. Insufficient land area proportions and unsuitable substrate conditions in zoos have historically been the primary cause of high cub mortality and physical and behavioral health problems among giant otters. For example, stress to the parents during cub-rearing due to inappropriate enclosure conditions has been the primary reason for cub neglect, abuse and infanticide.\nIn the wild, it has been suggested, although not systematically confirmed, that tourists cause similar stresses: disrupted lactation and denning, reduced hunting, and habitat abandonment are all risks. This sensitivity is matched by a strong protectiveness towards the young. All group members may aggressively charge intruders, including boats with humans in them.\nThe longest documented giant otter lifespan in the wild is eight years. In captivity, this may increase to 17, with an unconfirmed record of 19. The animal is susceptible to a variety of diseases, including canine parvovirus. Parasites, such as the larvae of flies and a variety of intestinal worms, also afflict the giant otter. Other causes of death include accidents, gastroenteritis, infanticide, and epileptic seizures.\nHunting and diet.\nThe giant otter is an apex predator, and its population status reflects the overall health of riverine ecosystems. It feeds mainly on fish, including cichlids, perch, characins (such as piranha), and catfish. One full-year study of giant otter scats in Amazonian Brazil found fish present in all fecal samples. Fish from the order Perciformes, particularly cichlids and perch, were seen in 97% of scats, and Characiformes, such as characins, in 86%. Fish remains were of medium-sized species that seem to prefer relatively shallow water, to the advantage of the visually oriented giant otter. Prey species found were also sedentary, generally swimming only short distances, which may aid the giant otter in predation. Hunting in shallow water has also been found to be more rewarding, with water depth less than having the highest success rate. The giant otter seems to be opportunistic, taking whatever species are most locally abundant. If fish are unavailable, it will also take crabs, snakes, and even small caimans and anacondas.\nThe species can hunt singly, in pairs, and in groups, relying on sharp eyesight to locate prey. In some cases, supposed cooperative hunting may be incidental, a result of group members fishing individually in close proximity; truly coordinated hunting may only occur where the prey cannot be taken by a single giant otter, such as with small anacondas and juvenile black caiman. The giant otter seems to prefer prey fish that are generally immobile on river bottoms in clear water. Prey chase is rapid and tumultuous, with lunges and twists through the shallows and few missed targets. The otter can attack from both above and below, swiveling at the last instant to clamp the prey in its jaws. Giant otters catch their own food and consume it immediately; they grasp the fish firmly between the forepaws and begin eating noisily at the head. Carter and Rosas have found captive adult animals consume around 10% of their body weight daily\u2014about , in keeping with findings in the wild.\nEcology.\nHabitat.\nThe species is amphibious, although primarily terrestrial. It occurs in freshwater rivers and streams, which generally flood seasonally. Other water habitats include freshwater springs and permanent freshwater lakes. Four specific vegetation types occur on one important creek in Suriname: riverbank high forest, floodable mixed marsh and high swamp forest, floodable low marsh forest, and grass islands and floating meadows within open areas of the creek itself. Duplaix identified two critical factors in habitat selection: food abundance, which appears to positively correlate to shallow water, and low sloping banks with good cover and easy access to preferred water types. The giant otter seems to choose clear, black waters with rocky or sandy bottoms over silty, saline, and white waters. \nGiant otters use areas beside rivers for building dens, campsites, and latrines. They clear significant amounts of vegetation while building their campsites. One report suggests maximum areas long and wide, well-marked by scent glands, urine, and feces to signal territory. Carter and Rosas found average areas a third this size. Giant otters adopt communal latrines beside campsites, and dig dens with a handful of entrances, typically under root systems or fallen trees. One report found between three and eight campsites, clustered around feeding areas. In seasonally flooded areas, the giant otter may abandon campsites during the wet season, dispersing to flooded forests in search of prey. Giant otters may adopt preferred locations perennially, often on high ground. These can become quite extensive, including \"backdoor\" exits into forests and swamps, away from the water. Otters do not visit or mark every site daily, but usually patrol all of them, often by a pair of otters in the morning.\nResearch generally takes place in the dry season and an understanding of the species' overall habitat use remains partial. An analysis of dry season range size for three otter groups in Ecuador found areas between . Utreras presumed habitat requirements and availability would differ dramatically in the rainy season: estimating range sizes of 1.98 to as much as 19.55\u00a0square kilometres (0.76 to 7.55\u00a0sq\u00a0miles) for the groups. Other researchers suggest approximately and note a strong inverse correlation between sociality and home range size; the highly social giant otter has smaller home range sizes than would be expected for a species of its mass. Population densities varied with a high of reported in Suriname and with a low of found in Guyana.\nIn 2021, conservationists at Fundaci\u00f3n Rewilding spotted a wild giant otter swimming in the Bermejo River in Impenetrable National Park, located in the Chaco province of northeast Argentina.\nPredation and competition.\nAdult giant otters living in family groups have no known serious natural predators, however there are some accounts of black caimans in Peru and yacare caimans in the Pantanal preying on giant otters. In addition, solitary animals and young may be vulnerable to attacks by the jaguar, cougar, and anaconda, but this is based on historical reports, not direct observation. Pups are more vulnerable, and may be taken by caiman and other large predators, although adults are constantly mindful of stray young, and will harass and fight off possible predators. When in the water, the giant otter faces danger from animals not strictly preying upon it: the electric eel and stingray are potentially deadly if stumbled upon, and piranha may be capable of at least taking bites out of a giant otter, as evidenced by scarring on individuals.\nEven if without direct predation, the giant otter must still compete with other predators for food resources. Duplaix documented interaction with the Neotropical otter. While the two species are sympatric (with overlapping ranges) during certain seasons, there appeared to be no serious conflict. The smaller neotropical otter is far more shy, less noisy, and less social; at about a third the weight of the giant otter, it is more vulnerable to predation, hence, a lack of conspicuousness is to its advantage. The neotropical otter is active during twilight and darkness, reducing the likelihood of conflict with the diurnal giant otter. Its smaller prey, different denning habits, and different preferred water types also reduce interaction.\nOther species that prey upon similar food resources include the caimans and large fish that are themselves piscivores. Gymnotids, such as the electric eel, and the large silurid catfish are among aquatic competitors. Two river dolphins, the tucuxi and Amazon river dolphin, might potentially compete with the giant otter, but different spatial use and dietary preferences suggest minimal overlap. Furthermore, Defler observed associations between giant otters and the Amazon river dolphins, and suggested that dolphins may benefit by fish fleeing from the otters. The spectacled caiman is another potential competitor, but Duplaix found no conflict with the species in Suriname.\nConservation status.\nThe IUCN listed the giant otter as \"endangered\" in 1999; it had been considered \"vulnerable\" under all previous listings from 1982 when sufficient data had first become available. It is regulated internationally under Appendix I of the Convention on International Trade in Endangered Species of Wild Fauna and Flora (CITES) meaning commercial trade in specimens (including parts and derivatives) is prohibited.\nThreats.\nThe animal faces a variety of critical threats. Poaching has long been a problem. Statistics show between 1959 and 1969 Amazonian Brazil alone accounted for 1,000 to 3,000 pelts annually. The species was so thoroughly decimated, the number dropped to just 12 in 1971. The implementation of CITES in 1973 finally brought about significant hunting reductions, although demand did not disappear entirely: in the 1980s, pelt prices were as high as US$250 on the European market. The threat has been exacerbated by the otters' relative fearlessness and tendency to approach human beings. They are extremely easy to hunt, being active through the day and highly inquisitive. The animal's relatively late sexual maturity and complex social life makes hunting especially disastrous.\nMore recently, habitat destruction and degradation have become the principal dangers, and a further reduction of 50% is expected in giant otter numbers within the 20 years after 2004 (about the span of three generations of giant otters). Typically, loggers first move into rainforest, clearing the vegetation along riverbanks. Farmers follow, creating depleted soil and disrupted habitats. As human activity expands, giant otter home ranges become increasingly isolated. Subadults leaving in search of new territory find it impossible to set up family groups. Specific threats from human industry include unsustainable mahogany logging in parts of the giant otter range, and concentrations of mercury in its diet of fish, a byproduct of gold mining.\nOther threats to the giant otter include conflict with fishermen, who often view the species as a nuisance (see below). Ecotourism also presents challenges: while it raises money and awareness for the animals, by its nature it also increases human effect on the species, both through associated development and direct disturbances in the field. A number of restrictions on land use and human intrusion are required to properly maintain wild populations. Schenck \"et al.\", who undertook extensive fieldwork in Peru in the 1990s, suggest specific \"no-go\" zones where the species is most frequently observed, offset by observation towers and platforms to allow viewing. Limits on the number of tourists at any one time, fishing prohibitions, and a minimum safe distance of are proposed to offer further protection.\nDistribution and population.\nThe giant otter has lost as much as 80% of its South American range. While still present in a number of north-central countries, giant otter populations are under considerable stress. The IUCN lists Bolivia, Brazil, Colombia, Ecuador, French Guiana, Guyana, Paraguay, Peru, Suriname, and Venezuela as current range countries. Given local extinctions, the species' range has become discontinuous. Total population numbers are difficult to estimate. An IUCN study in 2006 suggested 1,000 to 5,000 otters remain. Populations in Bolivia were once widespread but the country became a \"black spot\" on distribution maps after poaching between the 1940s and 1970s; a relatively healthy, but still small, population of 350 was estimated in the country in 2002. The species has likely been extirpated from southern Brazil, but in the west of the country, decreased hunting pressure in the critical Pantanal has led to very successful recolonization; an estimate suggests 1,000 or more animals in the region. \nIn 2006, most of this species lived in the Brazilian Amazon and its bordering areas. A significant population lives in the wetlands of the central Araguaia River, and in particular within Cant\u00e3o State Park, which, with its 843 oxbow lakes and extensive flooded forests and marshlands, is one of the best habitat patches for this species in Brazil.\nSuriname still has significant forest cover and an extensive system of protected areas, much of which protects the giant otter. Duplaix returned to the country in 2000 and found the giant otter still present on the Kaburi Creek, a \"jewel\" of biodiversity, although increased human presence and land use suggests, sooner or later, the species may not be able to find suitable habitat for campsites. In a report for World Wildlife Fund in 2002, Duplaix was emphatic about the importance of Suriname and the other Guianas: \nOther countries have taken a lead in designating protected areas in South America. In 2004, Peru created one of the largest conservation areas in the world, Alto Pur\u00fas National Park, with an area similar in size to Belgium. The park harbors many endangered plants and animals, including the giant otter, and holds the world record for mammal diversity. Bolivia designated wetlands larger than the size of Switzerland as a freshwater protected area in 2001; these are also home to the giant otter.\nInteractions with indigenous peoples.\nThroughout its range, the giant otter interacts with indigenous groups, who often practice traditional hunting and fishing. A study of five indigenous communities in Colombia suggests native attitudes toward the animal are a threat: the otters are often viewed as a nuisance that interferes with fishing, and are sometimes killed. Even when told of the importance of the species to ecosystems and the danger of extinction, interviewees showed little interest in continuing to coexist with the species. Schoolchildren, however, had a more positive impression of the animal.\nIn Suriname, the giant otter is not a traditional prey species for human hunters, which affords some protection. (One researcher has suggested the giant otter is hunted only in desperation due to its horrible taste.) The animal sometimes drowns in nets set across rivers and machete attacks by fishermen have been noted, according to Duplaix, but \"tolerance is the rule\" in Suriname. One difference in behavior was seen in the country in 2002: the normally inquisitive giant otters showed \"active avoidance behavior with visible panic\" when boats appeared. Logging, hunting, and pup seizure may have led groups to be far more wary of human activity.\nLocal people sometimes take pups for the exotic pet trade or as pets for themselves, but the animal rapidly grows to become unmanageable. Duplaix relates the story of an Arawak Indian who took two pups from their parents. While revealing of the affection held for the animals, the seizure was a profound blow to the breeding pair, which went on to lose their territory to competitors.\nThe species has also appeared in the folklore of the region. It plays an important role in the mythology of the Achuar people, where giant otters are seen as a form of the \"tsunki\", or water spirits: they are a sort of \"water people\" who feed on fish. They appear in a fish poisoning legend where they assist a man who has wasted his sexual energy, creating the anacondas of the world from his distressed and extended genitals. \nThe Boror\u00f3 people have a legend on the origin of tobacco smoking: those who used the leaf improperly by swallowing it were punished by being transformed into giant otters; the Bororo also associate the giant otter with fish and with fire. A Ticuna legend has it that the giant otter exchanged places with the jaguar: the story says jaguar formerly lived in the water and the giant otter came to the land only to eat. The indigenous Kichwa peoples from Amazonian Peru believed in a world of water where Yaku runa reigned as mother of the water and was charged with caring for fish and animals. Giant otters served as Yaku runa's canoes. A Maxacali creation story suggests that the practice of otter fishing may have been prevalent in the past.", "categories": ["Category:Apex predators", "Category:Articles containing Ancient Greek (to 1453)-language text", "Category:Articles containing Portuguese-language text", "Category:Articles containing Spanish-language text", "Category:Articles with 'species' microformats", "Category:Articles with Spanish-language sources (es)", "Category:Articles with short description", "Category:Articles with text in Tupi languages", "Category:CS1: long volume value", "Category:CS1 Spanish-language sources (es)"]}, {"docid": 44035599, "title": "Deforestation and climate change", "text": "Deforestation is a primary contributor to climate change, and climate change affects forests.\nLand use changes, especially in the form of deforestation, are the second largest anthropogenic source of atmospheric carbon dioxide emissions, after fossil fuel combustion. Greenhouse gases are emitted during combustion of forest biomass and decomposition of remaining plant material and soil carbon. Global models and national greenhouse gas inventories give similar results for deforestation emissions. , deforestation is responsible for about 11% of global greenhouse gas emissions. Carbon emissions from tropical deforestation are accelerating. Growing forests are a carbon sink with additional potential to mitigate the effects of climate change. \nSome of the effects of climate change, such as more wildfires, insect outbreaks, invasive species, and storms are factors that increase deforestation.\nDeforestation comes in many forms: wildfire, agricultural clearcutting, livestock ranching, and logging for timber, among others. Forests cover 31% of the land area on Earth and annually 75,700 square kilometers (18.7 million acres) of the forest is lost. According to the World Resources Institute, there was a 12% increase in the loss of primary tropical forests from 2019 to 2020. Mass deforestation continues to threaten a variety of forests, their biodiversity, and the ecosystems they provide. The main area of concern of deforestation is in tropical rain forests since they are home to the majority of the planet's biodiversity. The loss of forests due to deforestation also has significant implications for global biodiversity, as it leads to the extinction of numerous plant and animal species that are unique to these ecosystems, further exacerbating the ongoing global biodiversity crisis. According to a pan-tropical study published in March of 2023, tropical deforestation has led to a significant decrease in the amount of observed precipitation. By the year 2100, researchers anticipate that deforestation in the Congo will diminish regional precipitation levels by up to 8-10%. According to a study in tropical peatland forest of Borneo, deforestation also contributes to the increase in fire risk. Other effects caused by climate change and deforestation reacting together are soil erosion, water scarcity/flooding, and low mortality rates in specific regions. Solutions to slow down or potentially eliminate these issues are reforestation, afforestation, and agricultural change which could be funded by projects such as The Amazon Fund and UHN goals.\nClimate change.\nAveraged over all land and ocean surfaces, temperatures warmed roughly between 1880 and 2020, according to the Intergovernmental Panel on Climate Change. In the Northern Hemisphere, 1983 to 2012 were the warmest 30-year period of the last 1400 years.\nCauses of deforestation.\nLivestock ranching.\nLivestock ranching requires large portions of land to raise herds of animals and livestock crops for consumer needs. According to the World Wildlife Fund, \"Extensive cattle ranching is the number one culprit of deforestation in virtually every Amazon country, and it accounts for 80% of current deforestation.\" Livestock ranching was established in Texas at the time of the Spanish Missions, between 1820 and 1865 and was mainly driven by Mexican cowboys. When the missions closed cattle was abandoned and private citizens took on the responsibility. On occasions when cattle were rounded up and migrated with the Texans empty land was left behind. According to Greenpeace, a non-governmental global environmental organization, the cattle industry is responsible for a significant amount of methane emissions since 60% of all mammals on earth are livestock cows. Replacing forest land with pastures creates a loss of forest stock, which leads to the implication of increased greenhouse gas emissions by burning agriculture methodologies and land-use change.\nAgricultural expansion.\nThe largest cause of deforestation and acute degradation is agriculture. According to Wageningen University and Research Center, more than 80% of deforestation can be contributed to agriculture. Forests are being converted to plantations for coffee, tea, palm oil, rice, rubber, and various other popular products. The rising demand for certain products and global trade arrangements causes forest conversions, which ultimately leads to soil erosion. The top soil oftentimes erodes after forests are cleared which leads to sediment increase in rivers and streams. Over time, land used for agricultural purposes degrades, resulting in unusable land which causes producers to need to find new productive lands. Moreover, agricultural expansion plays a role in coupled systems that cause climatic effects that reach far beyond agricultural croplands. Environmental factor#Socioeconomic Drivers\nMost deforestation also occurs in tropical regions. The estimated amount of total land mass used by agriculture is around 38%. The main drivers of deforestation in relation to agriculture are population growth and the increased pressures for agricultural expansion. Deforestation is linked with CO2 emissions, in part due from crops having a relatively less impressive carbon storage per unit area than wooded areas or forests. Agricultural deforestation can take different forms, the most salient of which are the commercial plantations in tropical regions.\nAnother prevalent method of agricultural deforestation is slash-and-burn agriculture, which was primarily used by subsistence farmers in tropical regions but has now become increasingly less sustainable. The method does not leave land for continuous agricultural production but instead cuts and burns small plots of forest land which are then converted into agricultural zones. The farmers then exploit the nutrients in the ashes of the burned plants. As well as, intentionally set fires can possibly lead to devastating measures when unintentionally spreading fire to more land, which can result in the destruction of the protective canopy. This method is not sustainable because the plots can only be tilled for 2\u20133 years, where after farmers will move to a different plot and repeat the process. This process will be repeated about 5 to 10 times before a farmer would return to a patch of once deforested land allowed to return to a forested state. So If the land is not available, the length of time between cycles can be shortened leading to fewer nutrients in the soil. This lack of nutrients can then lead to smaller crop yields and a need to convert more forest land into agricultural zones. The repeated cycle of low yields and shortened fallow periods eventually results in less vegetation being able to grow on once burned lands and a decrease in average soil biomass. In small local plots sustainability is not an issue because of longer fallow periods and lesser overall deforestation. The relatively small size of the plots allowed for no net input of to be released. With the increased pressure to expand agricultural production, this method has been used on a much larger scale than traditional subsistence farming. Slash-and-burn agriculture accounts for about 30% of all global arable land.\nResearchers Offiong and Ita question whether increased food production through cropland expansion would be possible without resulting in greater climatic impacts. This is posited given that deforested soil is often unsatisfactory for growing crops. Poor quality soil would require extensive modifications and amendments through, primarily, the use of chemical fertilizers. The chemical-based alterations along with contemporary farming practices would lead to erosion and soil depletion unless continually treated with these substances. These repeated practices would create an unsustainable cycle needed to keep producing expected yields.\nDeforestation without reforestation has negative climatic effects but particularly for agricultural expansion, it creates a scenario for diminishing returns.\u00a0As noted by Offiong and Ita, it leads to a cycle of shrinking crop yields and having to amend poor quality soils continuously due to soil degradation. It also increases the occurrence of floods, landslides, drought, erosion, and desertification as well as disruption of the water cycles and loss of biodiversity. The loss of tree cover results in all of these environmental changes because of the initial disruption in the water system and loss of transfer.\nIn addition to land usage for deforested land being used for plant-based food production, it is also fused or also animal-based food production. Animal-based food production (whether for meat, dairy, or other products) impacts the land in a different way. Land used for grazing livestock is vulnerable to erosion, depletion of the soil biome, and desertification. Additionally, livestock contribute high levels of methane emissions, which have an enormous environmental impact.\nDeforestation, particularly in large swaths of the Amazon, where nearly 20% of the rainforest has been clear cut, has climactic effects and effects on water sources as well as on the soil. Moreover, the type of land usage after deforestation also produces varied results. When deforested land is converted to pasture land for livestock grazing it has a greater effect on the ecosystem than forest to cropland conversions. Other effect of deforestation in the Amazon rainforest is seen through the greater amount of Carbon Dioxide emission. The Amazon rainforest absorbs one-fourth of the Carbon Dioxide emissions on Earth, however, the amount of CO2 absorbed today decreases by 30% than it was in the 1990s due to deforestation.\nStudies conducted in the Ecuadorian Amazon by Kovacic and Salazar found that deforestation and agricultural expansion not only cause environmental degradation but do not guarantee the expected economic benefit for the small-scale farmers nor for the national economies of governments who are proposing agricultural expansion programs. Farmers in these studies were encouraged to change from a mere subsistence farming system to an intensive \"for-profit\" farming system where products are grown were primarily coffee, oil palm, and cocoa, all for export. According to Kovacic and Salazar, there is not an equal exchange between agricultural expansion and economic gains as touted by both governments and large-scale agricultural production companies. This holds true for small-scale farmers who move from subsistence farming to a small-scale intensive farming scheme regardless of product grown.\nIt is also important to note that not all deforestation is as result of agriculture expansion. Food production is only one driver. Between 2001 and 2015, only 27 +/- 5% of all forest disturbances globally were for agricultural expansion. Among other drivers were urbanization, forest fires, logging, and for shifting agriculture practices. The percentages are 0.6 +/- 0.3% for urbanization, 23 +/- 4% for forest fires, 26 +/- 4% for logging, and 24 +/- 3% for shifting agricultural practices. The types of drivers vary greatly depending on the region in which they take place. The regions with the greatest amount of deforestation for livestock and row crop agriculture are Central and South America, while commodity crop deforestation was found mainly in Southeast Asia. The region with the greatest forest loss due to shifting agriculture was sub-Saharan Africa. These distinctions are important in light of Silverio's research findings that not all deforestation affects the environment and climate in the same way.\nClimate change.\nA study suggests that \"tropical, arid and temperate forests are experiencing a significant decline in resilience, probably related to increased water limitations and climate variability\" which may shift ecosystems towards critical transitions and ecosystem collapses.\nLumber industry.\nA large contributing factor to deforestation is the lumber industry. A total of almost of timber, or about 1.3% of all forest land, is harvested each year. In addition, the increasing demand for low-cost timber products only supports the lumber company to continue logging. The carbon emitted from the process of converting timber to wood products accounts for 15% of the carbon emissions in the environment. Deforestation is the main concern in tropical rainforests since they are home to millions of animals and much biodiversity. Not only does the lumber industry impact local deforestation, but it also impacts the whole environment as deforestation is a major driver of climate change.\nDecrease in biodiversity.\nA study published in 2012 observed Amazonian plants and the effect that climate change and deforestation had on the vegetation and organisms found in the forest. The study found that if these living organisms were unable to adapt to the rising temperatures and loss of habitat, there would be a significant decrease in the biodiversity of the Amazon rainforest. If the Amazon experiences a loss of biodiversity, this will worsen the effects of climate change and deforestation as many of the plants will be gone, unable to take in carbon dioxide which is necessary to reduce the effects of global warming.\nGlobally, there are 18 \"hot-spots\", each of which contains a unique and biodiverse ecosystem. Together they contain approximately 20% of the earth's total flora, or roughly 50,000 separate species. The ASEAN Region alone, Indonesia, Malaysia, the Philippines, Singapore, and Thailand,\u00a0hosts approximately 20% of all of the world's species\u00a0and accounts for three of the Earth's \"hot-spots\". While the geographic zone houses one quarter of the world's forests, it has the highest rates of deforestation. This is notable because loss of forest habitats puts biodiversity in jeopardy. A 2007 study conducted by the National Science Foundation found that biodiversity and genetic diversity are codependent\u2014that diversity among species requires diversity within a species and vice versa. \"If any one type is removed from the system, the cycle can break down, and the community becomes dominated by a single species.\" Additionally, modeling studies have concluded that there are two crucial moments that can lead to devastating effects in the Amazon rainforest which are increase in temperature by 4\u00a0\u00b0C and deforestation reaching a level of 40%.\nDecrease in climate services.\nHuman activity such as deforestation for livestock grazing and fuel wood has led to forest degradation and over extraction resulting in ecosystem biodiversity loss. Loss and degradation of forest has a direct impact on the Earth's diverse flora and fauna and, therefore, on climate change because they are the best defense against buildup in the atmosphere. If there is more foliage photosynthesizing more will be absorbed, thereby balancing the potential temperature increases.\nForests are nature's atmospheric carbon sink; plants take in atmospheric carbon dioxide (a greenhouse gas) and convert the carbon into sugars and plant materials through the process of photosynthesis. The carbon is stored within the trees, vegetation, and soil of the forests. Studies show that \"intact forests\", in fact, do sequester carbon. Examples of large forests that have a significant impact on the balance of carbon include the Amazonian and the Central African rainforests. However, deforestation disrupts the processes of carbon sequestration and affects localized climates. Additionally, cutting down trees plays a role in a positive feedback loop centered around climate change on a much larger scale, as studies are finding.\nWhen a climate changes, this causes the shift in a species' geographic range in order to maintain the climatic conditions (temperature, humidity) it is accustomed to. Ecological zones will shift by approximately 160\u00a0km per 1 degree Celsius. A reduction in the area of any habitat, but particularly in forest habitat along with climatic change, enables species invasion and the possibility of biotic homogenization as stronger invasive species can take over weaker species in a fragile ecosystem. Humans will also be impacted by the loss of biodiversity as food, energy, and other 'ecosystem goods and services' patterns are disrupted.\nBurning or cutting down trees reverses the effects of carbon sequestration and releases greenhouse gases (including carbon dioxide) into the atmosphere. Furthermore, deforestation changes the landscape and reflectivity of earth's surface, i.e. decreasing Albedo. This results in an increase in the absorption of light energy from the sun in the form of heat, enhancing global warming.\nImplications on soil and water.\nTrees are a major source of carbon and it is estimated that the amount of carbon within the Amazon exceeds the ten year's worth of carbon released by human production. Unfortunately, since forests are often cleared by fire such as in slash and burn agriculture, the combustion process of wood release huge amounts of carbon dioxide into the atmosphere. The increase of atmospheric carbon is not the only consequence of deforestation, changes in soil properties could turn the soil itself into a carbon contributor. According to scientists at Yale University, clearing forests changes the environment of the microbial communities within the soil, and causes a loss of biodiversity in regards to the microbes since biodiversity is actually highly dependent on soil texture. Although the effect of deforestation has much more profound consequences on sandier soils compared to clay-like soils, the disruptions caused by deforestation ultimately reduces properties of soil such as hydraulic conductivity and water storage, thus reducing the efficiency of water and heat absorption. In a simulation of the deforestation process in the Amazon, researchers found that surface and soil temperatures increased by 1 to 3 degrees Celsius demonstrating the loss of the soil's ability to absorb radiation and moisture. Furthermore, soils that are rich in organic decay matter are more susceptible to fire, especially during long droughts. As a consequence of reduced evapotranspiration, precipitation is also reduced. This implies having a hotter and drier climate, and a longer dry season. This change in climate has drastic ecological and global impacts including increases in severity and frequency of fires, and disruption in the pollination process that will likely spread beyond the area of deforestation.\nIn addition to soil degradation, clean water sources and streamflow have fluctuated in the past year due to deforestation. A single forest can release and purify water through their interactions with the hydrological processes. Forestation can either lower annual streamflow or increase it. Scientists raise that 60% of the forest watersheds had annual streamflow discounted by 0.7 to 65.1% accompanying 0.7 to 100% thicket cover gain, inasmuch as 30% of ruling class (mainly narrow watersheds) had annual streamflow raised by 7 to 167.7% accompanying 12 to 100% jungle cover gain. Variations in annual streamflow to forest managements are even more affected to those created by clear-cutting, possibly due to station environments superior to forest management and wood variety picked.\nEffects of deforestation.\nAccording to a review, north of 50\u00b0N, large scale deforestation leads to an overall net global cooling while tropical deforestation leads to substantial warming not just due to impacts but also due to other biophysical mechanisms (making carbon-centric metrics inadequate). Irreversible deforestation would result in a permanent rise in the global surface temperature. Moreover, it suggests that standing tropical forests help cool the average global temperature by more than 1\u00a0\u00b0C.\nDeforestation of tropical forests may risk triggering tipping points in the climate system and of forest ecosystem collapse which would also have effects on climate change.\nForest fires.\nAs deforestation rates continue to rise, the likelihood of forest fires also increase. People tend to use wood from deforestation as a source of kindling for fires that assist in preparing meals and also serve as a source of heat. As the smoke is released from this burning wood, it can mix with clouds in the atmosphere, preventing rain and causing dry spells. Slash and burn agriculture also fuels the intensity of dry seasons that are increasingly seen, which spread forest fires beyond initial intention resulting in intensifying fires that create smoke that also suppresses rainfall as well. When this dryness continues for long periods of time, forest fires are more likely to occur. Statistics have shown that there is a direct correlation between forest fires and deforestation. Statistics regarding the Brazilian Amazon area during the early 2000s have shown that fires and the air pollution that accompanies these fires mirror the patterns of deforestation. As a result of this, Brazil has implemented policies in an effort to prevent the constant burning of the Amazon rainforest.\nThe Amazon rainforest has recently experienced fires that occurred inside the forest when wildfires tend to occur on the outer edges of the forest. Wetlands have faced an increase in forest fires as well. Due to the change in temperature, the climate around forests have become warm and dry, conditions that allow forest fires to occur. Even though forest fires have been a characteristic of the Amazon, it still has increased as extensive logging leaves flammable materials. As a result of these forest fires, stored carbon dioxide is released back into the atmosphere, worsening the effects of global warming and deforestation.\nUnder unmitigated climate change, by the end of the century, 21% of the Amazon would be vulnerable to post\u2010fire grass invasion. In 3% of the Amazon, fire return intervals are already shorter than the time required for grass exclusion by canopy recovery, implying a high risk of irreversible shifts to a fire\u2010maintained degraded forest grassy state. The south\u2010eastern region of the Amazon is currently at highest risk of irreversible degradation.\nHuman mortality.\nA study conducted from 2002 to 2018 determined that the increase in temperature as a result of climate change, and the lack of shade due to deforestation, has increased the mortality rate of workers in Indonesia. These findings imply that developing countries will face harsh effects of global warming as they might not have access to fresh water or electricity that would power air conditioning. As deforestation rates continue to increase, the percentage of workers that face mortality will increase simultaneously.\nA link between deforestation and infant mortality was found in Indonesia as well. The study shows documentation of deforestation and pregnancy order, as children born from first pregnancies face higher mortality risks due to in-utero exposure. The study\u2019s results suggest that women during their first pregnancy could have been affected by deforestation-induced malaria. It has been affirmed that in preserved regions, likely reasons including commercial activity, perinatal health care, alongside air pollution are not identifiable triggers of the weighty impression left by deforestation on newborn fatality.\nCase Study: Deforestation Effect on Air Pollution Concentration.\nA case study in the East Kalimantan Province (2019-2020) reinforced the fact that deforestation inhibits nature's ability to dilute greenhouse gasses in the air, specifically SO2 and NO2. \nCounteracting climate change.\nBenefits of reforestation and afforestation.\nWell-managed forests will have an appropriate natural amount of regeneration to maintain an adequate above-ground tree biomass density. The greater the above-ground tree biomass density, the greater the amount of Carbon (C) that the forest is able to sequester and store. A degraded forest, therefore, is unable to store greater amounts of Carbon (C), thus adding to Climate Change. In order to combat Carbon (C) emissions caused by deforestation and forest degradation actions that sequester and store this Carbon must be taken. Deforestation and forest degradation account for nearly 20% of all man-made emissions. The most efficient and cost-effective way to combat this is through sustainable forest management practices, afforestation, reforestation, and forest conservation; taken together these practices may provide Carbon (C) emissions reductions of up to 25% which will effectively curb climate change. Specifically, forests hold roughly 471 billion tons of the total carbon emissions in our world. If we can reduce deforestation, this would have reduced the 1.1 billion tons which are released from it to the atmosphere every year.\nWood harvesting and supply have reached around 550 million m3 per year, while the total increasing stock of European forests has more than quadrupled during the previous six decades. It now accounts for around 35 billion m3 of forest biomass. Since the beginning of the 1990s, the amounts of wood and carbon stored in European forests have increased by 50% due to greater forest area and biomass stocks. Every year, European woods adsorb and store around 155 million tonnes CO2 equivalent. This is comparable to 10% of all other sectors' emissions in Europe.\nThe forest landscape restoration strategy seeks to rehabilitate landscapes and repair marginal and degraded areas in order to generate productive forest landscapes that are resilient and long-term. It aims to guarantee that diverse ecological and land-use functions are restored, safeguarded, and preserved over time. The forestry industry tries to mitigate climate change by boosting carbon storage in growing trees and soils and improving the sustainable supply of renewable raw materials via sustainable forest management.\nAlternative harvesting methods.\nReduced impact logging (RIL) is a sustainable forestry method as it decreases the forest and canopy damages by approximately 75% compared to the conventional logging methods. Additionally, a 120-year regression model found that RIL would have a significantly higher reforestation in 30 years (\"18.3 m3 ha\u22121\") in relation to conventional logging (\"14.0 m3 ha\u22121\"). Furthermore, it is essential that RIL should be practiced as soon as possible to improve reforestation in the future. For instance, a study concluded that logging would have to reduce by 40% in Brazil if the current logging measures stay of \"\"6 trees/hectare\" with a 30-year cutting cycle\" stay in place. This would be to ensure that future ground biomass to have regeneration of the original ground biomass prior to harvesting.\nReforestation.\nReforestation is the natural or intentional restocking of existing forests and woodlands that have been depleted, usually through deforestation. It is the reestablishment of forest cover either naturally or artificially. Similar to the other methods of forestation, reforestation can be very effective because a single tree can absorb as much as of carbon dioxide per year and can sequester of carbon dioxide by the time it reaches 40 years old.\nThe relative cost of planting trees is low when looking at other methods of carbon emission reduction, making reforestation a go-to method for cost-effective means of reducing carbon dioxide in the atmosphere. Possible methods of reforestation include large-scale industrial plantations, the introduction of trees into existing agricultural systems, small-scale plantations by landowners, the establishment of woodlots on communal lands, and the rehabilitation of degraded areas through tree planting or assisted natural regeneration. Most of the focus of wide-scale reforestation efforts have been focused on tropical climate areas like some parts of Latin America and sub-Saharan Africa. Many other countries and regions are beginning to start or have already started reforestation programs and initiatives in hopes of counteracting global climate change drivers. Reforestation has also been shown to be useful in the process of nurturing once farmed land back to a condition where it can be used for agriculture or conservation. Reforestation can also help mitigate the effects of soil degradation and pollution depending on the methods of planting, location, and plant species.\nAfforestation.\nAfforestation is the planting of trees where there was no previous tree coverage. The degradation of forests ultimately leads to a decrease in oxygen and a sufficient increase of carbon dioxide in the atmosphere. In order to make up for the loss, more trees are being planted. As a result, the amount of carbon dioxide in the atmosphere could significantly decrease. According to scientific research, plantation forest could absorb more carbon dioxide than natural forest since they grow faster leading to a higher absorbance rate. The process is usually encouraged by governments because they want it to lead to a decrease in carbon dioxide and because it increases the aesthetics of the area. Although, it could lead to infringing upon ecosystems and create complications in environments that previously did not have tree coverage or forests.\nThere are three different types of afforestation that could have varying effects on the amount of carbon dioxide that is taken from the atmosphere. The three kinds of afforestation are natural regeneration, commercial plantations, and agroforestry. Although afforestation can help reduce the carbon emissions given off as a result of climate change, natural regeneration tends to be the most effective out of the three. Natural regeneration typically concerns a wide variety of vegetation, making natural forest levels so plants can receive sunlight to undergo photosynthesis. Commercial plantations typically result in mass amounts of lumber, which if used for fuel, will release the stored back into the atmosphere. Agroforestry stores energy based on the size and type of plant, meaning that the effect will vary depending on what is planted.\nAfforestation in China.\nAlthough China has set official goals for reforestation, these goals were set for an 80-year time horizon and were not significantly met by 2008. China is trying to correct these problems with projects such as the Green Wall of China, which aims to replant forests and halt the expansion of the Gobi Desert. A law promulgated in 1981 requires that every school student over the age of 11 plants at least one tree per year. But average success rates, especially in state-sponsored plantings, remain relatively low. And even the properly planted trees have had great difficulty surviving the combined impacts of prolonged droughts, pest infestation, and fires. Nonetheless, China currently has the highest afforestation rate of any country or region in the world, with 4.77 million hectares (47,000 square kilometers) of afforestation in 2008.\nAccording to the 2021 government Work report, the forest coverage rate will reach 24.1 percent when introducing the main targets and tasks for the 14th Five-Year Plan period. According to the National Forestry and Grassland Administration, China's forest coverage rate has increased from 12 percent in the early 1980s to 23.04 percent in August 2021. \nSeveral generations of People in Saihanba keep in mind the mission of restoring nature and protecting ecology, and work hard to build the largest artificial forest farm in the world. Compared with before the site was built, the forest coverage rate increased from 11.4% to 80%, and the forest stock increased from 330,000 cubic meters to 10.12 million cubic meters. In 2017, the builders of Saihanba Forest Farm in Hebei province won the Highest honor of the United Nations environmental protection - \"Champions of the Earth award\".\nOne of the significant strategy in China for afforestation is through mixed-tree plantations. It plays an important role in promoting reforestation in southwest China and on barren land. This is because mixed planting can have a significant positive impact on soil organic carbon (SOC) reserves in these types of areas. There are findings demonstrated that, in comparison to monoculture, mixed plantations can considerably improved the SOC stock by 12%, and that in order to achieve this, the mixed ratio should not be greater than 55%. Due to the limited water supply and low temperatures needed for growth in such areas, the researchers have found that mixed plantation was the most likely strategy for effectively boosting the SOC reserves of the land classified as barren. Additionally, the main factor influencing changes in soil organic carbon stocks in mixed plantations is the type of mixed forest. As the example of mix plantations in China has illustrated, the features of mixed forests can have a significant influence on soil organic carbon storage in a region, especially on barren ground, since the impact of mixed forests on soil organic carbon storage will vary based on land use and soil characteristics. In light of this, promoting mixed plantations is the key for Southwest China to achieve an effective afforestation. By realizing mixed forests in these dry and cold soils areas, mixed forests would be used to its maximum effect for storing more soil organic carbon, implying that it greatly increases the carbon absorption ability in these areas and promotes China's efforts to achieve carbon neutrality.\nAgroforestry.\nAgroforestry or agro-sylviculture is a land use management system in which combinations of trees or shrubs are grown around or among crops or pastureland. It combines agricultural and forestry technologies to create more diverse, productive, profitable, healthy, and sustainable land-use systems. There are many benefits to agroforestry such as increasing farm profitability. In addition, agroforestry helps to preserve and protect natural resources such as controlling soil erosions, creating habitat for the wildlife, and managing animal waste.\nEfforts are being made in Thailand to restore the land after 800,000 hectares of forest have been destroyed in exchange for cash crop land to grow maize. Agroforestry has become part of the solution to fix the damage caused by deforestation. Agroforestry would affect the agriculture and atmosphere in Thailand in numerous ways. By planting a combination of different tree species, these trees are able to change the microclimatic conditions. Nutrient cycling also occurs when trees are incorporated in the agricultural system. It is also probable that the soil erosion that occurred as a result of deforestation can be mediated when these trees are planted.\nReduce emissions from deforestation and forest degradation.\nRecognition of the negative impacts of deforestation and of the overwhelming evidence of global warming has led to the development of international policy surrounding the conservation of forests. One attempt towards fighting climate change globally is the \"Reducing Emissions for Deforestation and Forest Degradation\" (REDD+) efforts, and a few countries are already starting to implement and analyze ways to protect standing trees.\nIn the case of the Bac Kan province in Vietnam, researchers came up with systems to encourage leaving forests intact while also meeting international, national, and individual investments successfully. Their methods included \"benefit-distribution systems\" and dividends for ecosystem services. The researchers hope that their results \"can be replicated and directly contribute to reducing carbon emissions globally.\"\nHuman dimension of deforestation and climate change.\nDeforestation is often described as the changing of land from forested to non-forested by means both natural and unnatural. The relationship between deforestation and climate change is one of a positive feedback loop. The more trees that are removed equals larger effects of climate change which, in turn, results in the loss of more trees. In recent history, this process has been accelerated and amplified by humans in many different ways. These include logging, urbanization, mining, and agricultural development. One of the more recent and bigger consequences of deforestation is wildfires, which leads to greater harm to humans and animals. Fires release carbon monoxide and nitrogen oxides that affect air quality and animal and human health. The incessant need to expand these operations has resulted in widespread deforestation worldwide.\nAgricultural.\nAgricultural expansion is one of the worst offenders when it comes to deforestation in recent times. Since 1960, roughly 15% of the Amazon has been removed with the intention of replacing the land with agricultural practices. In Bolivia specifically, the jungle has been wiped out in order to house cattle and other valuable agricultural items by means of 'fishbone deforestation'.Fishbone is in reference to the visual aesthetic of the scarred land and how it branches off from the roadside in straight lines. This style of deforestation has proven to be fast-moving and efficient while tearing apart the land that humans, plants, and animals all inhabit. It is no coincidence that Brazil has recently become the world's largest beef exporter at the same time that the Amazon rainforest is being clear cut.\nSolutions to Deforestation.\nPreserving our current forests can be seen as the main solution to deforestation. We need forests in order to survive. They ensure that we can breathe. They are home to millions of people and billions depend on forests.\nThere are many solutions to deforestation. A start would be to convince companies and governments to change their habits, as their choice of raw materials has a big impact on our forests. By introducing deforestation prevention policies in supply chains, companies can be put under pressure. This can be used to try to pressure them to buy from sustainable sources and to stop using harmful materials and products. Similarly, we can convince our governments to protect forests and support programs that ensure the maintenance of our forests.\nAnother approach to preserve our forests is to change the consumption behavior of the population. But to do this, people first have to be informed and educated about this so that they take action themselves.\nConsuming less meat, avoiding disposable packaging, choosing recycled wood products, going paperless and many other ways exist to fight deforestation as citizens.\nContinuing on, checking on the activities of deforestation and the numerous systems to replant trees like afforestation and agroforestry will help studies and organizations understand the status of the amount of trees. With control and regular checks, the conservatory of forest protection can be strengthened. Forests and our vital ecosystems need to be protected, and many solutions to maintaining our ecosystems and environments is detrimental towards reducing global climate change.\nPolicies, projects, and foundations.\nGreat Green Wall (Africa).\nThe Great Green Wall is a project led by the African Union, initially conceived as a way to combat desertification in the Sahel region and hold back expansion of the Sahara, by planting a wall of trees stretching across the entire Sahel.\nThe Bali Action Plan.\nThe Bali Action Plan was developed in December 2007 in Bali, Indonesia. It is a direct result of The Kyoto Protocol of December 1997. One of the key elements of The Bali Action Plan involves a concerted effort by the member countries of The Kyoto Protocol to enact and create policy approaches that incentivize emissions reduction caused by deforestation and forest degradation in the developing world. It emphasized the importance of sustainable forest management and conservation practices in mitigating climate change. This coupled with the increased attention to carbon emission stocks as a way to provide additional resource flows to the developing countries.\nCommunity based forest management.\nCommunity-based forest management (CBFM) is a scheme that links governmental forest agencies and the local community in efforts to regenerate degraded forests, reforest deforested areas, and decrease carbon emissions that contribute to climate change. This partnership is done with the intent of not only repairing damage to the environment but also providing economic and social benefits to the affected area. In principle, the benefits for the local community involvement in the management and protection of their forests would be to provide employment and to supplement income from both the wage labor and additional agriculture which would then strength the entire local economy while improving environmental conditions and mitigating climate change. Therefore, implementing a CBFM system can provide rural development while mitigating climate change and sustaining biodiversity within the region. It is important to engage the local community members, many of which are indigenous since presumably, they would have a deeper knowledge of the local ecosystems as well as the life cycles of those ecosystems over time. Their involvement also helps to ensure that their cultural practices remain intact.\nArbor Day Foundation.\nFounded in 1972, the centennial of the first Arbor Day observance in the 19th century, the Foundation has grown to become the largest nonprofit membership organization dedicated to planting trees, with over one million members, supporters, and valued partners. They work on projects focused on planting trees around campuses, low-income communities, and communities that have been affected by natural disasters among other places.\nTrillion Tree Campaign.\nThe Billion Tree Campaign was launched in 2006 by the United Nations Environment Programme (UNEP) as a response to the challenges of global warming, as well as to a wider array of sustainability challenges, from water supply to biodiversity loss. Its initial target was the planting of one billion trees in 2007. Only one year later in 2008, the campaign's objective was raised to 7 billion trees\u2014a target to be met by the climate change conference that was held in Copenhagen, Denmark in December 2009. Three months before the conference, the 7 billion planted trees mark had been surpassed. In December 2011, after more than 12 billion trees had been planted, UNEP formally handed management of the program over to the not-for-profit Plant-for-the-Planet initiative, based in Munich, Germany.\nThe Amazon Fund (Brazil).\nConsidered the largest reserve of biological diversity in the world, the Amazon Basin is also the largest Brazilian biome, taking up almost half the nation's territory. The Amazon Basin corresponds to two fifths of South America's territory. Its area of approximately seven million square kilometers covers the largest hydrographic network on the planet, through which runs about one fifth of the fresh water on the world's surface. Deforestation in the Amazon rainforest is a major cause to climate change due to the decreasing number of trees available to capture increasing carbon dioxide levels in the atmosphere.\nThe Amazon Fund is aimed at raising donations for non-reimbursable investments in efforts to prevent, monitor and combat deforestation, as well as to promote the preservation and sustainable use of forests in the Amazon Biome, under the terms of Decree N.\u00ba 6,527, dated August 1, 2008. The Norwegian Government, which is the largest donor to the fund, froze its funding in 2019 over deforestation concerns. Norway has tied the resumption of funding to proof of a reduction in deforestation.\nThe Amazon Fund supports the following areas: management of public forests and protected areas, environmental control, monitoring and inspection, sustainable forest management, economic activities created with sustainable use of forests, ecological and economic zoning, territorial arrangement and agricultural regulation, preservation and sustainable use of biodiversity, and recovery of deforested areas. Besides those, the Amazon Fund may use up to 20% of its donations to support the development of systems to monitor and control deforestation in other Brazilian biomes and in biomes of other tropical countries.\nUHN goals.\nUHN (University Health Network) developed 17 goals in 2015. 30% of the goals had a direct association with the sustainable forestry management objectives. The goals show to be a platform for policy changes and implementation by other countries for achieving these goals through sustainable forestry management practices. Specifically, the goals which have shown to have the highest relation with SFM are the following: \"sustainable consumption and production (SDG 12), followed by land (SDG 15), cities (SDG 11), inequality (SDG 10), health and well-being (SDG 3), hunger (SDG 2), and poverty (SDG 1).\"\nThe UN Strategic Plan for Forests 2030.\nThe plan important targets such as increasing the area of protected, conserved, and sustainably managed forests (via long-term forest management plans) and increasing the proportion of forest-based products and materials produced from sustainably managed forests.", "categories": ["Category:All articles containing potentially dated statements", "Category:All articles lacking reliable references", "Category:All articles with unsourced statements", "Category:All pages needing cleanup", "Category:Articles containing potentially dated statements from 2019", "Category:Articles lacking reliable references from August 2021", "Category:Articles needing cleanup from August 2020", "Category:Articles with short description", "Category:Articles with unsourced statements from April 2020", "Category:CS1 maint: unfit URL"]}, {"docid": 523133, "title": "Zookeeper", "text": "A zookeeper, sometimes referred as animal keeper, is a person who manages zoo animals that are kept in captivity for conservation or to be displayed to the public. They are usually responsible for the feeding and daily care of the animals. As part of their routine, the zookeepers may clean the exhibits and report health problems. They may also be involved in scientific research or public education, such as conducting tours and answering questions.\nBackground.\nAnimal collections requiring wild animal care takers or zookeepers have existed since about 3,000 B.C.\nEarly civilizations in Mesopotamia (present day Iraq), Egypt, China and Pakistan / Northwest India allowed rulers and the wealthy class citizens to keep collections of wild animals. These civilizations had individuals who caught and cared for wild animals such as fish and birds. King Hammurabi (Babylonia, 1728-1686 BC) established the first known Code of Laws, which included fees that could be charged by \u201cox and ass doctors\u201d or what we know today as veterinarians.\nSome ancient collections of animals were very large and contained a wide variety of species, although specific details of these collections were not recorded. Many cultures such as the Chinese, Egyptians, Persians, Greeks, Arabian, and India collected. Little is known about how or where they kept these animals, or even what the animals were. Our knowledge comes from when these animals appeared in the processionals (parades) or in the arena fights. However, there is proof that large elephant exhibits were maintained outside of Rome. There is also proof of people who cared for the sick animals (veterinarians).\nIn the areas known as the New World, Aztec and Inca societies also maintained large animal collections. While these were only discovered in the early 16th century, they were much older than that. Montezuma (Mexico City) had the largest known collections. One collection consisted of birds and required some 300 keepers. Another collection consisted of mammals and reptiles requiring another 300 keepers. There were also fresh and salt water fish ponds.\nDuties and responsibilities.\nA zookeeper's responsibilities usually include feeding, maintaining and cleaning the animals, diet preparation, behavioral observation, record keeping, exhibit maintenance and providing environmental enrichment for the animals in their care. Some also conduct behavioral or reproductive research on a species and participate in public education through talks, programs or shows. They are expected to clean enclosures every day. They look for any signs of injuries or illness in the animals, and in the case of sickness or injury, the keeper is responsible for contacting a veterinarian, and sometimes a zookeeper will assist a veterinarian.\nSome zookeepers train the animals to make caring for them easier. For example, a zookeeper can train an elephant to lift their feet so that a veterinarian can check them more easily. Some zookeepers are responsible for informing an audience, in an exhibit or presentation, about certain types of animals and their behavioral characteristics. They also talk about experiences with the animal, and answer questions. The keeper is also responsible for lecturing the visiting public on how to behave responsibly toward the exhibited animals.\nDepending on the zoo structure, keepers may be assigned to work with a broad group of animals, such as mammals, birds, or reptiles, or they may work with a limited collection of animals such as primates, large cats, or small mammals. Traditionally, the live exhibits were often organized by taxonomy, resulting in clusters of carnivores cages, bird aviaries, primate exhibits, and so on, which led to sections within a zoo cared for by specialized staff. Some keepers can become highly specialized such as those who concentrate on a specific group of animals like birds, great apes, elephants or reptiles.\nModern habitat exhibits attempt to display a diversity of species of different animal classes within one enclosure to represent ecosystem concepts. Groups of enclosures are organized by themes, relating to, for example, zoogeography and bioclimatic zones, rather than taxonomy. The shift in exhibit arrangements is changing the scope of work for animal keepers, as they become habitat keepers, with a necessary working knowledge of living environment care, including landscape maintenance, plant care, climate control, and expanded knowledge of animals husbandry for many more species across taxonomic classes.\nEducational requirements.\nThe educational requirements for an entry level zoo keeper vary.\nIn the USA they are often required to have completed a college degree in zoology, biology, wildlife management, animal science, or some other animal-related field. Some colleges offer programs oriented towards a career in zoos. Job advancement is also possible but more limited than in some other careers requiring a college degree. In other institutions keepers are required to have finished a full apprenticeship as craftsmen, before receiving special training for their task as animal keeper. In fact in many European countries, people intending to keep or take care of wild animals need to be licensed. This license will only be given if they can prove sufficient knowledge and practical abilities (evidence of competence). Of course in the vast array of zoos in the world, some of them are still privately owned amateur facilities with a lack of well-trained personnel.\nIn contrast, some zoos in Australia have a strong reliance on dedicated part-time volunteer workers, who assist zookeepers in the simpler tasks such as preparation of foods and medicines, and cleaning of animal enclosures.\nInternships and volunteer work.\nIn the USA, in addition to good academic preparation, most zoos prefer to hire people for zookeeping positions who have prior animal-handling experience. There are a wide variety of internships that aspiring zoo keepers can take both during and after college. Many of these internships can be found by going to a local zoo or aquarium. Other internships can be found in an animal-related facility, including vet hospitals, humane society shelters, wildlife rehabilitation centers, farms and stables. Internships are an opportunity for individuals who are considering a career in animal welfare to learn more about companion animals and their behaviors.\nOccupational hazards.\nThere are several occupational hazards associated with zookeepers including allergens, zoonoses, bite injuries, slips, trips, and falls, chemicals, stress, and noise. These exposures have been associated with increased rates of alergic diseases, skin infections, bite-related infections, intestinal diseases, tuberculosis and psychological stress. The National Association of State Public Health Veterinarians publishes guidelines to identify and control risks associated with contact with animals in public settings.", "categories": ["Category:Articles with GND identifiers", "Category:Articles with J9U identifiers", "Category:Articles with LCCN identifiers", "Category:Articles with short description", "Category:Commons category link is on Wikidata", "Category:Short description matches Wikidata", "Category:Webarchive template wayback links", "Category:Zookeepers"]}, {"docid": 509191, "title": "Shedd Aquarium", "text": "Shedd Aquarium (formally the John G. Shedd Aquarium) is an indoor public aquarium in Chicago. Opened on May 30, 1930, the aquarium holds about 32,000 animals and is the third largest aquarium in the Western Hemisphere, after the Georgia Aquarium and Monterey Bay Aquarium.\nThe Shedd Aquarium is a highly-ranked world aquarium and at one time was the largest indoor facility in the world. It is the first inland aquarium with a permanent saltwater fish collection. The aquarium is located along Lake Michigan in the city's Museum Campus, which also includes other highly-ranked institutions such as Adler Planetarium and the Field Museum of Natural History.\nIn 2015, the Shedd Aquarium had 2.02 million visitors. It was the most visited aquarium in the Western Hemisphere in 2005, and in 2007 became the most visited cultural institution in Chicago. The aquarium contains 1,500 species, including fish, marine mammals, birds, snakes, amphibians, and insects. The aquarium received awards for \"best exhibit\" from the Association of Zoos and Aquariums (AZA) for Seahorse Symphony in 1999, Amazon Rising in 2001, and Wild Reef in 2004. It was designated a National Historic Landmark in 1987.\nHistory.\nShedd Aquarium was the gift of retail leader John G. Shedd, a prot\u00e9g\u00e9 of Marshall Field (benefactor of the adjacent Field Museum), to the city of Chicago. Although Shedd only lived long enough to see the architect's first drawings for the aquarium, his widow, Mary R. Shedd, cut the ribbon at the official opening ceremony.\nThe aquarium cost $3 million to build, and initially included 132 exhibit tanks. Groundbreaking took place on November 2, 1927, and construction was completed on December 19, 1929; the first exhibits opened on May 30, 1930. As one of the first inland aquariums in the world, the Shedd had to rely on a custom-made railroad car, the Nautilus, for the transport of fish and seawater. The Nautilus lasted until 1959.\nIn 1930, 20 railroad tank cars made eight round trips between Key West and Chicago to transport of seawater for the Shedd's saltwater exhibits. In 1933, Chicago hosted its second world's fair, the Century of Progress. The Aquarium was located immediately north of the fairgrounds, and the museum gained exposure to a large international crowd.\nIn 1971, Shedd Aquarium added one of its most popular exhibits, a exhibit reproducing a Caribbean coral reef. That same year, the aquarium acquired its first research vessel, a 75-foot (23 m) boat for exploring the Caribbean, manned by a crew to conduct field research and collect specimens. In 1985, this boat was replaced with the aquarium's current vessel, the \"Coral Reef II\".\nIn 1987, Shedd Aquarium was placed on the National Register of Historic Places.\nJohn Shedd's grandson, John Shedd Reed, who had served as president of Atchison, Topeka and Santa Fe Railroad from 1967 to 1986, was president of the aquarium's board from 1984 until 1994, and was a life trustee until his death in 2008. Ted A. Beattie served as president and CEO of the aquarium from 1994 until his retirement in 2016. Bridget C. Coughlin assumed duties as president and CEO of the company in the Spring of 2016.\nExhibits and presentations.\nThere are several permanent exhibits at Shedd: Waters of the World, Caribbean Reef, Amazon Rising, Wild Reef, and the Abbott Oceanarium.\nWaters of the World.\nThe oldest galleries in the aquarium feature exhibits on oceans, rivers, islands and lakes, and Chicago's own local waters. Species on exhibit include American bullfrog, a giant Pacific octopus, American alligator, lake sturgeon, starfish, lined seahorses, and alligator snapping turtle.\nCaribbean Reef.\nThe Caribbean Reef exhibit was built in 1971, on the site of the aquarium's very first exhibit, the Tropical Pool. A feature of this exhibit is a diver that interacts with the animals while talking with the people. A part of the exhibit is a circular tank that allows for maximum walk-around viewing. It was one of the first habitats to display schooling fish. It is also home to the rescued green sea turtle, Nickel, as well as Atlantic tarpons, cownose rays, redband parrotfish, Bonnethead sharks, a Green moray eel, and many more species. The exhibit is near the center of the first floor. It is adjacent to Amazon Rising, Waters of the World, and Wild Reef.\nAmazon Rising.\nThe Amazon Rising exhibit is a walkthrough flooded forest recreation of the Amazon River and the surrounding jungle. This exhibit contains 250 different species, and its highest water level is . Species from this area on exhibit include a green anaconda, red-bellied piranhas, electric eels, freshwater stingrays, dwarf caimans, caiman lizards, wattled jacanas, yellow-spotted river turtles, red-footed tortoises, yellow-footed tortoises, mata matas, Arapaimas, different species of South American birds, fish, and frogs, and many more.\nWild Reef.\nIn 2003, Shedd opened Wild Reef, a permanent exhibit located two levels below the main building. The exhibit contains a total of and recreates a Philippine coral reef on the Apo Island marine reserve, complete with living coral, multiple species of fish and rays, and a collection of sharks such as sandbar, zebra, blacktip reef sharks, white-spotted guitarfish, Spotted wobbegongs, and Japanese wobbegongs. The main draw of this attraction is a shark tank with high curved windows, allowing visitors a diver's-eye view. The Wild Reef exhibit also features a saltwater tank display area where coral is propagated and grown for conservation purposes.\nPolar Play Zone.\nThe exhibit is an interactive play area for children and contains an underwater viewing area of the beluga whales, Pacific white-sided dolphins and Sea otters. The exhibit also includes Southern rockhopper penguins and Magellanic penguins, as well as 5 circular tanks for moon jellyfish and starfishes that are by an interactive submarine model. There is also a starfish touch pool.\nStingray Touch.\nOpened on May 17, 2013, this exhibit allows guests to touch cownose rays as they swim around their outdoor exhibit. Located on the aquarium's South Terrace, this exhibit is open seasonally from May through October (weather permitting).\nOceanarium.\nIn 1991, Shedd Aquarium opened the Oceanarium (known since 2010 as the Abbott Oceanarium), a large addition to the aquarium that features marine mammals, including Pacific white-sided dolphins, beluga whales, sea otters and California sea lions, on the right side of the stairway that's next to the sea lions is an open estuary tank for several cuttlefish and by the sea otter exhibit, is a large natural looking touch tank for tide pool creatures like crabs, sea cucumbers and sea anemones. The lower level of the Oceanarium allows underwater viewing of the beluga whales and the dolphins. It holds in total; the largest single tank is the \"Whale Harbour\". The Oceanarium is the largest indoor marine mammal facility in the world. Several of the sea otters that lived in the aquarium in the past were rescued from the \"Exxon Valdez\" oil spill in 1989. In the fall of 2008, Shedd's Oceanarium was closed for preventive sealing as well as administrative upgrades. The animals in the exhibit area were temporarily moved to other zoos and aquariums until the exhibit reopened in May 2009.\nLand & Water.\nThe Land & Water aquatic presentation (formerly One World), replaced Fantasea in 2013. The show is presented at a 1,000 seat amphitheater in the Oceanarium and features Pacific white-sided dolphins, beluga whales, penguins, and California sea lions. A holiday version is sometimes shown in November and December.\n4D Theater.\nThe 4D Theater opened in 2009 as part of the renovation of the Abbott Oceanarium. The 4D experience includes a 3D film with interactive seats, high-tech audio and interactive elements like scents and bubbles. Films shown have included \"Blue Planet\", \"Splash and Bubbles\", \"Sea Monsters\", \"SpongeBob SquarePants 4-D\", \"\", \"Rudolph The Red-Nosed Reindeer\" (seasonal), and \"The Polar Express\" (seasonal).\nCurrent special exhibits.\nUnderwater Beauty.\nThis exhibit opened on May 25, 2018, and focuses on the visual beauty of sea life, with sections called \"Color\", \"Patterns\", and \"Rhythms.\" The exhibit features 100 different species of fish and invertebrate, displayed to accent their visual qualities, including the ribbon eel, lagoon jelly, flower hat jelly, peacock mantis shrimp, Weedy seadragon and longnose hawkfish.\nPrevious special exhibits.\nJellies.\nThe \"jellies\" exhibit opened in April 2011, focusing on jellyfish, and the misconceptions surrounding them. It featured at least 10 species of jellyfish, including moon jellyfish, egg-yolk jellyfish, purple-striped jelly, Atlantic sea nettle, jelly blubber and upside-down jellyfish. The exhibit closed in 2015.\nAmphibians.\nThe amphibian exhibit opened on May 15, 2015, and ran through January 1, 2018. It featured 40 different species of amphibians, including the gray tree frog, poison dart frog, fire-bellied toad, emperor newt, axolotl, tiger salamander, spring peeper, Japanese giant salamander, cane toad, and the marbled salamander.\nFantasea.\nFantasea was a multiple-aquatic animal show at Shedd Aquarium, running from October 16, 2009, through 2010. The show featured beluga whales, penguins and Pacific white-sided dolphins.\nAnimals on exhibit, past and present.\nAustralian Lungfish.\nWalter Chute, the aquarium's director from 1928 to 1964, wanted rare fish to attract the 10 million tourists expected to visit Chicago for the exposition in 1933. Granddad, an Australian lungfish, arrived at the Shedd in 1933, along with his mate, from Sydney during the Century of Progress world exposition. During the expo's run, they attracted about 4.5 million visitors.\nAt Granddad's death in 2017, he was claimed by the aquarium to be the oldest fish in any aquarium in the world. He was 109 years old; he weighed and was in length. His normal behavior was to lay like a sunken log on the bottom of his habitat.\nBeluga whales.\nShedd Aquarium related living Belugas as of November 15, 2022: Naya (F), Beethoven (M), Kayavak (F), Bella (F), Aurek (M), Kimalu (F), Annik (M) and Atlas (M).\nMauyak, Qannik, Miki, Kimalu, Annik: In 2000, Mauyak gave birth to Qannik, who was sent to Point Defiance Zoo in Tacoma where he died in 2009. On August 16, 2007, Mauyak gave birth yet again to a male calf named Miki, the Inuit word for \u2033small\u2033 bringing the total number of successful beluga calf births at the aquarium to four since 1999. Miki has been moved to the Mystic Aquarium in 2016. On August 27, 2012, Mauyak gave birth to a female calf, Kimalu. On July 3, 2019, Mauyak gave birth to a male calf, Annik, bringing the total number of belugas at Shedd to eight. Mauyak died on Saturday, November 12 2022. \nImmiayuk, Kayavak: Kayavak is one of the most famous residents of the Oceanarium. The whale became an orphan at only five months old after her mother, Immiayuk, died. Trainers fed Kayavak fish, cared for her day and night, taught her how to \"be a whale\", and she thrived to be the healthy adult she is today.\nPuiji, Bella, and Nunavik: In 2006, the beluga whale Puiji gave birth to a female calf, later named Bella. On December 14, 2009, she gave birth to a 162-pound, five-foot, four-inch male calf. Although it was a difficult birth, the calf survived and debuted to the public on Sunday, January 24, 2010. He has since been named \"Nunavik\" meaning \"friendly, beautiful, and wild\". Nunavik currently lives at the Georgia Aquarium as of 2016. Puiji died on Wednesday, October 26, 2011, following a seizure after having been undergoing treatment for an undisclosed medical condition over the course of several months.\nNaluark: Naluark was transferred to Mystic Aquarium & Institute for Exploration in Mystic, Connecticut, in October 2011. He has since been moved to SeaWorld Orlando in 2016.\nNaya: Another female beluga, named Naya, gave birth on December 20 to a 162-pound, five-foot two-inch male calf, though the calf died two days later from complications during birth.\nAlaskan sea otters.\nYaku (son of Kenai) was euthanized on February 26, 2022, due to failing health brought on by a tumor in his chest.\nKenai (\"Exxon Valdez\" oil spill survivor) was euthanized on October 9, 2012, due to failing health brought on by advancing years.\nKachemak (oldest sea otter in a North American Aquarium/Zoo) was euthanized on August 24, 2013, due to failing health related to age.\nSouthern sea otters.\nLuna (F), Cooper (M), Watson (M). Ellie (F)\nPacific white-sided dolphins.\nThe aquarium has five white sided dolphins: Kri (F), Katrl (F), Munchkin (F), Makoa (M) and Harmony (F).\nSagu and Makoa were conceived by Li'i at the Miami Seaquarium when Piquet was on a breeding loan there. Piquet gave birth to Sagu on Memorial Day weekend in 2012. Piquet gave birth to her second calf, Makoa on June 1, 2015. On April 18, 2016, Katrl gave birth to a male calf sired by Li'i. The calf was placed on display on June 18, 2016, and was named Kukdlaa meaning \"Bubbles\" in the Tlingit language. Piquet was moved to Miami SeaQuarium in early 2018 for a breeding loan and Ipo was transferred to Shedd to take her place.\nGreen sea turtle.\nNickel\nNickel is a female green sea turtle who resides at the Caribbean Reef exhibit located in directly in front of the main lobby. Nickel was rescued on Florida's Gulf Coast area in 1998, where she was struck by the propellers of a motorboat. This accident damaged her shell and paralyzed her from the waist down causing her to have buoyancy problems. Researchers thought that she could no longer live in the wild so she was brought to Shedd in the spring of 2003. Upon her arrival, she went through several medical examinations, including an x-ray. The x-ray revealed a 1975 nickel lodged in her throat which is where she received the name, Nickel. Nickel is one of the many rescued animals that reside in the Shedd. She serves as an example to many people of the effects human activities can have on wildlife.\nNorth American river otter.\nRio\nEuthanized on October 29, 2013, due to age related health issues, Rio was 21 and lived well past the median life expectancy of a North American river otter.\nGrouper.\nBubba\nBubba, a male Queensland grouper who was believed to be the first fish to undergo chemotherapy. He was introduced to the aquarium in 1987 and died in 2006.\nTarpon.\nDeadeye\nDeadeye, a female Atlantic tarpon, was the oldest fish to reside at the Caribbean Reef in the aquarium. She was first introduced to the aquarium in 1935 and died in 1998.\nAmerican alligators.\nIn 2016, the Shedd Aquarium introduced for the first time American alligators (\"Alligator mississippiensis\") to its permanent exhibit spaces. Eight juvenile alligators were added to the Islands and Lakes galleries.\nArchitecture.\nShedd Aquarium is also notable for its architecture. The basic design, by architectural firm Graham, Anderson, Probst & White, is taken from classical Greek architecture, more specifically Beaux Arts, to match the other structures of the Museum Campus. The central aquarium building is octagonal, fronted by Doric columns and a formal staircase and topped by a dome. Aquatic motifs are worked in at every opportunity; tortoise shells, dolphins, octopuses, waves, and even the Trident of Poseidon can be found all over the aquarium's exterior and interior. Improving upon its predecessor inland aquarium, the Belle Isle Aquarium in Detroit, extensive use was made of designs by Mary Chase Perry Stratton, incorporating her custom-made Pewabic Pottery tile. The Oceanarium is done in a more modern style representing the Pacific Northwest, but one that blends with the older part of the building. \"Whale Harbor\", the Oceanarium's main tank, is backed by a wall of windows that look out onto Lake Michigan.\nConservation and research.\nThe Daniel P. Haerther Center for Conservation and Research helps to provide on-site research at the aquarium. They study topics such as animal health and behavior, nutrition, animal training, reproduction and genetics.\nThe International Union for Conservation of Nature (IUCN) designated the Shedd Aquarium as its Center for Species Survival:Freshwater, to study and promote the conservation and restoration of global freshwater systems, and strategies for freshwater species survival.\nThe aquarium also partners with conservation efforts in the Caribbean and Southeast Asia. The Bahamian rock iguana is one of the most endangered lizards in the world. Since 1994, the Shedd Aquarium has been studying and providing conservation plans for this iguana. The Shedd Aquarium is now recognized as the lead authority on this iguana. In Southeast Asia, the Shedd partners with Project Seahorse to monitor and map out the seahorse populations in Southeast Asia.\nSince 1991, the Shedd Aquarium has been involved with research focused on beluga whales. They focus on the animal handling procedures to ensure the animals\u2019 welfare. The aquarium does most of their beluga whale research in Bristol Bay in southwest Alaska.", "categories": ["Category:1930 establishments in Illinois", "Category:All articles with self-published sources", "Category:Aquaria in Illinois", "Category:Articles using NRISref without a reference number", "Category:Articles with BGCI identifiers", "Category:Articles with ISNI identifiers", "Category:Articles with J9U identifiers", "Category:Articles with LCCN identifiers", "Category:Articles with SUDOC identifiers", "Category:Articles with Structurae structure identifiers"]}, {"docid": 6670017, "title": "Bornean orangutan", "text": "The Bornean orangutan (Pongo pygmaeus) is a species of orangutan endemic to the island of Borneo. Together with the Sumatran orangutan (\"Pongo abelii\") and Tapanuli orangutan (\"Pongo tapanuliensis\"), it belongs to the only genus of great apes native to Asia. Like the other great apes, orangutans are highly intelligent, displaying tool use and distinct cultural patterns in the wild. Orangutans share approximately 97% of their DNA with humans. Also called mias by the local population, the Bornean orangutan is a critically endangered species, with deforestation, palm oil plantations, and hunting posing a serious threat to its continued existence.\nTaxonomy.\nThe Bornean orangutan and the Sumatran orangutan diverged about 400,000 years ago, with a continued low level of gene flow between them since then. The two orangutan species were considered merely subspecies until 1996; they were elevated to species following sequencing of their mitochondrial DNA.\nThe Bornean orangutan has three subspecies:\nThere is some uncertainty about this, however. The population currently listed as \"P. p. wurmbii\" may be closer to the Sumatran orangutan (\"P. abelii\") than to the Bornean orangutan. If this is confirmed, \"P. abelii\" would be a subspecies of \"P. wurmbii\" (Tiedeman, 1808). In addition, the type locality of \"P. pygmaeus\" has not been established beyond doubt; it may be from the population currently listed as \"P. wurmbii\" (in which case \"P. wurmbii\" would be a junior synonym of \"P. pygmaeus\", while one of the names currently considered a junior synonym of \"P. pygmaeus\" would take precedence for the taxon in Sarawak and northern West Kalimantan). Bradon-Jones \"et al.\" considered \"P. morio\" to be a synonym of \"P. pygmaeus\", and the population found in East Kalimantan and Sabah to be a potentially unnamed separate taxon.\nIn early October 2014, researchers from domestic and foreign countries found about 50 orangutans in several groups in South Kalimantan Province, although previously there is no record that the province has orangutans.\nAs a member of the family Hominidae, Bornean orangutans are one of the closest extant relatives to \"Homo sapiens\".\nThis species was originally discovered by native Malaysians. There are several mentions of orangutans in Malaysian folklore. However, this species was originally named and described by the notable zoologist Carl Linnaeus in 1799. Its original name was \"Simia satyrus\", meaning \"satyr monkey\", but was changed when scientists discovered that not all orangutans are one species. The holotype of this organism is located in the British Museum in London.\nThe current species name \"P. pygmaeus\" is not Latin unlike most other Linnean classifications. The genus name \"Pongo\" is derived from the Bantu word \"\" used to indicate a large primate. It was originally used to describe chimpanzees in Western African dialects. The species name \"pygmaeus\" is derived from the Greek word \"pygmy\" meaning dwarf.\nPhysical description.\nThe Bornean orangutan is the third-largest ape after the western gorilla, and the largest truly arboreal (or tree-dwelling) extant ape. Body weights broadly overlap with the considerably taller \"Homo sapiens\", but the latter is considerably more variable in size. By comparison, the Sumatran orangutan is similar in size but, on average, is marginally lighter in weight. A survey of wild orangutans found that males weigh on average , ranging from , and long; females average , ranging from , and long. While in captivity, orangutans can grow considerably overweight, up to more than . The heaviest known male orangutan in captivity was an obese male named \"Andy\", who weighed in 1959 when he was 13 years old.\nThe Bornean orangutan has a distinctive body shape with very long arms that may reach up to 1.5 metres in length. It has grey skin, a coarse, shaggy, reddish coat and prehensile, grasping hands and feet. Its coat does not cover its face unlike most mammals, although Bornean orangutans do have some hair on their faces including a beard and mustache. It also has large, fatty cheek pads known as flanges as well as a pendulous throat sac.\nBornean orangutans are highly sexually dimorphic and have several features that differ between males and females. Males have much larger cheek pads, or flanges, that are composed of muscle and large amounts of fat. In females, the flanges are mostly composed of muscle. Males have relatively larger canines and premolars. Males have a more pronounced beard and mustache. The throat sac in males is also considerably larger. There are two body types for sexually mature males: smaller or larger. Larger males are more dominant but smaller males still breed successfully. There is little sexual dimorphism at birth.\nHabitat and distribution.\nThe Bornean orangutan lives in tropical rain forests in the Bornean lowlands, as well as montane rain forests in mountainous areas up to above sea level. This species lives throughout the canopy of primary and secondary forest, and moves large distances to find trees bearing fruit.\nIt is found in the two Malaysian states of Sabah and Sarawak, and four of the five Indonesian Provinces of Kalimantan. Due to habitat destruction, the species distribution is now highly patchy throughout the island, the species has become rare in the southeast of the island, as well as in the forest between the Rajang River in central Sarawak and the Padas River in western Sabah. Its presence in Brunei is uncertain and unconfirmed.\nThe first complete orangutan skeleton that was discovered was in the Hoa Binh province in Vietnam and thought to be from the late Pleistocene epoch. It differed from modern orangutans only in that its body was proportionately smaller compared to its head. This fossil and others confirm that orangutans once inhabited continental Southeast Asia even though currently, Bornean orangutans are only found in Malaysia and Indonesia.\nBehavior and ecology.\nIn history, orangutans ranged throughout Southeast Asia and into southern China, as well as on the island of Java and in southern Sumatra. They primarily inhabit peat swamp forest, tropical heath forest, and mixed dipterocarp forest.\nBornean orangutan are more solitary than their Sumatran relatives. Two or three orangutans with overlapping territories may interact, but only for short periods of time. Although orangutans are not territorial, adult males will display threatening behaviors upon meeting other males, and only socialize with females to mate. Males are considered the most solitary of the orangutans. The Bornean orangutan has a lifespan of 35\u201345 years in the wild; in captivity it can live to be about 60.\nDespite being arboreal, the Bornean orangutan travels on the ground more than its Sumatran counterpart. This may be in part because no large terrestrial predators could threaten an orangutan in Borneo. In Sumatra, orangutans must face predation by the fierce Sumatran tiger.\nThe Bornean orangutan exhibits nest-building behavior. Nests are built for use at night or during the day. Young orangutans learn by observing their mother's nest-building behaviour. This skill is practiced by juvenile orangutans. Nests may be elaborate and involve a foundation and mattress made by intertwining leaves and branches and adding broken leafy branches. Additional features such as shade, waterproof roof, \"pillow\", and \"blanket\", all of which are made from branches, twigs and leaves, may also be added. Nest-building in primates is considered as an example of tool use and not animal architecture.\nDiet.\nThe Bornean orangutan diet is composed of over 400 types of food, including wild figs, durians (\"Durio zibethinus\" and \"D. graveolens\"), leaves, seeds, bird eggs, flowers, sap, vines, honey, fungi, spider webs, insects, and, to a lesser extent than the Sumatran orangutan, bark. They have also been known to consume the inner shoots of plants and vines. They will also occasionally eat nutrient rich soil. They get the necessary quantities of water from both fruit and from tree holes.\nBornean orangutans have been sighted using spears to attempt (unsuccessfully) to catch fish. The species has been observed using tools such as leaves to wipe off faeces, a pad of leaves for holding spiny durian fruit, a leafy branch for a bee swatter, a bunch of leafy branches held together as an \"umbrella\" while traveling in the rain, a single stick as backscratcher, and a branch or tree trunk as a missile. In some regions, orangutans occasionally eat soil to get minerals that may neutralize the toxins and acids they consume in their primarily vegetarian diets. On rare occasions, orangutans will prey upon other, smaller primates, such as slow lorises.\nReproduction.\nMales and females generally come together only to mate. Subadult males (unflanged) will try to mate with any female and will be successful around half the time. Dominant flanged males will call and advertise their position to receptive females, who prefer mating with flanged males. Adult males will often target females with weaned infants as mating partners because the female is likely to be fertile.\nFemales reach sexual maturity and experience their first ovulatory cycle between about six and 11 years of age, although females with more body fat may experience this at an earlier age. The estrous cycle lasts between 22 and 30 days and menopause has been reported in captive orangutans at about age 48. Females tend to give birth at about 14\u201315 years of age. Newborn orangutans nurse every three to four hours, and begin to take soft food from their mothers' lips by four months. During the first year of its life, the young clings to its mother's abdomen by entwining its fingers in and gripping her hair. Offspring are weaned at about four years, but this could be much longer, and soon after they start their adolescent stage of exploring, but always within sight of their mother. During this period, they will also actively seek other young orangutans to play with and travel with. On average, juveniles do not become completely independent until they are about seven years of age. The birth rate for orangutans has been decreasing largely due to a lack of sufficient nutrients as a result of habitat loss.\nA 2011 study on female orangutans in free-ranging rehabilitation programs found that individuals that were supplemented with food resources had shorter interbirth intervals, as well as a reduced age, at first birth.\nConservation status.\nThe Bornean orangutan is more common than the Sumatran, with about 104,700 individuals in the wild, whereas just under 14,000 Sumatran orangutans are left in the wild. Orangutans are becoming increasingly endangered due to habitat destruction and the bushmeat trade, and young orangutans are captured to be sold as pets, usually entailing the killing of their mothers.\nThe Bornean orangutan is critically endangered according to the IUCN Red List of mammals, and is listed on Appendix I of CITES. The total number of Bornean orangutans is estimated to be less than 14% of what it was in the recent past (from around 10,000 years ago until the middle of the 20th century), and this sharp decline has occurred mostly over the past few decades due to human activities and development. Species distribution is now highly patchy throughout Borneo; it is apparently absent or uncommon in the southeast of the island, as well as in the forest between the Rajang River in central Sarawak and the Padas River in western Sabah (including the Sultanate of Brunei). A population of around 6,900 is found in Sabangau National Park, but this environment is at risk.\nThis view is also supported by the United Nations Environment Programme, which stated in its 2007 report that, due to illegal logging, fire and the extensive development of palm oil plantations, orangutans are critically endangered, and if the current trend continues, they will become extinct. When forest is burned down to clear room for palm oil plantations, not only does the Bornean orangutan suffer from habitat loss, but several individuals have been burned and killed in fires. Palm oil accounts for over one tenth of Indonesia's export earnings. It is in high demand because it is used in several packaged foods, deodorants, shampoos, soaps, candies, and baked goods.\nClimate change is another threat to Bornean orangutan conservation. The effects that human activity have had on Indonesian rainfall have made food less abundant and so Bornean orangutans are less likely to receive full nutrients so that they can be sufficiently healthy to breed.\nA November 2011 survey, based on interviews with 6,983 respondents in 687 villages across Kalimantan in 2008 to 2009, gave estimated orangutan killing rates of between 750 and 1800 in the year leading up to April 2008. These killing rates were higher than previously thought and confirm that the continued existence of the orangutan in Kalimantan is under serious threat. The survey did not quantify the additional threat to the species due to habitat loss from deforestation and expanding palm-oil plantations. The survey found that 73% of respondents knew orangutans were protected by Indonesian law.\nHowever, the Indonesian government rarely prosecutes or punishes perpetrators. In a rare prosecution in November 2011, two men were arrested for killing at least 20 orangutans and a number of long-nosed proboscis monkeys. They were ordered to conduct the killings by the supervisor of a palm oil plantation, to protect the crop, with a payment of $100 for a dead orangutan and $22 for a monkey.\nRescue and rehabilitation centers.\nA number of orangutan rescue and rehabilitation projects operate in Borneo.\nThe Borneo Orangutan Survival Foundation (BOS) founded by Dr Willie Smits has rescue and rehabilitation centres at Wanariset and Samboja Lestari in East Kalimantan and Nyaru Menteng, in Central Kalimantan founded and managed by Lone Dr\u00f8scher Nielsen. BOS also works to conserve and recreate the fast-disappearing rainforest habitat of the orangutan, at Samboja Lestari and Mawas.\nOrangutan Foundation International, founded by Dr Birut\u0117 Galdikas, rescues and rehabilitates orangutans, preparing them for release back into protected areas of the Indonesian rain forest. In addition, it promotes the preservation of the rain forest for them.\nThe Sepilok Orangutan Rehabilitation Centre near Sandakan in the state of Sabah in Malaysian Borneo opened in 1964 as the first official orangutan rehabilitation project.\nOrangutan Foundation, founded by Ashley Leiman, operates programmes in Central Kalimantan, Indonesian Borneo. The Foundation rescues orphaned orangutans and enters them into their soft-release programme, allowing them to develop the skills necessary to survive in the wild. When old enough, orangutans are released into the protected Lamandau Wildlife Reserve. Orangutan Foundation works to protect orangutans by focusing on habitat protection and capacity building, especially in local communities.\nA seven-year longitudinal study published in 2011 looked at whether the lifespan of zoo-housed orangutans was related to a subjective assessment of well-being, with the intent of applying such measures to assess the welfare of orangutans in captivity. Of the subjects, 100 were Sumatran (\"Pongo abelii\"), 54 Bornean (\"Pongo pygmaeus\") and 30 were hybrid orangutans. 113 zoo employees, who were highly familiar with the typical behavior of the orangutans, used a four-item questionnaire to assess their subjective well-being. The results indicated that orangutans in higher subjective well-being were less likely to die during the follow-up period. The study concluded that happiness was related to longer life in orangutans.\nIn late 2014, Nyaru Menteng veterinarians failed to rescue the life of a female orangutan. An operation was performed in which 40 air-rifle pellets were removed from her body. The orangutan was found at a palm oil plantation in Indonesian Borneo.\nGenome and Demographic History.\nOrangutans and humans diverged lineages approximately 14-18 million years ago. About 17,000 years ago, there was a migration of the Bornean orangutans as they eventually went to Sumatra, effectively trading places with the Sumatra orangutans that were there at the time. These two species of orangutans have been closely related throughout their evolutionary history due to the fact that they were so close in physical proximity. Therefore, their genomes and demographic history are similar. The two species themselves are estimated to have split about 3.5 million years ago. Although these two species have officially diverged, it is speculated that the reason as to why they are genetically similar is because the males of each respective species tend to migrate between the two islands and breed with the females from their sister species. As a result, both the Bornean orangutans and the Sumatran orangutans have been studied closely as a pair, and thus much genome findings attribute evolutionary changes to this relationship. In addition, the Bornean orangutans, as compared to the Sumatran orangutans, have lower autosomal gene diversity. This is attributed to the fact that they have a much smaller population size. Also, the Bornean orangutans have lower nucleotide diversity.\nAs the Bornean orangutans and Sumatra orangutans both exist within the same species, they exhibit similar cultural behaviors that have been found to exist amongst most orangutan populations. The fact that orangutans tend to showcase similar cultural traditions is due to the fact that they typically live in similar environments and are adept at learning from one another from their early stages of life.\nThe Bornean orangutan has been linked to the fact that it has gone through a deep divergence in relation to its relatives and ancestors. During the Middle Pleistocene, there were low levels of gene flow, which was determined through the analysis of Y-chromosomal data. One reason as to why this may have occurred is because of the Sunda shelf, which is where the island of Borneo is located. During this time, this event's dry climate during the Late Pleistocene attributed to a more abundant genetic exchange. As a result, there were many early divergences of gene pools between the Bornean orangutans, as well as the Sumatran orangutans. Relating back to the Middle Pleistocene, the Bornean orangutan lineage went through a dramatic population decline. This is likely attributed to the fact that they had been isolated from their ancestral populations. Therefore, natural geographic barriers are attributed to be the reason as to why the Bornean orangutans were eventually isolated and ended up colonizing other regions. In addition, this geographic isolation also indicates that the Bornean orangutans did not undergo a severe genetic bottleneck. With the Borneo orangutan, selection was found to have been found through physiological adaptations \u2013 most of which has to do with being able to adapt to the ever-changing climate on the Borneo island.", "categories": ["Category:ARKive links", "Category:Articles with 'species' microformats", "Category:Articles with short description", "Category:Articles with text in Bantu languages", "Category:CS1 Indonesian-language sources (id)", "Category:Commons category link is on Wikidata", "Category:Critically endangered fauna of Asia", "Category:Critically endangered fauna of Indonesia", "Category:East Kalimantan", "Category:Endemic fauna of Borneo"]}, {"docid": 477917, "title": "Lemur", "text": "Lemurs ( ) (from Latin \"lemures\" \u2013 ghosts or spirits) are wet-nosed primates of the superfamily Lemuroidea (), divided into 8 families and consisting of 15 genera and around 100 existing species. They are endemic to the island of Madagascar. Most existing lemurs are small, have a pointed snout, large eyes, and a long tail. They chiefly live in trees and are active at night. \nLemurs share resemblance with other primates, but evolved independently from monkeys and apes. Due to Madagascar's highly seasonal climate, lemur evolution has produced a level of species diversity rivaling that of any other primate group. Until shortly after humans arrived on the island around 2,000\u00a0years ago, there were lemurs as large as a male gorilla. Most species have been discovered or promoted to full species status since the 1990s; however, lemur taxonomic classification is controversial and depends on which species concept is used.\nLemurs range in weight from the mouse lemur to the indri. Lemurs share many common basal primate traits, such as divergent digits on their hands and feet, and nails instead of claws (in most species). However, their brain-to-body size ratio is smaller than that of anthropoid primates. As with all strepsirrhine primates, they have a \"wet nose\" (rhinarium). Lemurs are generally the most social of the strepsirrhine primates, and communicate more with scents and vocalizations than with visual signals. Lemurs have a relatively low basal metabolic rate, and as a result may exhibit dormancy such as hibernation or torpor. They also have seasonal breeding and female social dominance. Most eat a wide variety of fruits and leaves, while some are specialists. Two species of lemurs may coexist in the same forest due to different diets.\nLemur research during the 18th and 19th centuries focused on taxonomy and specimen collection. Modern studies of lemur ecology and behavior did not begin in earnest until the 1950s and 1960s. Initially hindered by political issues on Madagascar during the mid-1970s, field studies resumed in the 1980s. Lemurs are important for research because their mix of ancestral characteristics and traits shared with anthropoid primates can yield insights on primate and human evolution. Many lemur species remain endangered due to habitat loss and hunting. Many lemur species have already gone extinct in the last 2000 years due to human activity, and are collectively referred to as the \"subfossil lemurs\". These are typically larger than extant lemurs, with the largest, \"Archaeoindris\", being the size of a gorilla. Although local traditions, such as fady, generally help protect lemurs and their forests, illegal logging, economic privation and political instability conspire to thwart conservation efforts. Because of these threats and their declining numbers, the International Union for Conservation of Nature (IUCN) considers lemurs to be the world's most endangered mammals, noting that up to 90% of all lemur species confront the threat of extinction in the wild within the next 20 to 25\u00a0years. As an iconic flagship species that exemplifies the biodiverse fauna of Madagascar, however, lemurs have facilitated the emergence of eco-tourism in Madagascar in World Heritage Sites, such as the Rainforests of the Atsinanana in eastern Madagascar. In addition, conservation organizations, such as the Lemur Conservation Foundation and the Duke Lemur Center, increasingly seek to implement community-based approaches, such as encouraging local communities to adopt sustainable agriculture and afforestation initiatives, to expand employment opportunities for ecological programs, preserve lemur habitats as well as promote public awareness and appreciation for lemurs.\nEtymology.\nThe name lemur is derived from the Latin \"lemures\", which refers to specters or ghosts that were exorcised during the Lemuria festival of ancient Rome.\nCarl Linnaeus, the founder of modern binomial nomenclature, gave lemurs their name as early as 1758, when he used it in the 10th edition of \"Systema Naturae\". He included three species under the genus \"Lemur\": \"Lemur tardigradus\" (the red slender loris, now known as \"Loris tardigradus\"), \"Lemur catta\" (the ring-tailed lemur), and \"Lemur volans\" (the Philippine colugo, now known as \"Cynocephalus volans\").\nAlthough the term \"lemur\" was first intended for slender lorises, it was soon limited to the endemic Malagasy primates, which have been known as \"lemurs\" ever since. According to Linnaeus' own explanation, the name was selected because of the nocturnal activity and slow movements of the slender loris. Being familiar with the works of Virgil and Ovid and seeing an analogy that fit with his naming scheme, Linnaeus adapted the term \"lemur\" for these nocturnal primates.\nIt was noted in 2012 that it has been commonly and falsely assumed that Linnaeus was referring to the ghost-like appearance, reflective eyes, and ghostly cries of lemurs. It has also been speculated that Linnaeus may also have known that some Malagasy people have held legends that lemurs are the souls of their ancestors, but this is unlikely given that the name was selected for slender lorises from India.\nEvolutionary history.\nLemurs are primates belonging to the suborder Strepsirrhini. Like other strepsirrhine primates, such as lorises, pottos, and galagos, they share ancestral (or plesiomorphic) traits with early primates. In this regard, lemurs are popularly confused with ancestral primates; however, lemurs did not give rise to monkeys and apes (simians). Instead, they evolved independently in isolation on Madagascar. All in strepsirrhines including lemurs are traditionally thought to have evolved from early primates known as adapiforms during the Eocene (56 to 34\u00a0mya) or Paleocene (66 to 56\u00a0mya). Adapiforms, however, lack a specialized arrangement of teeth, known as a toothcomb, which nearly all living strepsirrhines possess. A more recent hypothesis is that lemurs descended from lorisoids (loris-like) primates. This is supported by comparative studies of the cytochrome\u00a0b gene and the presence of the strepsirrhine toothcomb in both groups. Instead of being the direct ancestors of lemurs, the adapiforms may have given rise to both the lemurs and lorisoids, a split that would be supported by molecular phylogenetic studies. The later split between lemurs and lorises is thought to have occurred approximately 62 to 65\u00a0mya according to molecular studies, although other genetic tests and the fossil record in Africa suggest more conservative estimates of 50 to 55\u00a0mya for this divergence. However, the oldest lemur fossils on Madagascar are actually subfossils dating to the Late Pleistocene.\nOnce part of the supercontinent Gondwana, the island of Madagascar has been isolated since it broke away from eastern Africa (~160\u00a0mya), Antarctica (~80\u2013130\u00a0mya), and India (~80\u201390\u00a0mya). Since ancestral lemurs are thought to have originated in Africa around 62 to 65\u00a0mya, they must have crossed the Mozambique Channel, a deep channel between Africa and Madagascar with a minimum width of about 560\u00a0km (350\u00a0mi). In 1915, paleontologist William Diller Matthew noted that the mammalian biodiversity on Madagascar (including lemurs) can only be accounted for by random rafting events, where very small populations rafted from nearby Africa on tangled mats of vegetation, which get flushed out to sea from major rivers. This form of biological dispersal can occur randomly over millions of years. In the 1940s, American paleontologist George Gaylord Simpson coined the term \"sweepstakes hypothesis\" for such random events. Rafting has since been the most accepted explanation for the lemur colonization of Madagascar, but until recently this trip was thought to be very unlikely because strong ocean currents flow away from the island. In , a report demonstrated that around 60\u00a0mya both Madagascar and Africa were 1,650\u00a0km (1,030\u00a0mi) south of their present-day positions, placing them in a different ocean gyre, producing currents that ran counter to what they are today. The ocean currents were shown to be even stronger than today, which would have pushed a raft along faster, shortening the trip to 30\u00a0days or less\u2014short enough for a small mammal to survive easily. As the continental plates drifted northward, the currents gradually changed, and by 20\u00a0mya the window for oceanic dispersal had closed, effectively isolating the lemurs and the rest of the terrestrial Malagasy fauna from mainland Africa. Isolated on Madagascar with only a limited number of mammalian competitors, the lemurs did not have to compete with other evolving arboreal mammalian groups, such as squirrels. They were also spared from having to compete with monkeys, which evolved later. The intelligence, aggression, and deceptiveness of monkeys gave them an advantage over other primates in exploiting the environment.\nDistribution and diversity.\nLemurs have adapted to fill many open ecological niches since making their way to Madagascar. Their diversity in both behavior and morphology (outward appearance) rivals that of the monkeys and apes found elsewhere in the world. Ranging in size from the 30\u00a0g (1.1\u00a0oz) Madame Berthe's mouse lemur, the world's smallest primate, to the recently extinct 160\u2013200\u00a0kg (350\u2013440\u00a0lb) \"Archaeoindris fontoynonti\", lemurs evolved diverse forms of locomotion, varying levels of social complexity, and unique adaptations to the local climate.\nLemurs lack any shared traits that make them stand out from all other primates. Different types of lemurs have evolved unique combinations of unusual traits to cope with Madagascar's harsh, seasonal climate. These traits can include seasonal fat storage, hypometabolism (including torpor and hibernation), small group sizes, low encephalization (relative brain size), cathemerality (activity both day and night), and strict breeding seasons. Extreme resource limitations and seasonal breeding are also thought to have given rise to three other relatively common lemur traits: female social dominance, sexual monomorphism, and male\u2013male competition for mates involving low levels of agonism, such as sperm competition.\nBefore the arrival of humans roughly 1500 to 2000\u00a0years ago, lemurs were found all across the island. However, early settlers quickly converted the forests to rice paddies and grassland through slash-and-burn agriculture (known locally as \"tavy\"), restricting lemurs to approximately 10% of the island's area, ~60,000\u00a0km2 (23,000\u00a0sq mi). Today, the diversity and complexity of lemur communities increases with floral diversity and precipitation and is highest in the rainforests of the east coast. Despite their adaptations for weathering extreme adversity, habitat destruction and hunting have resulted in lemur populations declining sharply, and their diversity has diminished, with the recent extinction of at least 17\u00a0species in eight genera, known collectively as the subfossil lemurs. Most of the approximately 100\u00a0species and subspecies of lemur are either threatened or endangered. Unless trends change, extinctions are likely to continue.\nUntil recently, giant lemurs existed on Madagascar. Now represented only by recent or subfossil remains, they were modern forms that were once part of the rich lemur diversity that has evolved in isolation. Some of their adaptations were unlike those seen in their living relatives. All 17\u00a0extinct lemurs were larger than the extant (living) forms, some weighing as much as 200\u00a0kg (440\u00a0lb), and are thought to have been active during the day. Not only were they unlike the living lemurs in both size and appearance, they also filled ecological niches that either no longer exist or are now left unoccupied. Large parts of Madagascar, which are now devoid of forests and lemurs, once hosted diverse primate communities that included more than 20\u00a0lemur species covering the full range of lemur sizes.\nTaxonomic classification and phylogeny.\nFrom a taxonomic standpoint, the term \"lemur\" originally referred to the genus \"Lemur\", which currently contains only the ring-tailed lemur. The term is now used in the colloquial sense in reference to all Malagasy primates.\nLemur taxonomy is controversial, and not all experts agree, particularly with the recent increase in the number of recognized species. According to Russell Mittermeier, the president of Conservation International (CI), taxonomist Colin Groves, and others, there are nearly 100\u00a0recognized species or subspecies of extant (or living) lemur, divided into five families and 15\u00a0genera. Because genetic data indicates that the recently extinct subfossil lemurs were closely related to living lemurs, an additional three families, eight genera, and 17\u00a0species can be included in the total. In contrast, other experts have labeled this as taxonomic inflation, instead preferring a total closer to 50 species.\nThe classification of lemurs within the suborder Strepsirrhini is equally controversial, although most experts agree on the same phylogenetic tree. In one taxonomy, the infraorder Lemuriformes contains all living strepsirrhines in two superfamilies, Lemuroidea for all lemurs and Lorisoidea for the lorisoids (lorisids and galagos). Alternatively, the lorisoids are sometimes placed in their own infraorder, Lorisiformes, separate from the lemurs. In another taxonomy published by Colin Groves, the aye-aye was placed in its own infraorder, Chiromyiformes, while the rest of the lemurs were placed in Lemuriformes and the lorisoids in Lorisiformes.\nAlthough it is generally agreed that the aye-aye is the most basal member of the lemur clade, the relationship between the other four families is less clear since they diverged during a narrow 10 to 12\u00a0million-year window between the Late Eocene (42\u00a0mya) and into the Oligocene (30\u00a0mya). The two main competing hypotheses are shown in the adjacent image.\nLemur taxonomy has changed significantly since the first taxonomic classification of lemurs by Carl Linnaeus in 1758. One of the greatest challenges has been the classification of the aye-aye, which has been a topic of debate up until very recently. Until Richard Owen published a definitive anatomical study in 1866, early naturalists were uncertain whether the aye-aye (genus \"Daubentonia\") was a primate, rodent, or marsupial. However, the placement of the aye-aye within the order Primates remained problematic until very recently. Based on its anatomy, researchers have found support for classifying the genus \"Daubentonia\" as a specialized indriid, a sister group to all strepsirrhines, and as an indeterminate taxon within the order Primates. Molecular tests have now shown Daubentoniidae is basal to all Lemuriformes, and in 2008, Russell Mittermeier, Colin Groves, and others ignored addressing higher-level taxonomy by defining lemurs as monophyletic and containing five living families, including Daubentoniidae.\nRelationships among lemur families have also proven to be problematic and have yet to be definitively resolved. To further complicate the issue, several Paleogene fossil primates from outside Madagascar, such as \"Bugtilemur\", have been classified as lemurs. However, scientific consensus does not accept these assignments based on genetic evidence, and therefore it is generally accepted that the Malagasy primates are monophyletic. Another area of contention is the relationship between the sportive lemurs and the extinct koala lemurs (Megaladapidae). Formerly grouped in the same family due to similarities in dentition, they are no longer considered to be closely related due to genetic studies.\nMore taxonomic changes have occurred at the genus level, although these revisions have proven more conclusive, often supported by genetic and molecular analysis. The most noticeable revisions included the gradual split of a broadly defined genus \"Lemur\" into separate genera for the ring-tailed lemur, ruffed lemurs, and brown lemurs due to a host of morphological differences.\nDue to several taxonomic revisions by Russell Mittermeier, Colin Groves, and others, the number of recognized lemur species has grown from 33 species and subspecies in 1994 to approximately 100 in 2008. With continuing cytogenetic and molecular genetic research, as well as ongoing field studies, particularly with cryptic species such as mouse lemurs, the number of recognized lemur species is likely to keep growing. However, the rapid increase in the number of recognized species has had its critics among taxonomists and lemur researchers. Since classifications ultimately depend on the species concept used, conservationists often favor definitions that result in the splitting of genetically distinct populations into separate species to gain added environmental protection. Others favor a more thorough analysis.\nAnatomy and physiology.\nLemurs vary greatly in size. They include the smallest primates in the world and, until recently, also included some of the largest. They currently range in size from about 30\u00a0g (1.1\u00a0oz) for Madame Berthe's mouse lemur (\"Microcebus berthae\") up to 7\u20139\u00a0kg (15\u201320\u00a0lb) for the indri (\"Indri indri\") and diademed sifaka (\"Propithecus diadema\"). One recently extinct species rivaled the gorilla in size, at 160\u2013200\u00a0kg (350\u2013440\u00a0lb) for \"Archaeoindris fontoynonti\".\nLike all primates, lemurs have five divergent digits with nails (in most cases) on their hands and feet. Most lemurs possess a laterally compressed, elongated nail, called a toilet-claw, on the second toe and use it for scratching and grooming. In addition to the toilet-claw, lemurs share a variety of other traits with other strepsirrhine primates, which include a rhinarium (or \"wet nose\"); a fully functional vomeronasal organ, which detects pheromones; a postorbital bar and the lack of postorbital closure (a wall of thin bone behind the eye); orbits (bony sockets that enclose the eye) that are not fully facing forward; left and right mandible (lower jaw) bones that are not fully fused; and a small brain-to-body mass ratio.\nAdditional traits shared with other prosimian primates (strepsirrhine primates and tarsiers) include a bicornuate (two-horned) uterus and epitheliochorial placentation. Because their thumbs are only pseudo-opposable, making their movement less independent of the other fingers, their hands are less than perfect at grasping and manipulating objects. On their feet, they have a widely abducted hallux (first toe) which facilitates the grasping of tree limbs. A common misconception is that lemurs have a prehensile tail, a trait found only in New World monkeys, particularly atelids, among primates. Lemurs also rely heavily on their sense of smell, a trait shared with most other mammals and early primates, but not with the visually oriented higher primates. This sense of smell is important in terms of marking territory as well as provide an indication of whether or not another lemur is a viable breeding partner.\nLemurs are a diverse group of primates in terms of morphology and physiology. Some lemurs, such as the sportive lemurs and indriids, have longer hind limbs than forelimbs, making them excellent leapers. Indriids also have a specialized digestive system for folivory, exhibiting enlarged salivary glands, a spacious stomach, and an elongated caecum (lower gut) that facilitates fermentation. The hairy-eared dwarf lemur (\"Allocebus trichotis\") reportedly has a very long tongue, allowing it to feed on nectar. Likewise, the red-bellied lemur (\"Eulemur rubriventer\") has a feathery brush-shaped tongue, also uniquely adapted to feed on nectar and pollen. The aye-aye has evolved some traits that are unique among primates, making it stand out among the lemurs. Such traits include continuously growing, rodent-like front teeth for gnawing through wood and hard seeds; a highly mobile, filiform (filament-shaped) middle finger for extracting food from tiny holes; large, bat-like ears for detecting hollow spaces within trees; and use of self-generated acoustical cues to forage.\nLemurs are unusual since they have great variability in their social structure, yet generally lack sexual dimorphism in size and canine tooth morphology. However, some species tend towards having larger females, and two species of true lemur (genus \"Eulemur\"), the gray-headed lemur (\"E. albocollaris\") and the red lemur (\"E. rufus\"), exhibit size differences in canine teeth. True lemurs show sexual dichromatism (sexual differences in fur coloration), but the difference between the genders varies from strikingly obvious, as in the blue-eyed black lemur (\"E. macaco\"), to nearly imperceptible in the case of the common brown lemur (\"E. fulvus\").\nCrypsis, or the inability of humans to visually distinguish between two or more distinct species, has recently been discovered among lemurs, particularly within the sportive lemurs (\"Lepilemur\") and mouse lemurs (\"Microcebus\"). With sportive lemurs, subspecies were traditionally defined based on slight morphological differences, but new genetic evidence has supported giving full species status to these regional populations. In the case of mouse lemurs, the gray mouse lemur (\"M. murinus\"), golden-brown mouse lemur (\"M. ravelobensis\"), and Goodman's mouse lemur (\"M. lehilahytsara\") were considered the same species until recently, when genetic tests identified them as cryptic species.\nDentition.\nThe lemur dentition is heterodont (having multiple tooth morphologies) and derives from an ancestral primate permanent dentition of . Indriids, sportive lemurs, the aye-aye, and the extinct sloth lemurs, monkey lemurs, and koala lemurs have reduced dentitions, having lost incisors, canines, or premolars. The ancestral deciduous dentition is , but young indriids, aye-ayes, koala lemurs, sloth lemurs, and probably monkey lemurs have fewer deciduous teeth.\nThere are also noticeable differences in dental morphology and tooth topography between lemurs. Indri, for instance, have teeth that are perfectly adapted for shearing leaves and crushing seeds. In the toothcomb of most lemurs, the bottom incisors and canine teeth are procumbent (face forward rather than up) and finely spaced, thus providing a tool for either grooming or feeding. For instance, indri use their toothcomb not only for grooming, but also to pry out the large seeds from the tough epicarp of \"Beilschmiedia\" fruits, while fork-marked lemurs use their relatively long toothcomb to cut through tree bark to induce the flow of tree sap. The toothcomb is kept clean by the sublingua or \"under-tongue\", a specialized structure that acts like a toothbrush to remove hair and other debris. The sublingua extends below the tip of the tongue and is tipped with keratinized, serrated points that rake between the front teeth.\nOnly the aye-aye, the extinct giant aye-aye, and the largest of the extinct giant sloth lemurs lack a functional strepsirrhine toothcomb. In the case of the aye-aye, the morphology of the deciduous incisors, which are lost shortly after birth, indicates that its ancestors had a toothcomb. These milk teeth are lost shortly after birth and are replaced by open-rooted, continually growing (hypselodont) incisors.\nThe toothcomb in lemurs normally consists of six teeth (four incisors and two canines), although indriids, monkey lemurs, and some sloth lemurs only have a four-tooth toothcomb due to the loss of either a canine or an incisor. Because the lower canine is either included in the toothcomb or lost, the lower dentition can be difficult to read, especially since the first premolar (P2) is often shaped like a canine (caniniform) to fill the canine's role. In folivorous (leaf-eating) lemurs, except for indriids, the upper incisors are greatly reduced or absent. Used together with the toothcomb on the mandible (lower jaw), this complex is reminiscent of an ungulate browsing pad.\nLemurs are unusual among primates for their rapid dental development, particularly among the largest species. For example, indriids have relatively slow body growth but extremely fast tooth formation and eruption. By contrast, anthropoid primates exhibit slower dental development with increased size and slower morphological development. Lemurs are also dentally precocious at birth, and have their full permanent dentition at weaning.\nLemurs generally have thin tooth enamel compared to anthropoid primates. This may result in extra wear and breakage to the anterior (front) teeth due to heavy use in grooming, feeding, and fighting. Little other dental health information is available for lemurs, except that wild ring-tailed lemurs at Berenty Private Reserve occasionally exhibit abscessed maxillary canines (seen as open wounds on the muzzle) and tooth decay, possibly due to the consumption of non-native foods.\nSenses.\nThe sense of smell, or olfaction, is highly important to lemurs and is frequently used in communication. Lemurs have long snouts (compared to the short snouts of haplorrhines) that are traditionally thought to position the nose for better sifting of smells, although long snouts do not necessarily translate into high olfactory acuity since it is not the relative size of the nasal cavity that correlates with smell, but the density of olfactory receptors. Instead, the long snouts may facilitate better chewing.\nThe wet nose, or rhinarium, is a trait shared with other strepsirrhines and many other mammals, but not with haplorrhine primates. Although it is claimed to enhance the sense of smell, it is actually a touch-based sense organ that connects with a well-developed vomeronasal organ (VNO). Since pheromones are usually large, non-volatile molecules, the rhinarium is used to touch a scent-marked object and transfer the pheromone molecules down the philtrum (the nasal mid-line cleft) to the VNO via the nasopalatine ducts that travel through the incisive foramen of the hard palate.\nTo communicate with smell, which is useful at night, lemurs will scent mark with urine as well as scent glands located on the wrists, inside elbow, genital regions, or the neck. The scrotal skin of most male lemurs has scent glands. Ruffed lemurs (genus \"Varecia\") and male sifakas have a gland at the base of their neck, while the greater bamboo lemur (\"Prolemur simus\") and the ring-tailed lemur have glands inside the upper arms near the axilla. Male ring-tailed lemurs also have scent glands on the inside of their forearms, adjacent to a thorn-like spur, which they use to gouge, and simultaneously, scent-mark tree branches. They will also wipe their tails between their forearms and then engage in \"stink fights\" by waving their tail at their opponents.\nLemurs (and strepsirrhines in general) are considered to be less visually oriented than the higher primates, since they rely so heavily on their sense of smell and pheromone detection. The fovea on the retina, which yields higher visual acuity, is not well-developed. The postorbital septum (or bony closure behind the eye) in haplorrhine primates is thought to stabilize the eye slightly, allowing for the evolution of the fovea. With only a postorbital bar, lemurs have been unable to develop a fovea. Therefore, regardless of their activity pattern (nocturnal, cathemeral, or diurnal), lemurs exhibit low visual acuity and high retinal summation. Lemurs can see a wider visual field, however, than anthropoid primates due to a slight difference in the angle between the eyes, as shown in the following table:\nAlthough they lack a fovea, some diurnal lemurs have a cone-rich, although less clustered, area centralis. This area centralis has a high rod-to-cone cell ratio in many diurnal species studied thus far, whereas diurnal anthropoids have no rod cells in their fovea. Once again, this suggests lower visual acuity in lemurs than in anthropoids. Furthermore, the rod-to-cone cell ratio can be variable even among diurnal species. For instance, Verreaux's sifaka (\"Propithecus verreauxi\") and the indri (\"Indri indri\") have only a few large cones scattered along their predominantly rod-dominated retina. The eyes of the ring-tailed lemur contain one cone to five rods. Nocturnal lemurs such as mouse lemurs and dwarf lemurs, on the other hand, have retinas made up entirely of rod cells.\nSince cone cells make color vision possible, the high prevalence of rod cells in lemur eyes suggest they have not evolved color vision. The most studied lemur, the ring-tailed lemur, has been shown to have blue-yellow vision, but lacks the ability to distinguish red and green hues. Due to polymorphism in opsin genes, which code for color receptivity, trichromatic vision may rarely occur in females of a few lemur species, such as Coquerel's sifaka (\"Propithecus coquereli\") and the red ruffed lemur (\"Varecia rubra\"). Most lemurs, therefore, are either monochromats or dichromats.\nMost lemurs have retained the tapetum lucidum, a reflective layer of tissue in the eye, which is found in many vertebrates. This trait is absent in haplorrhine primates, and its presence further limits the visual acuity in lemurs. The strepsirrhine choroidal tapetum is unique among mammals because it is made up of crystalline riboflavin, and the resulting optical scattering is what limits visual acuity. Although the tapetum is considered to be ubiquitous in lemurs, there appear to be exceptions among true lemurs, such as the black lemur and the common brown lemur, as well as the ruffed lemurs. Since the riboflavins in the tapetum have a tendency to dissolve and vanish when processed for histological investigation, however, the exceptions are still debatable.\nLemurs also have a third eyelid known as a nictitating membrane, whereas most other primates have a lesser developed plica semilunaris. The nictitating membrane keeps the cornea moist and clean by sweeping across the eye.\nMetabolism.\nLemurs have low basal metabolic rates (BMR), which helps them to conserve energy during the dry season, when water and food are scarce. They can optimize their energy use by lowering their metabolic rate to 20% below the values predicted for mammals of similar body mass. The red-tailed sportive lemur (\"Lepilemur ruficaudatus\"), for instance, reportedly has one of the lowest metabolic rates among mammals. Its low metabolic rate may be linked to its generally folivorous diet and relatively small body mass. Lemurs exhibit behavioral adaptations to complement this trait, including sunning behaviors, hunched sitting, group huddling, and nest sharing, in order to reduce heat loss and conserve energy. Dwarf lemurs and mouse lemurs exhibit seasonal cycles of dormancy to conserve energy. Before dry season, they will accumulate fat in white adipose tissue located at the base of the tail and hind legs, doubling their weight. At the end of the dry season, their body mass may fall to half of what it was prior to the dry season. Lemurs that do not experience states of dormancy are also able to shut down aspects of their metabolism for energy conservation.\nBehaviour.\nLemur behaviour is as variable as lemur morphology. Differences in diet, social systems, activity patterns, locomotion, communication, predator avoidance tactics, breeding systems, and intelligence levels help define lemur taxa and set individual species apart from the rest. Although trends frequently distinguish the smaller, nocturnal lemurs from the larger, diurnal lemurs, there are often exceptions that help exemplify the unique and diverse nature of these Malagasy primates.\nDiet.\nLemur diets are highly variable and demonstrate a high degree of plasticity, although general trends suggest that the smallest species primarily consume fruit and insects (omnivory), while the larger species are more herbivorous, consuming mostly plant material. As with all primates, hungry lemurs might eat anything that is edible, whether or not the item is one of their preferred foods. For instance, the ring-tailed lemur eats insects and small vertebrates when necessary and as a result it is commonly viewed as an opportunistic omnivore. Coquerel's giant mouse lemur (\"Mirza coquereli\") is mostly frugivorous, but will consume insect secretions during the dry season.\nA common assumption in mammalogy is that small mammals cannot subsist entirely on plant material and must have a high-calorie diet in order to survive. As a result, it was thought that the diet of tiny primates must be high in protein-containing insects (insectivory). Research has shown, however, that mouse lemurs, the smallest living primates, consume more fruit than insects, contradicting the popular hypothesis.\nPlant material makes up the majority of most lemur diets. Members of at least 109 of all known plant families in Madagascar (55%) are exploited by lemurs. Since lemurs are primarily arboreal, most of these exploited species are woody plants, including trees, shrubs, or lianas. Only the ring-tailed lemur, the bamboo lemurs (genus \"Hapalemur\"), and the black-and-white ruffed lemur (\"Varecia variegata\") are known to consume herbs. While Madagascar is rich in fern diversity, these plants are rarely eaten by lemurs. One possible reason for this is that ferns lack flowers, fruits, and seeds\u2014common food items in lemur diets. They also occur close to the ground, while lemurs spend most of their time in the trees. Lastly, ferns have an unpleasant taste due to the high content of tannins in their fronds. Likewise, mangroves appear to be rarely exploited by lemurs due to their high tannin content. Some lemurs appear to have evolved responses against common plant defenses, however, such as tannins and alkaloids. The golden bamboo lemur (\"Hapalemur aureus\"), for instance, eats giant bamboo (\"Cathariostachys madagascariensis\"), which contains high levels of cyanide. This lemur can consume twelve times the typically lethal dose for most mammals on a daily basis; the physiological mechanisms that protect it from cyanide poisoning are unknown. At the Duke Lemur Center (DLC) in the United States, lemurs that roam the outdoor enclosures have been observed eating poison ivy (\"Taxicodendron radicans\"), yet have shown no ill effects.\nMany of the larger lemur species consume leaves (folivory), particularly the indriids. However, some smaller lemurs such as sportive lemurs (genus \"Lepilemur\") and woolly lemurs (genus \"Avahi\") also primarily eat leaves, making them the smallest primates that do so. The smallest of the lemurs generally do not eat much leaf matter. Collectively, lemurs have been documented consuming leaves from at least 82 native plant families and 15 alien plant families. Lemurs tend to be selective in their consumption of the part of the leaf or shoot as well as its age. Often, young leaves are preferred over mature leaves.\nMany lemurs that eat leaves tend to do so during times of fruit scarcity, sometimes suffering weight loss as a result. Most lemur species, including most of the smallest lemurs and excluding some of the indriids, predominantly eat fruit (frugivory) when available. Collectively, lemurs have been documented consuming fruit from at least 86\u00a0native plant families and 15\u00a0alien plant families. As with most tropical fruit eaters, the lemur diet is dominated by fruit from \"Ficus\" (fig) species. In many anthropoid primates, fruit is a primary source of vitamin C, but unlike anthropoid primates, lemurs (and all strepsirrhines) can synthesize their own vitamin C. Historically, captive lemur diets high in vitamin C-rich fruits have been thought to cause hemosiderosis, a type of iron overload disorder, since vitamin C increases iron absorption. Although lemurs in captivity have been shown to be prone to hemosiderosis, the frequency of the disease varies across institutions and may depend on the diet, husbandry protocols, and genetic stock. Assumptions about the problem need to be tested separately for each species. The ring-tailed lemur, for instance, seems to be less prone to the disorder than other lemur species.\nOnly eight species of lemur are known to be seed predators (granivores), but this may be under-reported since most observations only report fruit consumption and do not investigate whether the seeds are consumed as well. These lemurs include some indriids, such as the diademed sifaka (\"Propithecus diadema\"), the golden-crowned sifaka (\"Propithecus tattersalli\"), the indri, and the aye-aye. The aye-aye, which specializes in structurally defended resources, can chew through \"Canarium\" seeds, which are harder than the seeds that New World monkeys are known to break open. At least 36\u00a0genera from 23\u00a0families of plants are targeted by lemur seed predators.\nInflorescences (clusters of flowers) of at least 60\u00a0plant families are eaten by lemurs ranging in size from the tiny mouse lemurs to the relatively large ruffed lemurs. If the flowers are not exploited, sometimes the nectar is consumed (nectarivory) along with the pollen (palynivory). At least 24\u00a0native species from 17\u00a0plant families are targeted for nectar or pollen consumption.\nBark and plant exudates such as tree sap are consumed by a few lemur species. The exploitation of exudates has been reported in 18 plant species and only in the dry regions in the south and west of Madagascar. Only the Masoala fork-marked lemur (\"Phaner furcifer\") and Coquerel's giant mouse lemur regularly consume tree sap. Bark has never been reported as an important food item in lemur diets, but at least four species eat it: the aye-aye, the red-tailed sportive lemur (\"Lepilemur ruficaudatus\"), the common brown lemur (\"Eulemur fulvus\"), and Verreaux's sifaka (\"Propithecus verreauxi\"). Most bark feeding is directly linked to exudate feeding, except for the aye-aye's bark feeding on \"Afzelia bijuga\" (genus \"Afzelia\") at Nosy Mangabe in the northeast.\nSoil consumption (geophagy) has also been reported and likely helps with digestion, provides minerals and salts, and helps absorb toxins. Sifakas have been observed eating soil from termite mounds, possibly adding beneficial intestinal flora to aid the digestion of cellulose from their folivorous diet.\nSocial systems.\nLemurs are social and live in groups that usually include fewer than 15\u00a0individuals. Observed social organization patterns include \"solitary but social\", \"fission-fusion\", \"pair bonds\", and \"multi-male group\". Nocturnal lemurs are mostly solitary but social, foraging alone at night but often nesting in groups during the day. The degree of socialization varies by species, gender, location, and season. In many nocturnal species, for instance, the females, along with their young, will share nests with other females and possibly one male, whose larger home range happens to overlap one or more female nesting groups. In sportive lemurs and fork-marked lemurs, one or two females may share a home range, possibly with a male. In addition to sharing nests, they will also interact vocally or physically with their range-mate while they forage at night. Diurnal lemurs exhibit many of the social systems seen in monkeys and apes, living in relatively permanent and cohesive social groups. Multi-male groups are the most common, just as they are in most anthropoid primates. True lemurs utilize this social system, often living in groups of ten or less. Ruffed lemurs have been shown to live in fission-fusion societies, and Indri forms pair bonds.\nSome lemurs exhibit female philopatry, where females stay within their natal range and the males migrate upon reaching maturity, and in other species both sexes will migrate. In some cases, female philopatry may help explain the evolution of female-bonded multi-male groups, such as those of the ring-tailed lemur, Milne-Edwards' sifaka (\"Propithecus edwardsi\"), and the Verreaux's sifaka. Their ancestors may have been more solitary, with females that lived in mother-daughter pairs (or dyads). Over time, these dyads may have allied themselves with other neighboring mother-daughter dyads in order to defend more distributed resources in a wide home range. If this is true, then multi-male groups in lemurs may differ fundamentally in their internal structure from those in catarrhine primates (Old World monkeys and apes).\nThe presence of female social dominance sets lemurs apart from most other primates and mammals; in most primate societies, males are dominant unless females band together to form coalitions that displace them. However, many \"Eulemur\" species are exceptions and the greater bamboo lemur (\"Prolemur simus\") does not exhibit female dominance. When females are dominant within a group, the way they maintain dominance varies. Ring-tailed lemur males act submissively with or without signs of female aggression. Male crowned lemurs (\"Eulemur coronatus\"), on the other hand, will only act submissively when females act aggressively towards them. Female aggression is often associated with, but not limited to, feeding.\nThere have been many hypotheses that have attempted to explain why lemurs exhibit female social dominance while other primates with similar social structures do not, but no consensus has been reached after decades of research. The dominant view in the literature states that female dominance is an advantageous trait given the high costs of reproduction and the scarcity of resources available. Indeed, female dominance has been shown to be linked to increased maternal investment. However, when reproductive costs and extreme seasonality of resources were compared across primates, other primates demonstrated male dominance under conditions that were similar to or more challenging than those faced by lemurs. In 2008, a new hypothesis revised this model using simple game theory. It was argued that when two individuals were equally matched in fighting capacity, the one with the most need would win the conflict since it would have the most to lose. Consequently, the female, with higher resource needs for pregnancy, lactation, and maternal care, was more likely to win in resource conflicts with equally sized males. This, however, assumed monomorphism between sexes. The following year, a new hypothesis was proposed to explain monomorphism, stating that because most female lemurs are only sexually receptive for a day or two each year, males can utilize a more passive form of mate guarding: copulatory plugs, which block the female reproductive tract, preventing other males from successfully mating with her, and thus reducing the need for aggression and the evolutionary drive for sexual dimorphism.\nIn general, levels of agonism (or aggression) tend to correlate with relative canine height. The ring-tailed lemur has long, sharp upper canine teeth in both sexes, and it also exhibits high levels of agonism. The Indri, on the other hand, has smaller canines and exhibits lower levels of aggression. When neighboring groups of the same species defend their territories, the conflict can take the form of ritualized defense. In sifakas, these ritualized combats involve staring, growling, scent-marking, and leaping to occupy certain sections of the tree. The indri defends its home range with ritualized \"singing\" battles.\nLike other primates, lemurs groom socially (allogroom) to ease tensions and solidify relationships. They groom in greeting, when waking up, when settling in for sleep, between mother and infant, in juvenile relations, and for sexual advances. Unlike anthropoid primates, who part the fur with the hands and pick out particles with the fingers or mouth, lemurs groom with their tongue and scraping with their toothcomb. Despite the differences in technique, lemurs groom with the same frequency and for the same reasons as anthropoids.\nActivity patterns.\nThe biological rhythm can vary from nocturnal in smaller lemurs to diurnal in most larger lemurs. Diurnality is not seen in any other living strepsirrhine. Cathemerality, where an animal is active sporadically both day and night, occurs among some of the larger lemurs. Few if any other primates exhibit this sort of activity cycle, either regularly or irregularly under changing environmental conditions. The most heavily studied cathemeral lemurs are the true lemurs. Although the mongoose lemur (\"E. mongoz\") is the best-documented example, every species in the genus studied has shown some degree of cathemeral behavior, although night activity is often restricted by light availability and moon periodicity. This type of behavior was first documented in the 1960s in true lemur species as well as other Lemuridae species, such as ruffed lemurs and bamboo lemurs. Initially described as \"crepuscular\" (active at dawn and dusk), anthropologist Ian Tattersall stimulated additional research and coined the new term \"cathemeral\", although many non-anthropologists prefer the terms \"circadian\" or \"diel\".\nIn order to conserve energy and water in their highly seasonal environment, mouse lemurs and dwarf lemurs exhibit seasonal behavioral cycles of dormancy where the metabolic rate and body temperature are lowered. They are the only primates known to do so. They accumulate fat reserves in their hind legs and the base of their tail before the dry winter season, when food and water are scarce, and can exhibit daily and prolonged torpor during the dry season. Daily torpor constitutes less than 24 hours of dormancy, whereas prolonged torpor averages two weeks in duration and signals hibernation. Mouse lemurs have been observed experiencing torpor that lasts for several consecutive days, but dwarf lemurs are known to hibernate for six to eight months every year, particularly on the west coast of Madagascar.\nDwarf lemurs are the only primates known to hibernate for extended periods. Unlike other hibernating mammals from temperate regions, which have to awaken regularly for a few days, dwarf lemurs experience five months of continuous deep hibernation (May through September). Before and after this deep hibernation, there are two months (April and October) of transition, where they will forage on a limited basis to reduce demands on their fat reserves. Unlike any other hibernating mammal, the body temperature of hibernating dwarf lemurs will fluctuate with the ambient temperature rather than remaining low and stable.\nOther lemurs that do not exhibit dormancy conserve energy by selecting thermoregulated microhabitats (such as tree holes), sharing nests, and reducing exposed body surfaces, such as by hunched sitting and group huddling. Also, the ring-tailed lemur, ruffed lemurs, and sifakas are commonly seen sunning, thus using solar radiation to warm their bodies instead of metabolic heat.\nLocomotion.\nLocomotor behavior in lemurs, both living and extinct, is highly varied and its diversity exceeds that of anthropoids. Locomotor postures and behaviors have included vertical clinging and leaping (including saltatory behavior), seen in indriids and bamboo lemurs; slow (loris-like) arboreal quadrupedal locomotion, once exhibited by \"Mesopropithecus\"; fast arboreal quadrupedal locomotion, seen in true lemurs and ruffed lemurs; partially terrestrial quadrupedal locomotion, seen in the ring-tailed lemur; highly terrestrial quadrupedal locomotion, once exhibited by monkey lemurs such as \"Hadropithecus\"; and sloth-like suspensory locomotion, once exhibited by many of the sloth lemurs, such as \"Palaeopropithecus\". The Lac Alaotra gentle lemur (\"Hapalemur alaotrensis\") has even been reported to be a good swimmer. Sometimes these locomotor types are lumped together into two main groups of lemurs, the vertical clingers and leapers and the arboreal (and occasionally terrestrial) quadrupeds.\nThe jumping prowess of the indriids has been well documented and is popular among ecotourists visiting Madagascar. Using their long, powerful back legs, they catapult themselves into the air and land in an upright posture on a nearby tree, with both hands and feet tightly gripping the trunk. Indriids can leap up to 10\u00a0m (33\u00a0ft) rapidly from tree trunk to tree trunk, an ability referred to as \"ricochetal leaping\". Verreaux's sifaka (\"Propithecus verreauxi\") manages to do this in the spiny forests of southern Madagascar. It is unknown how it avoids impaling its palms on the thorn-covered trunks of large plants such as \"Alluaudia\". When distances between trees are too great, sifakas will descend to the ground and cross distances more than 100\u00a0m (330\u00a0ft) by standing upright and hopping sideways with the arms held to the side and waving up and down from chest to head height, presumably for balance. This is sometimes described as a \"dance-hop\".\nCommunication.\nLemur communication can be transmitted through sound, sight, and smell (olfaction). The ring-tailed lemur, for instance, uses complex though highly stereotyped behaviors such as scent-marking and vocalizations. Visual signals are probably the least used by lemurs, since they lack many of the muscles used in common primate facial expressions. Given their poor vision, whole-body postures are probably more noticeable. However, the ring-tailed lemur has demonstrated distinct facial expressions including a threat stare, pulled back lips for submission, and pulled back ears along with flared nostrils during scent-marking. This species has also been observed using yawns as threats. Their ringed tails also communicate distance, warn off neighboring troops, and help locate troop members. Sifakas are known to exhibit an open-mouth play face as well as a submissive teeth-baring grimace used in agonistic interactions.\nOlfaction is particularly important to lemurs, except for the indri, which lacks most common lemur scent glands and has a greatly reduced olfactory region in the brain. Olfaction can communicate information about age, sex, reproductive status, as well as demarcate the boundaries of a territory. It is most useful for communication between animals that rarely encounter each other. Small, nocturnal lemurs mark their territories with urine, while the larger, diurnal species use scent glands located on various parts of their anatomy. The ring-tailed lemur engages in \"stink fights\" by rubbing its tail across scent glands on its wrists, and then flicking its tail at other male opponents. Some lemurs defecate in specific areas, otherwise known as latrine behavior. Although many animals exhibit this behavior, it is a rare trait among primates. Latrine behavior can represent territorial marking and aid in interspecies signaling.\nCompared to other mammals, primates in general are very vocal, and lemurs are no exception. Some lemur species have extensive vocal repertoires, including the ring-tailed lemur and ruffed lemurs. Some of the most common calls among lemurs are predator alarm calls. Lemurs not only respond to alarm calls of their own species, but also alarm calls of other species and those of non-predatory birds. The ring-tailed lemur and a few other species have different calls and reactions to specific types of predators. With mating calls, it has been shown that mouse lemurs that cannot be discerned visually respond more strongly to the calls of their own species, particularly when exposed to the calls of other mouse lemurs that they would encounter normally within their home range. Lemur calls can also be very loud and carry long distances. Ruffed lemurs use several loud calls that can be heard up to 1\u00a0km (0.62\u00a0mi) away on a clear, calm day. The loudest lemur is the indri, whose calls can be heard up to 2\u00a0km (1.2\u00a0mi) or more and thus communicate more effectively the territorial boundaries over its 34 to 40\u00a0hectares (0.13 to 0.15\u00a0sq mi) home range. Both ruffed lemurs and the indri exhibit contagious calling, where one individual or group starts a loud call and others within the area join in. The song of the indri can last 45\u00a0seconds to more than 3\u00a0minutes and tends to coordinate to form a stable duet comparable to that of gibbons.\nTactile communication (touch) is mostly used by lemurs in the form of grooming, although the ring-tailed lemur also clumps together to sleep (in an order determined by rank), reaches out and touches adjacent members, and cuffs other members. Reaching out and touching another individual in this species has been shown to be a submissive behavior, done by younger or submissive animals towards older and more dominant members of the troop. Allogrooming, however, appears to occur more frequently between higher ranking individuals, a shared trait with other primate species. Unlike anthropoid primates, lemur grooming seems to be more intimate and mutual, often directly reciprocated. Anthropoids, on the other hand, use allogrooming to manage agonistic interactions. The ring-tailed lemur is known to be very tactile, spending between 5 and 11% of its time grooming.\nPredator avoidance.\nAll lemurs experience some predation pressure. Common defenses against predation include the use of alarm calls and predator mobbing, mostly among diurnal lemurs. The leaping abilities of lemurs may have evolved for predator avoidance rather than for travel, according to a study in kinematics. Nocturnal lemurs are difficult to see and track at night and decrease their visibility by foraging alone. They also try to avoid predators by using concealing sleeping locations, such as nests, tree holes, or dense vegetation, Some may also avoid areas frequented by predators by detecting the smell of their feces and alternating between multiple sleeping locations. Even torpor and hibernation states among cheirogaleids may be partly due to high levels of predation. Infants are protected while foraging by either leaving them in the nest or by stashing them in a hidden location, where the infant remains immobile in the absence of the parent.\nDiurnal lemurs are visible during the day, so many live in groups, where the increased number of eyes and ears helps aid in predator detection. Diurnal lemurs use and respond to alarm calls, even those of other lemur species and non-predatory birds. The ring-tailed lemur has different calls and reactions to different classes of predators, such as predatory birds, mammals, or snakes. Some lemurs, such as the indri, use crypsis to camouflage themselves. They are often heard but difficult to see in the trees due to the dappled light, earning them the reputation of being \"ghosts of the forest\".\nReproduction.\nExcept for the aye-aye and the Lac Alaotra gentle lemur, lemurs are seasonal breeders with very short mating and birth seasons influenced by the highly seasonal availability of resources in their environment. Mating season usually last less than three weeks each year, and the female vagina opens up only during a few hours or days of her most receptive time of estrus. These narrow windows for reproduction and resource availability appear to relate to their short gestation periods, rapid maturation, and low basal metabolic rates, as well as the high energy costs of reproduction for females. This may also relate to the relatively high mortality rate among adult females and the higher proportion of adult males in some lemur populations\u2014both unusual traits among primates. In both the aye-aye and Lac Alaotra gentle lemur, birth (parturition) occurs over a six-month period.\nLemurs time their mating and birth seasons so that all weaning periods are synchronized to match the time of highest food availability. Weaning occurs either before or shortly after the eruption of the first permanent molars in lemurs. Mouse lemurs are able to fit their entire breeding cycle into the wet season, whereas larger lemurs, such as sifakas, must lactate for two months during the dry season. Infant survival in some species, such as Milne-Edwards' sifaka, has been shown to be directly impacted by both environmental conditions and the rank, age, and health of the mother. The breeding season is also affected by geographical location. For example, mouse lemurs give birth between September and October in their native habitat in the Southern Hemisphere, but from May through June in the captive settings in the Northern Hemisphere.\nScent factors heavily into lemur reproduction. Scent-marking activity escalates during the mating season. Pheromones may coordinate reproductive timing for females coming into estrus. Mating can be either monogamous or promiscuous for both males and females, and mating can include individuals from outside the group. Monogamous lemurs include the red-bellied lemur (\"Eulemur rubriventer\") and the mongoose lemur (\"E. mongoz\"), although the mongoose lemur has been observed mating outside of its pair bond. Monogamy is most common among nocturnal species, although some exhibit scramble competition, sexual suppression of subordinates, or competitions between males that avoid direct fighting. In mouse lemurs, males utilize sperm plugs, developed enlarged testes during the mating season, and develop size dimorphism (likely due to the enlarged testes). These indicate a mating system known as scramble competition polygyny, where males cannot defend females or the resources that might attract them.\nThe gestation period varies within lemurs, ranging from 9 weeks in mouse lemurs and 9\u201310\u00a0weeks in dwarf lemurs to 18\u201324\u00a0weeks in other lemurs. The smaller, nocturnal lemurs, such as mouse lemurs, giant mouse lemurs, and dwarf lemurs, usually give birth to more than one infant, whereas the larger, nocturnal lemurs, such as fork-marked lemurs, sportive lemurs, and the aye-aye usually have one offspring. Dwarf and mouse lemurs have up to four offspring, but both average only two. Ruffed lemurs are the only large, diurnal lemurs to consistently give birth to two or three offspring. All other lemurs have single births. Multiple births in lemurs are normally fraternal, and are known to occur in every five to six births in species such as the ring-tailed lemur and some \"Eulemur\".\nAfter the offspring are born, lemurs either carry them around or stash them while foraging. When transported, the infants either cling to the mother's fur or are carried in the mouth by the scruff. In some species, such as bamboo lemurs, infants are carried by mouth until they are able to cling to their mother's fur. Species that park their offspring include nocturnal species (e.g. mouse lemurs, sportive lemurs, and dwarf lemurs), bamboo lemurs, and ruffed lemurs. In the case of the ruffed lemurs, the young are altricial and the mothers build nests for them, much like the smaller, nocturnal lemur species. Woolly lemurs are unusual for nocturnal lemurs because they live in cohesive family groups and carry their single offspring with them rather than parking them. Alloparenting (multiple or group parenting) has been reported in all lemur families except the sportive lemurs and aye-aye. Allonursing is also known to occur in several lemur groups. Even males have been observed caring for infants in species such as the red-bellied lemur, mongoose lemur, eastern lesser bamboo lemur, silky sifaka, fat-tailed dwarf lemur, and ruffed lemurs.\nYet another trait that sets most lemurs apart from anthropoid primates is their long lifespan together with their high infant mortality. Many lemurs, including the ring-tailed lemur, have adapted to a highly seasonal environment, which has affected their birthrate, maturation, and twinning rate (r-selection). This helps them to recover rapidly from a population crash. In captivity, lemurs can live twice as long as they do in the wild, benefiting from consistent nutrition that meets their dietary requirements, medical advancements, and improved understanding of their housing requirements. In 1960, it was thought that lemurs could live between 23 and 25 years. We now know that the larger species can live for more than 30 years without showing signs of aging (senescence) and still be capable of reproduction.\nCognitive abilities and tool use.\nLemurs have traditionally been regarded as being less intelligent than anthropoid primates, with monkeys and apes often described as having more cunning, guile, and deceptiveness. Many lemur species, such as sifakas and the ring-tailed lemur, have scored lower on tests designed for monkeys while performing as well as monkeys on other tests. These comparisons may not be fair since lemurs prefer to manipulate objects with their mouths (rather than their hands) and only take interest in objects when in captivity. Recent studies have shown that lemurs exhibit levels of technical intelligence on par with many other primates, although they manipulate objects less often. Tool use has not been witnessed by lemurs in the wild, although in captivity the common brown lemur and the ring-tailed lemur have been demonstrated to be able to understand and use tools.\nA few lemurs have been noted to have relatively large brains. The extinct \"Hadropithecus\" was as large as a large male baboon and had a comparably sized brain, giving it the largest brain size relative to body size among all prosimians. The aye-aye also has a large brain-to-body ratio, which may indicate a higher level of intelligence. However, despite having a built-in tool in the form of its thin, elongated middle finger, which it uses to fish for insect grubs, the aye-aye has tested poorly in the use of extraneous tools.\nEcology.\nMadagascar not only contains two radically different climatic zones, the rainforests of the east and the dry regions of the west, but also swings from extended drought to cyclone-generated floods. These climatic and geographical challenges, along with poor soils, low plant productivity, wide ranges of ecosystem complexity, and a lack of regularly fruiting trees (such as fig trees) have driven the evolution of lemurs' immense morphological and behavioral diversity. Their survival has required the ability to endure the persistent extremes, not yearly averages.\nLemurs have either presently or formerly filled the ecological niches normally occupied by monkeys, squirrels, woodpeckers, and grazing ungulates. With the diversity of adaptations for specific ecological niches, habitat selection among lemur families and some genera is often very specific, thus minimizing competition. In nocturnal lemurs from the more seasonal forests in the west, up to five species can coexist during the wet season due to high food abundance. However, to endure the extreme dry season, three of the five species utilize different dietary patterns and their underlying physiological traits to allow them to coexist: fork-marked lemurs feed on tree gum, sportive lemurs feed on leaves, and giant mouse lemurs sometimes feed on insect secretions. The other two species, the gray mouse lemur and the fat-tailed dwarf lemur (\"Cheirogaleus medius\"), avoid competition through reduced activity. The gray mouse lemur uses bouts of torpor, while the fat-tailed dwarf lemur hibernates completely. Similarly, on the east coast entire genera focus on specific food to avoid too much niche overlap. True lemurs and ruffed lemurs are frugivorous, indriids are folivorous, and bamboo lemurs specialize in bamboo and other grasses. Once again, seasonal dietary differences as well as subtle differences in substrate preferences, forest strata used, activity cycle, and social organization enable lemur species to coexist, although this time the species are more closely related and have similar niches. A classic example involves resource partitioning between three species of bamboo lemur that live in close proximity in small forested areas: the golden bamboo lemur, the greater bamboo lemur, and the eastern lesser bamboo lemur (\"Hapalemur griseus\"). Each utilizes either different species of bamboo, different parts of the plant, or different layers in the forest. Nutrient and toxin content (such as cyanide) help regulate food selection, though seasonal food preferences are also known to play a role.\nDietary regimes of lemurs include folivory, frugivory, and omnivory, with some being highly adaptable while others specialize on foods such as plant exudates (tree gum) and bamboo. In some cases, lemur feeding patterns directly benefit the native plant life. When lemurs exploit nectar, they may act as pollinators as long as the functional parts of the flower are not damaged. In fact, several unrelated Malagasy flowering plants demonstrate lemur-specific pollination traits, and studies indicate that some diurnal species, such as the red-bellied lemur and the ruffed lemurs, act as major pollinators. Two examples of plant species that rely on lemurs for pollination include traveller's palm (\"Ravenala madagascariensis\") and a species of legume-like liana, \"Strongylodon cravieniae\". Seed dispersal is another service lemurs provide. After passing through the lemur gut, tree and vine seeds exhibit lower mortality and germinate faster. Latrine behavior exhibited by some lemurs may help improve soil quality and facilitate seed dispersal. Because of their importance in maintaining a healthy forest, frugivorous lemurs may qualify as keystone mutualists.\nAll lemurs, particularly the smaller species, are affected by predation and they are important prey items for predators. Humans are the most significant predator of diurnal lemurs, despite taboos that occasionally forbid the hunting and eating of certain lemur species. Other predators include native euplerids, such as the fossa, feral cats, domestic dogs, snakes, diurnal birds of prey, and crocodiles. Extinct giant eagles, including one or two species from the genus \"Aquila\" and the giant Malagasy crowned eagle (\"Stephanoaetus mahery\"), as well as the giant fossa (\"Cryptoprocta spelea\"), previously also preyed on lemurs, perhaps including the giant subfossil lemurs or their subadult offspring. The existence of these extinct giants suggests that predator-prey interactions involving lemurs were more complex than they are today. Today, predator size restricts owls to the smaller lemurs, usually 100\u00a0g (3.5\u00a0oz) or less, while the larger lemurs fall victim to the larger diurnal birds of prey, such as the Madagascar harrier-hawk (\"Polyboroides radiatus\") and the Madagascar buzzard (\"Buteo brachypterus\").\nResearch.\nSimilarities that lemurs share with anthropoid primates, such as diet and social organization, along with their own unique traits, have made lemurs the most heavily studied of all mammal groups on Madagascar. Research often focuses on the link between ecology and social organization, but also on their behavior and morphophysiology (the study of anatomy in relation to function). Studies of their life-history traits, behavior and ecology help understanding of primate evolution, since they are thought to share similarities with ancestral primates.\nLemurs have been the focus of monographic series, action plans, field guides, and classic works in ethology. However, few species have been thoroughly studied to date, and most research has been preliminary and restricted to a single locality. Only recently have numerous scientific papers been published to explain the basic aspects of behavior and ecology of poorly known species. Field studies have given insights on population dynamics and evolutionary ecology of most genera and many species. Long-term research focused on identified individuals is in its infancy and has only been started for a few populations. However, learning opportunities are dwindling as habitat destruction and other factors threaten the existence of lemur populations across the island.\nLemurs are mentioned in sailors' voyage logs as far back as 1608 and in 1658 that at least seven lemur species were described in detail by the French merchant, \u00c9tienne de Flacourt, who may also have been the only westerner to see and chronicle the existence of a giant (now extinct) lemur, which he called the \"tretretretre\". Around 1703 merchants and sailors began bringing lemurs back to Europe, at which time James Petiver, an apothecary in London, described and illustrated the mongoose lemur. Starting in 1751, the London illustrator George Edwards began describing and illustrating some lemur species, of which a few were included in various editions of \"Systema Naturae\" by Carl Linnaeus. In the 1760s and 1770s, French naturalists Georges-Louis Leclerc, Comte de Buffon and Louis-Jean-Marie Daubenton began describing the anatomy of several lemur species. The first traveling naturalist to comment on lemurs was Philibert Commer\u00e7on in 1771, although it was Pierre Sonnerat who recorded a greater variety of lemur species during his travels.\nDuring the 19th century, there was an explosion of new lemur descriptions and names, which later took decades to sort out. During this time, professional collectors gathered specimens for museums, menageries, and cabinets. Some of the major collectors were Johann Maria Hildebrandt and Charles Immanuel Forsyth Major. From these collections, as well as increasing observations of lemurs in their natural habitats, museum systematists including Albert G\u00fcnther and John Edward Gray continued to contribute new names for new lemur species. However, the most notable contributions from this century includes the work of Alfred Grandidier, a naturalist and explorer who devoted himself to the study of Madagascar's natural history and local people. With the help of Alphonse Milne-Edwards, most of the diurnal lemurs were illustrated at this time. However, lemur taxonomic nomenclature took its modern form in the 1920s and 1930s, being standardized by Ernst Schwarz in 1931.\nAlthough lemur taxonomy had developed, it was not until the 1950s and 1960s that the in-situ (or on-site) study of lemur behavior and ecology began to blossom. Jean-Jacques Petter and Arlette Petter-Rousseaux toured Madagascar in 1956 and 1957, surveying many of its lemur species and making important observations about their social groupings and reproduction. In 1960, the year of Madagascar's independence, David Attenborough introduced lemurs to the West with a commercial film. Under the guidance of John Buettner-Janusch, who founded the Duke Lemur Center in 1966, Alison Jolly traveled to Madagascar in 1962 to study the diet and social behavior of the ring-tailed lemur and Verreaux's sifaka at Berenty Private Reserve. The Petters and Jolly spawned a new era of interest in lemur ecology and behavior and were shortly followed by anthropologists such as Alison Richard, Robert Sussman, Ian Tattersall, and many others. Following the political turmoil of the mid-1970s and Madagascar's revolution, field studies resumed in the 1980s, thanks in part to the renewed involvement of the Duke Lemur Center under the direction of Elwyn L. Simons and the conservation efforts of Patricia Wright. In the decades that followed, huge strides have been made in lemur studies and many new species have been discovered.\nEx situ research (or off-site research) is also popular among researchers looking to answer questions that are difficult to test in the field. For example, efforts to sequence the genome of the gray mouse lemur will help researchers understand which genetic traits set primates apart from other mammals and will ultimately help understand what genomic traits set humans apart from other primates. One of the foremost lemur research facilities is the Duke Lemur Center (DLC) in Durham, North Carolina. It maintains the largest captive lemur population outside of Madagascar, which it maintains for non-invasive research and captive breeding. Many important research projects have been carried out there, including studies of lemur vocalizations, basic locomotor research, the kinematics of bipedalism, the effects of social complexity transitive reasoning, and cognition studies involving a lemur's ability to organize and retrieve sequences from memory. Other facilities, such as the Lemur Conservation Foundation, located near Myakka City, Florida, have also hosted research projects, such as one that looked at lemurs' ability to preferentially select tools based on functional qualities.\nConservation.\nLemurs are threatened by a host of environmental problems, including deforestation, hunting for bushmeat, live capture for the exotic pet trade, and climate change. All species are listed by CITES on Appendix I, which prohibits trade of specimens or parts, except for scientific purposes. As of 2005, the International Union for Conservation of Nature (IUCN) listed 16% of all lemur species as critically endangered, 23% as endangered, 25% as vulnerable, 28% as \"data deficient\", and only 8% as least concern. Over the next five years, at least 28\u00a0species were newly identified, none of which have had their conservation status assessed. Many are likely to be considered threatened since the new lemur species that have been described recently are typically confined to small regions. Given the rate of continued habitat destruction, undiscovered species could go extinct before being identified. Since the arrival of humans on the island approximately 2000\u00a0years ago, all endemic Malagasy vertebrates over 10\u00a0kg (22\u00a0lb) have disappeared, including 17\u00a0species, 8\u00a0genera, and 3\u00a0families of lemurs. The IUCN Species Survival Commission (IUCN/SSC), the International Primatological Society (IPS), and Conservation International (CI) have included as many as five lemurs in their biennial \"Top 25 Most Endangered Primates\". The 2008\u20132010 list includes the greater bamboo lemur, gray-headed lemur (\"Eulemur cinereiceps\"), blue-eyed black lemur (\"Eulemur flavifrons\"), northern sportive lemur (\"Lepilemur septentrionalis\"), and silky sifaka. In 2012, an assessment by the Primate Specialist Group of the International Union for Conservation of Nature (IUCN) concluded that 90% of the then 103\u00a0described species of lemur should be listed as threatened on the IUCN Red List, making lemurs the most endangered group of mammals. The IUCN reiterated its concern in 2013, noting that 90% of all lemur species could be extinct within 20 to 25\u00a0years unless a US$7\u00a0million 3-year conservation plan aimed at helping local communities can be implemented.\nMadagascar is one of the poorest countries in the world, with a high population growth rate of 2.5%\u00a0per year and nearly 70% of the population living in poverty. The country is also burdened with high levels of debt and limited resources. These socioeconomic issues have complicated conservation efforts, even though the island of Madagascar has been recognized by IUCN/SSC as a critical primate region for over 20\u00a0years. Due to its relatively small land area\u2014587,045\u00a0km2 (226,659\u00a0sq mi)\u2014compared to other high-priority biodiversity regions and its high levels of endemism, the country is considered one of the world's most important biodiversity hotspots, with lemur conservation being a high priority. Despite the added emphasis for conservation, there is no indication that the extinctions that began with the arrival of humans have come to an end.\nThreats in the wild.\nThe greatest concern facing lemur populations is habitat destruction and degradation. Deforestation takes the form of local subsistence use, such as slash and burn agriculture (referred to as \"tavy\" in Malagasy), the creation of pasture for cattle through burning, and legal and illegal gathering of wood for firewood or charcoal production; commercial mining; and the illegal logging of precious hardwoods for foreign markets. After centuries of unsustainable use, as well as rapidly escalating forest destruction since 1950, less than 60,000\u00a0km2 (23,000\u00a0sq mi) or 10% of Madagascar's land area remains forested. Only 17,000\u00a0km2 (6,600\u00a0sq mi) or 3% of the island's land area is protected and due to dire economic conditions and political instability, most of the protected areas are ineffectively managed and defended. Some protected areas were set aside because they were naturally protected by their remote, isolated location, often on steep cliffs. Other areas, such as the dry forests and spiny forests of the west and south, receive little protection and are in serious danger of being destroyed.\nSome species may be in risk of extinction even without complete deforestation, such as ruffed lemurs, which are very sensitive to habitat disturbance. If large fruit trees are removed, the forest may sustain fewer individuals of a species and their reproductive success may be affected for years. Small populations may be able to persist in isolated forest fragments for 20 to 40\u00a0years due to long generation times, but in the long term, such populations may not be viable. Small, isolated populations also risk extirpation by natural disasters and disease outbreaks (epizootics). Two diseases that are lethal to lemurs and could severely impact isolated lemur populations are toxoplasmosis, which is spread by feral cats, and the herpes simplex virus carried by humans.\nClimate change and weather-related natural disasters also threaten lemur survival. For the last 1000 years, western and highland regions have been growing significantly drier, but in the past few decades, severe drought has become much more frequent. There are indications that deforestation and forest fragmentation are accelerating this gradual desiccation. The effects of drought are even felt in the rainforests. As annual rainfall decreases, the larger trees that make up the high canopy suffer increased mortality, failure to fruit, and decreased production of new leaves, which folivorous lemurs prefer. Cyclones can defoliate an area, knock down canopy trees, and create landslides and flooding. This can leave lemur populations without fruit or leaves until the following spring, requiring them to subsist on crisis foods, such as epiphytes.\nLemurs are hunted for food by the local Malagasy, either for local subsistence or to supply a luxury meat market in the larger cities. Most rural Malagasy do not understand what \"endangered\" means, nor do they know that hunting lemurs is illegal or that lemurs are found only in Madagascar. Many Malagasy have taboo, or \"fady\", about hunting and eating lemurs, but this does not prevent hunting in many regions. Even though hunting has been a threat to lemur populations in the past, it has recently become a more serious threat as socioeconomic conditions deteriorate. Economic hardships have caused people to move around the country in search of employment, leading local traditions to break down. Drought and famine can also relax the \"fady\" that protect lemurs. Larger species, such as sifakas and ruffed lemurs, are common targets, but smaller species are also hunted or accidentally caught in snares intended for larger prey. Experienced, organized hunting parties using firearms, slings and blowguns can kill as many as eight to twenty lemurs in one trip. Organized hunting parties and lemur traps can be found in both non-protected areas and remote corners of protected areas. National parks and other protected areas are not adequately protected by law enforcement agencies. Often, there are too few park rangers to cover a large area, and sometimes terrain within the park is too rugged to check regularly.\nAlthough not as significant as deforestation and hunting, some lemurs, such as crowned lemurs and other species that have successfully been kept in captivity, are occasionally kept as exotic pets by Malagasy people. Bamboo lemurs are also kept as pets, although they only survive for up to two months. Live capture for the exotic pet trade in wealthier countries is not normally considered a threat due to strict regulations controlling their export.\nConservation efforts.\nLemurs have drawn much attention to Madagascar and its endangered species. In this capacity, they act as flagship species, the most notable of which is the ring-tailed lemur, which is considered an icon of the country. The presence of lemurs in national parks helps drive ecotourism, which especially helps local communities living in the vicinity of the national parks, since it offers employment opportunities and the community receives half of the park entrance fees. In the case of Ranomafana National Park, job opportunities and other revenue from long-term research can rival that of ecotourism.\nStarting in 1927, the Malagasy government has declared all lemurs as \"protected\" by establishing protected areas that are now classified under three categories: National Parks (Parcs Nationaux), Strict Nature Reserves (R\u00e9serves Naturelles Int\u00e9grales), and Special Reserves (R\u00e9serves Sp\u00e9ciales). There are currently 18\u00a0national parks, 5\u00a0strict nature reserves, and 22\u00a0special reserves, as well as several other small private reserves, such as Berenty Reserve and Sainte Luce Private Reserve, both near Fort Dauphin. All protected areas, excluding the private reserves, comprise approximately 3% of the land surface of Madagascar and are managed by Madagascar National Parks, formerly known as l'Association Nationale pour la Gestion des Aires Prot\u00e9g\u00e9es (ANGAP), as well as other non-governmental organizations (NGOs), including Conservation International (CI), the Wildlife Conservation Society (WCS), and the World Wide Fund for Nature (WWF). Most lemur species are covered by this network of protected areas, and a few species can be found in multiple parks or reserves.\nConservation is also facilitated by the Madagascar Fauna Group (MFG), an association of nearly 40\u00a0zoos and related organizations, including the Duke Lemur Center, the Durrell Wildlife Conservation Trust, and the Saint Louis Zoological Park. This international NGO supports Madagascar's Parc Ivoloina, helps protect Betampona Reserve and other protected areas, and promotes field research, breeding programs, conservation planning, and education in zoos. One of their major projects involved the release of captive black-and-white ruffed lemurs, designed to help restock the dwindling population within Betampona Reserve.\nHabitat corridors are needed for linking these protected areas so that small populations are not isolated. In in Durban, South Africa, Madagascar's former president Marc Ravalomanana promised to triple the size of the island's protected areas in five years. This became known as the \"Durban Vision\". In June\u00a02007, the World Heritage Committee included a sizable portion of Madagascar's eastern rainforests as a new UNESCO World Heritage Site.\nDebt relief may help Madagascar protect its biodiversity. \nCaptive lemur populations are maintained locally and outside of Madagascar in varied zoological conservatories and research centers, although the diversity of species is limited. Sikafas, for instance, do not survive well in captivity, so few facilities have them. The largest captive lemur population can be found at the Duke Lemur Center (DLC), whose mission includes non-invasive research, conservation (e.g. captive breeding), and public education. Another large lemur colony includes the Myakka City Lemur Reserve run by the Lemur Conservation Foundation (LCF), which also hosts lemur research. In Madagascar, Lemurs' Park is a free-range, private facility southwest of Antananarivo that exhibits lemurs for the public while also rehabilitating captive-born lemurs for reintroduction into the wild.\nIn Malagasy culture.\nIn Malagasy culture, lemurs, and animals in general, have souls (\"ambiroa\") which can get revenge if mocked while alive or if killed in a cruel fashion. Because of this, lemurs, like many other elements of daily life, have been a source of taboos, known locally as \"fady\", which can be based around stories with four basic principles. A village or region may believe that a certain type of lemur may be the ancestor of the clan. They may also believe that a lemur's spirit may get revenge. Alternatively, the animal may appear as a benefactor. Lemurs are also thought to impart their qualities, good or bad, onto human babies. In general, \"fady\" extend beyond a sense of the forbidden, but can include events that bring bad luck.\nOne example of lemur \"fady\" told around 1970 comes from Ambatofinandrahana in the Fianarantsoa Province. According to the account, a man brought a lemur home in a trap, but alive. His children wanted to keep the lemur as a pet, but when the father told them it was not a domestic animal, the children asked to kill it. After the children tortured the lemur, it eventually died and was eaten. A short time later, all the children died of illness. As a result, the father declared that anyone who tortures lemurs for fun shall \"be destroyed and have no descendants.\"\n\"Fady\" can not only help protect lemurs and their forests under stable socioeconomic situations, but they can also lead to discrimination and persecution if a lemur is known to bring bad fortune, for instance, if it walks through town. In other ways, \"fady\" does not protect all lemurs equally. For example, although the hunting and eating of certain species may be taboo, other species may not share that same protection and are therefore targeted instead. \"Fady\" can vary from village to village within the same region. If people move to a new village or region, their \"fady\" may not apply to the lemur species that are locally present, making them available for consumption. \"Fady\" restrictions on lemur meat can be relaxed in times of famine and drought.\nThe aye-aye is almost universally viewed unfavorably across Madagascar, though the tales vary from village to village and region to region. If people see an aye-aye, they may kill it and hang the corpse on a pole near a road outside of town (so others can carry the bad fortunes away) or burn their village and move. The superstitions behind aye-aye \"fady\" include beliefs that they kill and eat chickens or people, that they kill people in their sleep by cutting their aortic vein, that they embody ancestral spirits, or that they warn of illness, death, or bad luck in the family. As of 1970, the people of the Marolambo District in the Toamasina Province feared the aye-aye because they believed it had supernatural powers. Because of this, no one was allowed to mock, kill, or eat one.\nThere are also widespread \"fady\" about indri and sifakas. They are often protected from hunting and consumption because of their resemblance to humans and their ancestors, mostly due to their large size and upright or orthograde posture. The resemblance is even stronger for indri, which lack the long tail of most living lemurs. Known locally as \"babakoto\" (\"Ancestor of Man\"), the indri is sometimes seen as the progenitor of the family or clan. There are also stories of an indri that helped a human down from a tree, so they are seen as benefactors. Other lemur \"fady\" include the belief that a wife will have ugly children if her husband kills a woolly lemur, or that if a pregnant woman eats a dwarf lemur, her baby will get its beautiful, round eyes.\nIn popular culture.\nLemurs have also become popular in Western culture in recent years. The DreamWorks Animation franchise \"Madagascar\" features the characters King Julien, Maurice and Mort and was seen by an estimated 100\u00a0million people in theaters and 200\u2013300\u00a0million people on DVD worldwide. Prior to this film, \"Zoboomafoo\", a Public Broadcasting Service (PBS) children's television series from 1999 to 2001, helped to popularize sifakas by featuring a live Coquerel's sifaka from the Duke Lemur Center as well as a puppet. The Disney Channel series, \"Bear in the Big Blue House\" one of the characters, Treelo, is a lemur. A twenty-episode series called \"Lemur Kingdom\" (in the United States) or \"Lemur Street\" (in the United Kingdom and Canada) aired in 2008 on Animal Planet. It combined the typical animal documentary with dramatic narration to tell the story of two groups of ring-tailed lemurs at Berenty Private Reserve.\nLemurs of many kinds, appear in William S. Burroughs final novel \"Ghost of Chance\" that takes place in and around Madagascar. ", "categories": ["Category:All Wikipedia articles in need of updating", "Category:All articles containing potentially dated statements", "Category:Articles containing potentially dated statements from 2013", "Category:Articles using diversity taxobox", "Category:Articles with 'species' microformats", "Category:Articles with hAudio microformats", "Category:Articles with short description", "Category:CS1 Latin-language sources (la)", "Category:Endemic fauna of Madagascar", "Category:Extant Pleistocene first appearances"]}, {"docid": 567471, "title": "Sea otter", "text": "The sea otter (Enhydra lutris) is a marine mammal native to the coasts of the northern and eastern North Pacific Ocean. Adult sea otters typically weigh between , making them the heaviest members of the weasel family, but among the smallest marine mammals. Unlike most marine mammals, the sea otter's primary form of insulation is an exceptionally thick coat of fur, the densest in the animal kingdom. Although it can walk on land, the sea otter is capable of living exclusively in the ocean.\nThe sea otter inhabits nearshore environments, where it dives to the sea floor to forage. It preys mostly on marine invertebrates such as sea urchins, various mollusks and crustaceans, and some species of fish. Its foraging and eating habits are noteworthy in several respects. Its use of rocks to dislodge prey and to open shells makes it one of the few mammal species to use tools. In most of its range, it is a keystone species, controlling sea urchin populations which would otherwise inflict extensive damage to kelp forest ecosystems. Its diet includes prey species that are also valued by humans as food, leading to conflicts between sea otters and fisheries.\nSea otters, whose numbers were once estimated at 150,000\u2013300,000, were hunted extensively for their fur between 1741 and 1911, and the world population fell to 1,000\u20132,000 individuals living in a fraction of their historic range. A subsequent international ban on hunting, sea otter conservation efforts, and reintroduction programs into previously populated areas have contributed to numbers rebounding, and the species occupies about two-thirds of its former range. The recovery of the sea otter is considered an important success in marine conservation, although populations in the Aleutian Islands and California have recently declined or have plateaued at depressed levels. For these reasons, the sea otter remains classified as an endangered species.\nEvolution.\nThe sea otter is the heaviest (the giant otter is longer, but significantly slimmer) member of the family Mustelidae, a diverse group that includes the 13 otter species and terrestrial animals such as weasels, badgers, and minks. It is unique among the mustelids in not making or burrows, in having no functional anal scent glands, and in being able to live its entire life without leaving the water. The only living member of the genus \"Enhydra\", the sea otter is so different from other mustelid species that, as recently as 1982, some scientists believed it was more closely related to the earless seals. Genetic analysis indicates the sea otter and its closest extant relatives, which include the African speckle-throated otter, Eurasian otter, African clawless otter and Asian small-clawed otter, shared an ancestor approximately 5\u00a0million years ago.\nFossil evidence indicates the \"Enhydra\" lineage became isolated in the North Pacific approximately 2\u00a0million years ago, giving rise to the now-extinct \"Enhydra macrodonta\" and the modern sea otter, \"Enhydra lutris\". One related species has been described, \"Enhydra reevei\", from the Pleistocene of East Anglia. The modern sea otter evolved initially in northern Hokkaid\u014d and Russia, and then spread east to the Aleutian Islands, mainland Alaska, and down the North American coast. In comparison to cetaceans, sirenians, and pinnipeds, which entered the water approximately 50, 40, and 20\u00a0million years ago, respectively, the sea otter is a relative newcomer to a marine existence. In some respects, though, the sea otter is more fully adapted to water than pinnipeds, which must haul out on land or ice to give birth. The full genome of the northern sea otter (\"Enhydra lutris kenyoni\") was sequenced in 2017 and may allow for examination of the sea otter's evolutionary divergence from terrestrial mustelids.\nTaxonomy.\nThe first scientific description of the sea otter is contained in the field notes of Georg Steller from 1751, and the species was described by Carl Linnaeus in his landmark 1758 10th edition of \"Systema Naturae\". Originally named \"Lutra marina\", it underwent numerous name changes before being accepted as \"Enhydra lutris\" in 1922. The generic name \"Enhydra\", derives from the Ancient Greek \"en\"/\u03b5\u03bd \"in\" and \"hydra\"/\u03cd\u03b4\u03c1\u03b1 \"water\", meaning \"in the water\", and the Latin word \"lutris\", meaning \"otter\". It was formerly sometimes referred to as the \"sea beaver\".\nSubspecies.\nThree subspecies of the sea otter are recognized with distinct geographical distributions. \"Enhydra lutris lutris\" (nominate), the Asian sea otter, ranges across Russia's Kuril Islands northeast of Japan, and the Commander Islands in the northwestern Pacific Ocean. In the eastern Pacific Ocean, \"E. l. kenyoni\", the northern sea otter, is found from Alaska's Aleutian Islands to Oregon and \"E. l. nereis\", the southern sea otter, is native to central and southern California. The Asian sea otter is the largest subspecies and has a slightly wider skull and shorter nasal bones than both other subspecies. Northern sea otters possess longer mandibles (lower jaws) while southern sea otters have longer rostrums and smaller teeth.\nDescription.\nThe sea otter is one of the smallest marine mammal species, but it is the heaviest mustelid. Male sea otters usually weigh and are in length, though specimens up to have been recorded. Females are smaller, weighing and measuring in length. For its size, the male otter's baculum is very large, massive and bent upwards, measuring in length and at the base.\nUnlike most other marine mammals, the sea otter has no blubber and relies on its exceptionally thick fur to keep warm. With up to , its fur is the densest of any animal. The fur consists of long, waterproof guard hairs and short underfur; the guard hairs keep the dense underfur layer dry. There is an air compartment between the thick fur and the skin where air is trapped and heated by the body. Cold water is kept completely away from the skin and heat loss is limited. However, a potential disadvantage of this form of insulation is compression of the air layer as the otter dives, thereby reducing the insulating quality of fur at depth when the animal forages. The fur is thick year-round, as it is shed and replaced gradually rather than in a distinct molting season. As the ability of the guard hairs to repel water depends on utmost cleanliness, the sea otter has the ability to reach and groom the fur on any part of its body, taking advantage of its loose skin and an unusually supple skeleton. The coloration of the pelage is usually deep brown with silver-gray speckles, but it can range from yellowish or grayish brown to almost black. In adults, the head, throat, and chest are lighter in color than the rest of the body.\nThe sea otter displays numerous adaptations to its marine environment. The nostrils and small ears can close. The hind feet, which provide most of its propulsion in swimming, are long, broadly flattened, and fully webbed. The fifth digit on each hind foot is longest, facilitating swimming while on its back, but making walking difficult. The tail is fairly short, thick, slightly flattened, and muscular. The front paws are short with retractable claws, with tough pads on the palms that enable gripping slippery prey. The bones show osteosclerosis, increasing their density to reduce buoyancy.\nThe sea otter presents an insight into the evolutionary process of the mammalian invasion of the aquatic environment, which has occurred numerous times over the course of mammalian evolution. Having only returned to the sea about 3 million years ago, sea otters represent a snapshot at the earliest point of the transition from fur to blubber. In sea otters, fur is still advantageous, given their small nature and division of lifetime between the aquatic and terrestrial environments. However, as sea otters evolve and adapt to spending more and more of their lifetimes in the sea, the convergent evolution of blubber suggests that the reliance on fur for insulation would be replaced by a dependency on blubber. This is particularly true due to the diving nature of the sea otter; as dives become lengthier and deeper, the air layer's ability to retain heat or buoyancy decreases, while blubber remains efficient at both of those functions. Blubber can also additionally serve as an energy source for deep dives, which would most likely prove advantageous over fur in the evolutionary future of sea otters. \nThe sea otter propels itself underwater by moving the rear end of its body, including its tail and hind feet, up and down, and is capable of speeds of up to . When underwater, its body is long and streamlined, with the short forelimbs pressed closely against the chest. When at the surface, it usually floats on its back and moves by sculling its feet and tail from side to side. At rest, all four limbs can be folded onto the torso to conserve heat, whereas on particularly hot days, the hind feet may be held underwater for cooling. The sea otter's body is highly buoyant because of its large lung capacity \u2013 about 2.5 times greater than that of similar-sized land mammals \u2013 and the air trapped in its fur. The sea otter walks with a clumsy, rolling gait on land, and can run in a bounding motion.\nLong, highly sensitive whiskers and front paws help the sea otter find prey by touch when waters are dark or murky. Researchers have noted when they approach in plain view, sea otters react more rapidly when the wind is blowing towards the animals, indicating the sense of smell is more important than sight as a warning sense. Other observations indicate the sea otter's sense of sight is useful above and below the water, although not as good as that of seals. Its hearing is neither particularly acute nor poor.\nAn adult's 32 teeth, particularly the molars, are flattened and rounded for crushing rather than cutting food. Seals and sea otters are the only carnivores with two pairs of lower incisor teeth rather than three; the adult dental formula is . The teeth and bones are sometimes stained purple as a result of ingesting sea urchins.\nThe sea otter has a metabolic rate two or three times that of comparatively sized terrestrial mammals. It must eat an estimated 25 to 38% of its own body weight in food each day to burn the calories necessary to counteract the loss of heat due to the cold water environment. Its digestive efficiency is estimated at 80 to 85%, and food is digested and passed in as little as three hours. Most of its need for water is met through food, although, in contrast to most other marine mammals, it also drinks seawater. Its relatively large kidneys enable it to derive fresh water from sea water and excrete concentrated urine.\nBehavior.\nThe sea otter is diurnal. It has a period of foraging and eating in the morning, starting about an hour before sunrise, then rests or sleeps in mid-day. Foraging resumes for a few hours in the afternoon and subsides before sunset, and a third foraging period may occur around midnight. Females with pups appear to be more inclined to feed at night. Observations of the amount of time a sea otter must spend each day foraging range from 24 to 60%, apparently depending on the availability of food in the area.\nSea otters spend much of their time grooming, which consists of cleaning the fur, untangling knots, removing loose fur, rubbing the fur to squeeze out water and introduce air, and blowing air into the fur. To casual observers, it appears as if the animals are scratching, but they are not known to have lice or other parasites in the fur. When eating, sea otters roll in the water frequently, apparently to wash food scraps from their fur.\nForaging.\nThe sea otter hunts in short dives, often to the sea floor. Although it can hold its breath for up to five minutes, its dives typically last about one minute and not more than four. It is the only marine animal capable of lifting and turning over rocks, which it often does with its front paws when searching for prey. The sea otter may also pluck snails and other organisms from kelp and dig deep into underwater mud for clams. It is the only marine mammal that catches fish with its forepaws rather than with its teeth.\nUnder each foreleg, the sea otter has a loose pouch of skin that extends across the chest. In this pouch (preferentially the left one), the animal stores collected food to bring to the surface. This pouch also holds a rock, unique to the otter, that is used to break open shellfish and clams. At the surface, the sea otter eats while floating on its back, using its forepaws to tear food apart and bring it to its mouth. It can chew and swallow small mussels with their shells, whereas large mussel shells may be twisted apart. It uses its lower incisor teeth to access the meat in shellfish.\nTo eat large sea urchins, which are mostly covered with spines, the sea otter bites through the underside where the spines are shortest, and licks the soft contents out of the urchin's shell.\nThe sea otter's use of rocks when hunting and feeding makes it one of the few mammal species to use tools. To open hard shells, it may pound its prey with both paws against a rock on its chest. To pry an abalone off its rock, it hammers the abalone shell using a large stone, with observed rates of 45 blows in 15 seconds. Releasing an abalone, which can cling to rock with a force equal to 4,000 times its own body weight, requires multiple dives.\nSocial structure.\nAlthough each adult and independent juvenile forages alone, sea otters tend to rest together in single-sex groups called \"rafts\". A raft typically contains 10 to 100 animals, with male rafts being larger than female ones. The largest raft ever seen contained over 2000 sea otters. To keep from drifting out to sea when resting and eating, sea otters may wrap themselves in kelp.\nA male sea otter is most likely to mate if he maintains a breeding territory in an area that is also favored by females. As autumn is the peak breeding season in most areas, males typically defend their territory only from spring to autumn. During this time, males patrol the boundaries of their territories to exclude other males, although actual fighting is rare. Adult females move freely between male territories, where they outnumber adult males by an average of five to one. Males that do not have territories tend to congregate in large, male-only groups, and swim through female areas when searching for a mate.\nThe species exhibits a variety of vocal behaviors. The cry of a pup is often compared to that of a gull. Females coo when they are apparently content; males may grunt instead. Distressed or frightened adults may whistle, hiss, or in extreme circumstances, scream. Although sea otters can be playful and sociable, they are not considered to be truly social animals. They spend much time alone, and each adult can meet its own hunting, grooming, and defense needs.\nReproduction and life cycle.\nSea otters are polygynous: males have multiple female partners, typically those that inhabit their territory. If no territory is established, they seek out females in estrus. When a male sea otter finds a receptive female, the two engage in playful and sometimes aggressive behavior. They bond for the duration of estrus, or 3 days. The male holds the female's head or nose with his jaws during copulation. Visible scars are often present on females from this behavior.\nBirths occur year-round, with peaks between May and June in northern populations and between January and March in southern populations. Gestation appears to vary from four to twelve months, as the species is capable of delayed implantation followed by four months of pregnancy. In California, sea otters usually breed every year, about twice as often as those in Alaska.\nBirth usually takes place in the water and typically produces a single pup weighing . Twins occur in 2% of births; however, usually only one pup survives. At birth, the eyes are open, ten teeth are visible, and the pup has a thick coat of baby fur. Mothers have been observed to lick and fluff a newborn for hours; after grooming, the pup's fur retains so much air, the pup floats like a cork and cannot dive. The fluffy baby fur is replaced by adult fur after about 13 weeks.\nNursing lasts six to eight months in Californian populations and four to twelve months in Alaska, with the mother beginning to offer bits of prey at one to two months. The milk from a sea otter's two abdominal nipples is rich in fat and more similar to the milk of other marine mammals than to that of other mustelids. A pup, with guidance from its mother, practices swimming and diving for several weeks before it is able to reach the sea floor. Initially, the objects it retrieves are of little food value, such as brightly colored starfish and pebbles. Juveniles are typically independent at six to eight months, but a mother may be forced to abandon a pup if she cannot find enough food for it; at the other extreme, a pup may nurse until it is almost adult size. Pup mortality is high, particularly during an individual's first winter\u00a0\u2013 by one estimate, only 25% of pups survive their first year. Pups born to experienced mothers have the highest survival rates.\nFemales perform all tasks of feeding and raising offspring, and have occasionally been observed caring for orphaned pups. Much has been written about the level of devotion of sea otter mothers for their pups\u00a0\u2013 a mother gives her infant almost constant attention, cradling it on her chest away from the cold water and attentively grooming its fur. When foraging, she leaves her pup floating on the water, sometimes wrapped in kelp to keep it from floating away; if the pup is not sleeping, it cries loudly until she returns. Mothers have been known to carry their pups for days after the pups' deaths.\nFemales become sexually mature at around three or four years of age and males at around five; however, males often do not successfully breed until a few years later. A captive male sired offspring at age 19. In the wild, sea otters live to a maximum age of 23 years, with lifespans ranging from 10 to 15 years for males and 15\u201320 years for females. Several captive individuals have lived past 20 years, and a female at the Seattle Aquarium died at the age of 28 years. Sea otters in the wild often develop worn teeth, which may account for their apparently shorter lifespans.\nPopulation and distribution.\nSea otters live in coastal waters deep, and usually stay within a kilometre (\u00a0mi) of the shore. They are found most often in areas with protection from the most severe ocean winds, such as rocky coastlines, thick kelp forests, and barrier reefs. Although they are most strongly associated with rocky substrates, sea otters can also live in areas where the sea floor consists primarily of mud, sand, or silt. Their northern range is limited by ice, as sea otters can survive amidst drift ice but not land-fast ice. Individuals generally occupy a home range a few kilometres long, and remain there year-round.\nThe sea otter population is thought to have once been 150,000 to 300,000, stretching in an arc across the North Pacific from northern Japan to the central Baja California Peninsula in Mexico. The fur trade that began in the 1740s reduced the sea otter's numbers to an estimated 1,000 to 2,000 members in 13 colonies. Hunting records researched by historian Adele Ogden place the westernmost limit of the hunting grounds off the northern Japanese island of Hokkaido and the easternmost limit off Punta Morro Hermosa about south of Punta Eugenia, Baja California's westernmost headland in Mexico.\nIn about two-thirds of its former range, the species is at varying levels of recovery, with high population densities in some areas and threatened populations in others. Sea otters currently have stable populations in parts of the Russian east coast, Alaska, British Columbia, Washington, and California, with reports of recolonizations in Mexico and Japan. Population estimates made between 2004 and 2007 give a worldwide total of approximately 107,000 sea otters.\nJapan.\nAdele Ogden wrote in \"The California Sea Otter Trade\" that sea otter were hunted \"from Yezo northeastward past the Kuril Group and Kamchatka to the Aleutian Chain\". \"Yezo\" refers to the island of Hokkaido in northern Japan; the only confirmed sea otter population in Japanese territory is on the coast surrounding the town of Erimo, Hokkaido.\nRussia.\nCurrently, the most stable and secure part of the sea otter's range is Russia. Before the 19th century, around 20,000 to 25,000 sea otters lived near the Kuril Islands, with more near Kamchatka and the Commander Islands. After the years of the Great Hunt, the population in these areas, currently part of Russia, was only 750. By 2004, sea otters had repopulated all of their former habitat in these areas, with an estimated total population of about 27,000. Of these, about 19,000 are at the Kurils, 2,000 to 3,500 at Kamchatka and another 5,000 to 5,500 at the Commander Islands. Growth has slowed slightly, suggesting the numbers are reaching carrying capacity.\nBritish Columbia.\nAlong the North American coast south of Alaska, the sea otter's range is discontinuous. A remnant population survived off Vancouver Island into the 20th century, but it died out despite the 1911 international protection treaty, with the last sea otter taken near Kyuquot in 1929. From 1969 to 1972, 89 sea otters were flown or shipped from Alaska to the west coast of Vancouver Island. This population increased to over 5,600 in 2013 with an estimated annual growth rate of 7.2%, and their range on the island's west coast extended north to Cape Scott and across the Queen Charlotte Strait to the Broughton Archipelago and south to Clayoquot Sound and Tofino. In 1989, a separate colony was discovered in the central British Columbia coast. It is not known if this colony, which numbered about 300 animals in 2004, was founded by transplanted otters or was a remnant population that had gone undetected. By 2013, this population exceeded 1,100 individuals, was increasing at an estimated 12.6% annual rate, and its range included Aristazabal Island, and Milbanke Sound south to Calvert Island. In 2008, Canada determined the status of sea otters to be \"special concern\".\nUnited States.\nAlaska.\nAlaska is the central area of the sea otter's range. In 1973, the population in Alaska was estimated at between 100,000 and 125,000 animals. By 2006, though, the Alaska population had fallen to an estimated 73,000 animals. A massive decline in sea otter populations in the Aleutian Islands accounts for most of the change; the cause of this decline is not known, although orca predation is suspected. The sea otter population in Prince William Sound was also hit hard by the Exxon Valdez oil spill, which killed thousands of sea otters in 1989.\nWashington.\nIn 1969 and 1970, 59 sea otters were translocated from Amchitka Island to Washington, and released near La Push and Point Grenville. The translocated population is estimated to have declined to between 10 and 43 individuals before increasing, reaching 208 individuals in 1989. As of 2017, the population was estimated at over 2,000 individuals, and their range extends from Point Grenville in the south to Cape Flattery in the north and east to Pillar Point along the Strait of Juan de Fuca.\nIn Washington, sea otters are found almost exclusively on the outer coasts. They can swim as close as six feet off shore along the Olympic coast. Reported sightings of sea otters in the San Juan Islands and Puget Sound almost always turn out to be North American river otters, which are commonly seen along the seashore. However, biologists have confirmed isolated sightings of sea otters in these areas since the mid-1990s.\nOregon.\nThe last native sea otter in Oregon was probably shot and killed in 1906. In 1970 and 1971, a total of 95 sea otters were transplanted from Amchitka Island, Alaska to the Southern Oregon coast. However, this translocation effort failed and otters soon again disappeared from the state. In 2004, a male sea otter took up residence at Simpson Reef off of Cape Arago for six months. This male is thought to have originated from a colony in Washington, but disappeared after a coastal storm. On 18 February 2009, a male sea otter was spotted in Depoe Bay off the Oregon Coast. It could have traveled to the state from either California or Washington.\nCalifornia.\nThe historic population of California sea otters was estimated at 16,000 before the fur trade decimated the population, leading to their assumed extinction. Today's population of California sea otters are the descendants of a single colony of about 50 sea otters located near Bixby Creek Bridge in March 1938 by Howard G. Sharpe, owner of the nearby Rainbow Lodge on Bixby Bridge in Big Sur. Their principal range has gradually expanded and extends from Pigeon Point in San Mateo County to Santa Barbara County.\nSea otters were once numerous in San Francisco Bay. Historical records revealed the Russian-American Company sneaked Aleuts into San Francisco Bay multiple times, despite the Spanish capturing or shooting them while hunting sea otters in the estuaries of San Jose, San Mateo, San Bruno and around Angel Island. The founder of Fort Ross, Ivan Kuskov, finding otters scarce on his second voyage to Bodega Bay in 1812, sent a party of Aleuts to San Francisco Bay, where they met another Russian party and an American party, and caught 1,160 sea otters in three months. By 1817, sea otters in the area were practically eliminated and the Russians sought permission from the Spanish and the Mexican governments to hunt further and further south of San Francisco. Remnant sea otter populations may have survived in the bay until 1840, when the Rancho Punta de Quentin was granted to Captain John B. R. Cooper, a sea captain from Boston, by Mexican Governor Juan Bautista Alvarado along with a license to hunt sea otters, reportedly then prevalent at the mouth of Corte Madera Creek.\nIn the late 1980s, the USFWS relocated about 140 southern sea otters to San Nicolas Island in southern California, in the hope of establishing a reserve population should the mainland be struck by an oil spill. To the surprise of biologists, the majority of the San Nicolas sea otters swam back to the mainland. Another group of twenty swam north to San Miguel Island, where they were captured and removed. By 2005, only 30 sea otters remained at San Nicolas, although they were slowly increasing as they thrived on the abundant prey around the island. The plan that authorized the translocation program had predicted the carrying capacity would be reached within five to 10 years. The spring 2016 count at San Nicolas Island was 104 sea otters, continuing a 5-year positive trend of over 12% per year. Sea otters were observed twice in Southern California in 2011, once near Laguna Beach and once at Zuniga Point Jetty, near San Diego. These are the first documented sightings of otters this far south in 30 years.\nWhen the USFWS implemented the translocation program, it also attempted, in 1986, to implement \"zonal management\" of the Californian population. To manage the competition between sea otters and fisheries, it declared an \"otter-free zone\" stretching from Point Conception to the Mexican border. In this zone, only San Nicolas Island was designated as sea otter habitat, and sea otters found elsewhere in the area were supposed to be captured and relocated. These plans were abandoned after many translocated otters died and also as it proved impractical to capture the hundreds of otters which ignored regulations and swam into the zone. However, after engaging in a period of public commentary in 2005, the Fish and Wildlife Service failed to release a formal decision on the issue. Then, in response to lawsuits filed by the Santa Barbara-based Environmental Defense Center and the Otter Project, on 19 December 2012 the USFWS declared that the \"no otter zone\" experiment was a failure, and will protect the otters re-colonizing the coast south of Point Conception as threatened species. Although abalone fisherman blamed the incursions of sea otters for the decline of abalone, commercial abalone fishing in southern California came to an end from overfishing in 1997, years before significant otter moved south of Point Conception. In addition, white abalone (\"Haliotis sorenseni\"), a species never overlapping with sea otter, had declined in numbers 99% by 1996, and became the first marine invertebrate to be federally listed as endangered.\nAlthough the southern sea otter's range has continuously expanded from the remnant population of about 50 individuals in Big Sur since protection in 1911, from 2007 to 2010, the otter population and its range contracted and since 2010 has made little progress. As of spring 2010, the northern boundary had moved from about Tunitas Creek to a point southeast of Pigeon Point, and the southern boundary has moved along the Gaviota Coast from approximately Coal Oil Point to Gaviota State Park. A toxin called microcystin, produced by a type of cyanobacteria (\"Microcystis\"), seems to be concentrated in the shellfish the otters eat, poisoning them. Cyanobacteria are found in stagnant water enriched with nitrogen and phosphorus from septic tank and agricultural fertilizer runoff, and may be flushed into the ocean when streamflows are high in the rainy season. A record number of sea otter carcasses were found on California's coastline in 2010, with increased shark attacks an increasing component of the mortality. Great white sharks do not consume relatively fat-poor sea otters but shark-bitten carcasses have increased from 8% in the 1980s to 15% in the 1990s and to 30% in 2010 and 2011.\nFor southern sea otters to be considered for removal from threatened species listing, the U.S. Fish and Wildlife Service (USFWS) determined that the population should exceed 3,090 for three consecutive years. In response to recovery efforts, the population climbed steadily from the mid-20th century through the early 2000s, then remained relatively flat from 2005 to 2014 at just under 3,000. There was some contraction from the northern (now Pigeon Point) and southern limits of the sea otter's range during the end of this period, circumstantially related to an increase in lethal shark bites, raising concerns that the population had reached a plateau. However, the population increased markedly from 2015 to 2016, with the United States Geological Survey (USGS) California sea otter survey 3-year average reaching 3,272 in 2016, the first time it exceeded the threshold for delisting from the Endangered Species Act (ESA). If populations continued to grow and ESA delisting occurred, southern sea otters would still be fully protected by state regulations and the Marine Mammal Protection Act, which set higher thresholds for protection, at approximately 8,400 individuals. However, ESA delisting seems unlikely due to a precipitous population decline recorded in the spring 2017 USGS sea otter survey count, from the 2016 high of 3,615 individuals to 2,688, a loss of 25% of the California sea otter population.\nMexico.\nHistorian Adele Ogden described sea otters are particularly abundant in \"Lower California\", now the Baja California Peninsula, where \"seven bays...were main centers\". The southernmost limit was Punta Morro Hermoso about south of Punta Eugenia, in turn a headland at the southwestern end of Sebasti\u00e1n Vizca\u00edno Bay, on the west coast of the Baja Peninsula. Otter were also taken from San Benito Island, Cedros Island, and Isla Natividad in the Bay. By the early 1900s, Baja's sea otters were extirpated by hunting. In a 1997 survey, small numbers of sea otters, including pups, were reported by local fishermen, but scientists could not confirm these accounts. However, male and female otters have been confirmed by scientists off shores of the Baja Peninsula in a 2014 study, who hypothesize that otter dispersed there beginning in 2005. These sea otters may have dispersed from San Nicolas Island, which is away, as individuals have been recorded traversing distances of over . Genetic analysis of most of these animals were consistent with California, i.e. United States, otter origins, however one otter had a haplotype not previously reported, and could represent a remnant of the original native Mexican otter population.\nEcology.\nDiet.\nHigh energetic requirements of sea otter metabolism require them to consume at least 20% of their body weight a day. Surface swimming and foraging are major factors in their high energy expenditure due to drag on the surface of the water when swimming and the thermal heat loss from the body during deep dives when foraging. Sea otter muscles are specially adapted to generate heat without physical activity.\nSea otters consume over 100 prey species. In most of its range, the sea otter's diet consists almost exclusively of marine benthic invertebrates, including sea urchins (such as \"Strongylocentrotus franciscanus\" and \"S. purpuratus\"), fat innkeeper worms, a variety of bivalves such as clams, mussels (such as \"Mytilus edulis\"), and scallops (such as \"Crassadoma gigantea\"), abalone, limpets (such as \"Diodora aspera\"), chitons (such as \"Katharina tunicata\"), other mollusks, crustaceans, and snails. Its prey ranges in size from tiny limpets and crabs to giant octopuses. Where prey such as sea urchins, clams, and abalone are present in a range of sizes, sea otters tend to select larger items over smaller ones of similar type. In California, they have been noted to ignore Pismo clams smaller than across.\nIn a few northern areas, fish are also eaten. In studies performed at Amchitka Island in the 1960s, where the sea otter population was at carrying capacity, 50% of food found in sea otter stomachs was fish. The fish species were usually bottom-dwelling and sedentary or sluggish forms, such as \"Hemilepidotus hemilepidotus\" and family Tetraodontidae. However, south of Alaska on the North American coast, fish are a negligible or extremely minor part of the sea otter's diet. Contrary to popular depictions, sea otters rarely eat starfish, and any kelp that is consumed apparently passes through the sea otter's system undigested.\nThe individuals within a particular area often differ in their foraging methods and prey types, and tend to follow the same patterns as their mothers. The diet of local populations also changes over time, as sea otters can significantly deplete populations of highly preferred prey such as large sea urchins, and prey availability is also affected by other factors such as fishing by humans. Sea otters can thoroughly remove abalone from an area except for specimens in deep rock crevices, however, they never completely wipe out a prey species from an area. A 2007 Californian study demonstrated, in areas where food was relatively scarce, a wider variety of prey was consumed. Surprisingly, though, the diets of individuals were more specialized in these areas than in areas where food was plentiful.\nAs a keystone species.\nSea otters are a classic example of a keystone species; their presence affects the ecosystem more profoundly than their size and numbers would suggest. They keep the population of certain benthic (sea floor) herbivores, particularly sea urchins, in check. Sea urchins graze on the lower stems of kelp, causing the kelp to drift away and die. Loss of the habitat and nutrients provided by kelp forests leads to profound cascade effects on the marine ecosystem. North Pacific areas that do not have sea otters often turn into urchin barrens, with abundant sea urchins and no kelp forest. Kelp forests are extremely productive ecosystems. Kelp forests sequester (absorb and capture) CO2 from the atmosphere through photosynthesis. Sea otters may help mitigate effects of climate change by their cascading trophic influence\nReintroduction of sea otters to British Columbia has led to a dramatic improvement in the health of coastal ecosystems, and similar changes have been observed as sea otter populations recovered in the Aleutian and Commander Islands and the Big Sur coast of California However, some kelp forest ecosystems in California have also thrived without sea otters, with sea urchin populations apparently controlled by other factors. The role of sea otters in maintaining kelp forests has been observed to be more important in areas of open coast than in more protected bays and estuaries.\nSea otters affect rocky ecosystems that are dominated by mussel beds by removing mussels from rocks. This allows space for competing species and increases species diversity.\nPredators.\nLeading mammalian predators of this species include orcas and sea lions, and bald eagles may grab pups from the surface of the water. Young predators may kill an otter and not eat it. On land, young sea otters may face attack from bears and coyotes. In California, great white sharks are their primary predator but there is no evidence that the sharks eat them.\nUrban runoff transporting cat feces into the ocean brings \"Toxoplasma gondii\", an obligate parasite of felids, which has killed sea otters. Parasitic infections of \"Sarcocystis neurona\" are also associated with human activity. According to the U.S. Geological Survey and the CDC, northern sea otters off Washington have been infected with the H1N1 flu virus and \"may be a newly identified animal host of influenza viruses\".\nRelationship with humans.\nFur trade.\nSea otters have the thickest fur of any mammal, which makes them a common target for many hunters. Archaeological evidence indicates that for thousands of years, indigenous peoples have hunted sea otters for food and fur. Large-scale hunting, part of the Maritime Fur Trade, which would eventually kill approximately one million sea otters, began in the 18th century when hunters and traders began to arrive from all over the world to meet foreign demand for otter pelts, which were one of the world's most valuable types of fur.\nIn the early 18th century, Russians began to hunt sea otters in the Kuril Islands and sold them to the Chinese at Kyakhta. Russia was also exploring the far northern Pacific at this time, and sent Vitus Bering to map the Arctic coast and find routes from Siberia to North America. In 1741, on his second North Pacific voyage, Bering was shipwrecked off Bering Island in the Commander Islands, where he and many of his crew died. The surviving crew members, which included naturalist Georg Steller, discovered sea otters on the beaches of the island and spent the winter hunting sea otters and gambling with otter pelts. They returned to Siberia, having killed nearly 1,000 sea otters, and were able to command high prices for the pelts. Thus began what is sometimes called the \"Great Hunt\", which would continue for another hundred years. The Russians found the sea otter far more valuable than the sable skins that had driven and paid for most of their expansion across Siberia. If the sea otter pelts brought back by Bering's survivors had been sold at Kyakhta prices they would have paid for one tenth the cost of Bering's expedition.\nRussian fur-hunting expeditions soon depleted the sea otter populations in the Commander Islands, and by 1745, they began to move on to the Aleutian Islands. The Russians initially traded with the Aleuts inhabitants of these islands for otter pelts, but later enslaved the Aleuts, taking women and children hostage and torturing and killing Aleut men to force them to hunt. Many Aleuts were either murdered by the Russians or died from diseases the hunters had introduced. The Aleut population was reduced, by the Russians' own estimate, from 20,000 to 2,000. By the 1760s, the Russians had reached Alaska. In 1799, Tsar Paul I consolidated the rival fur-hunting companies into the Russian-American Company, granting it an imperial charter and protection, and a monopoly over trade rights and territorial acquisition.\nUnder Aleksander I, the administration of the merchant-controlled company was transferred to the Imperial Navy, largely due to the alarming reports by naval officers of native abuse; in 1818, the indigenous peoples of Alaska were granted civil rights equivalent to a townsman status in the Russian Empire.\nOther nations joined in the hunt in the south. Along the coasts of what is now Mexico and California, Spanish explorers bought sea otter pelts from Native Americans and sold them in Asia. In 1778, British explorer Captain James Cook reached Vancouver Island and bought sea otter furs from the First Nations people. When Cook's ship later stopped at a Chinese port, the pelts rapidly sold at high prices, and were soon known as \"soft gold\". As word spread, people from all over Europe and North America began to arrive in the Pacific Northwest to trade for sea otter furs.\nRussian hunting expanded to the south, initiated by American ship captains, who subcontracted Russian supervisors and Aleut hunters in what are now Washington, Oregon, and California. Between 1803 and 1846, 72 American ships were involved in the otter hunt in California, harvesting an estimated 40,000 skins and tails, compared to only 13 ships of the Russian-American Company, which reported 5,696 otter skins taken between 1806 and 1846. In 1812, the Russians founded an agricultural settlement at what is now Fort Ross in northern California, as their southern headquarters.\nEventually, sea otter populations became so depleted, commercial hunting was no longer viable. It had stopped in the Aleutian Islands, by 1808, as a conservation measure imposed by the Russian-American Company. Further restrictions were ordered by the company in 1834. When Russia sold Alaska to the United States in 1867, the Alaska population had recovered to over 100,000, but Americans resumed hunting and quickly extirpated the sea otter again. Prices rose as the species became rare. During the 1880s, a pelt brought $105 to $165 in the London market, but by 1903, a pelt could be worth as much as $1,125. In 1911, Russia, Japan, Great Britain (for Canada) and the United States signed the Treaty for the Preservation and Protection of Fur Seals, imposing a moratorium on the harvesting of sea otters. So few remained, perhaps only 1,000\u20132,000 individuals in the wild, that many believed the species would become extinct.\nRecovery and conservation.\nDuring the 20th century, sea otter numbers rebounded in about two-thirds of their historic range, a recovery considered one of the greatest successes in marine conservation. However, the IUCN still lists the sea otter as an endangered species, and describes the significant threats to sea otters as oil pollution, predation by orcas, poaching, and conflicts with fisheries\u00a0\u2013 sea otters can drown if entangled in fishing gear. The hunting of sea otters is no longer legal except for limited harvests by indigenous peoples in the United States. Poaching was a serious concern in the Russian Far East immediately after the collapse of the Soviet Union in 1991; however, it has declined significantly with stricter law enforcement and better economic conditions.\nThe most significant threat to sea otters is oil spills, to which they are particularly vulnerable, since they rely on their fur to keep warm. When their fur is soaked with oil, it loses its ability to retain air, and the animals can quickly die from hypothermia. The liver, kidneys, and lungs of sea otters also become damaged after they inhale oil or ingest it when grooming. The Exxon Valdez oil spill of 24 March 1989 killed thousands of sea otters in Prince William Sound, and as of 2006, the lingering oil in the area continues to affect the population. Describing the public sympathy for sea otters that developed from media coverage of the event, a U.S. Fish and Wildlife Service spokesperson wrote:\nThe small geographic ranges of the sea otter populations in California, Washington, and British Columbia mean a single major spill could be catastrophic for that state or province. Prevention of oil spills and preparation to rescue otters if one happens is a major focus for conservation efforts. Increasing the size and range of sea otter populations would also reduce the risk of an oil spill wiping out a population. However, because of the species' reputation for depleting shellfish resources, advocates for commercial, recreational, and subsistence shellfish harvesting have often opposed allowing the sea otter's range to increase, and there have even been instances of fishermen and others illegally killing them.\nIn the Aleutian Islands, a massive and unexpected disappearance of sea otters has occurred in recent decades. In the 1980s, the area was home to an estimated 55,000 to 100,000 sea otters, but the population fell to around 6,000 animals by 2000. The most widely accepted, but still controversial, hypothesis is that killer whales have been eating the otters. The pattern of disappearances is consistent with a rise in predation, but there has been no direct evidence of orcas preying on sea otters to any significant extent.\nAnother area of concern is California, where recovery began to fluctuate or decline in the late 1990s. Unusually high mortality rates amongst adult and subadult otters, particularly females, have been reported. In 2017 the US Geological Survey found a 3% drop in the sea otter population of the California coast. This number still keeps them on track for removal from the endangered species list, although just barely. Necropsies of dead sea otters indicate diseases, particularly \"Toxoplasma gondii\" and acanthocephalan parasite infections, are major causes of sea otter mortality in California. The \"Toxoplasma gondii\" parasite, which is often fatal to sea otters, is carried by wild and domestic cats and may be transmitted by domestic cat droppings flushed into the ocean via sewage systems. Although disease has clearly contributed to the deaths of many of California's sea otters, it is not known why the California population is apparently more affected by disease than populations in other areas.\nSea otter habitat is preserved through several protected areas in the United States, Russia and Canada. In marine protected areas, polluting activities such as dumping of waste and oil drilling are typically prohibited. An estimated 1,200 sea otters live within the Monterey Bay National Marine Sanctuary, and more than 500 live within the Olympic Coast National Marine Sanctuary.\nEconomic impact.\nSome of the sea otter's preferred prey species, particularly abalone, clams, and crabs, are also food sources for humans. In some areas, massive declines in shellfish harvests have been blamed on the sea otter, and intense public debate has taken place over how to manage the competition between sea otters and humans for seafood.\nThe debate is complicated because sea otters have sometimes been held responsible for declines of shellfish stocks that were more likely caused by overfishing, disease, pollution, and seismic activity. Shellfish declines have also occurred in many parts of the North American Pacific coast that do not have sea otters, and conservationists sometimes note the existence of large concentrations of shellfish on the coast is a recent development resulting from the fur trade's near-extirpation of the sea otter. Although many factors affect shellfish stocks, sea otter predation can deplete a fishery to the point where it is no longer commercially viable. Scientists agree that sea otters and abalone fisheries cannot exist in the same area, and the same is likely true for certain other types of shellfish, as well.\nMany facets of the interaction between sea otters and the human economy are not as immediately felt. Sea otters have been credited with contributing to the kelp harvesting industry via their well-known role in controlling sea urchin populations; kelp is used in the production of diverse food and pharmaceutical products. Although human divers harvest red sea urchins both for food and to protect the kelp, sea otters hunt more sea urchin species and are more consistently effective in controlling these populations. \"E. lutris\" is a controlling predator of the red king crab (\"Paralithodes camtschaticus\") in the Bering Sea, which would otherwise be out of control as it is in its invasive range, the Barents Sea. (Berents otters, \"Lutra lutra\", occupy the same ecological niche and so are believed to help to control them in the Berents but this has not been studied.) The health of the kelp forest ecosystem is significant in nurturing populations of fish, including commercially important fish species. In some areas, sea otters are popular tourist attractions, bringing visitors to local hotels, restaurants, and sea otter-watching expeditions.\nRoles in human cultures.\nFor many maritime indigenous cultures throughout the North Pacific, especially the Ainu in the Kuril Islands, the Koryaks and Itelmen of Kamchatka, the Aleut in the Aleutian Islands, the Haida of Haida Gwaii and a host of tribes on the Pacific coast of North America, the sea otter has played an important role as a cultural, as well as material, resource. In these cultures, many of which have strongly animist traditions full of legends and stories in which many aspects of the natural world are associated with spirits, the sea otter was considered particularly kin to humans. The Nuu-chah-nulth, Haida, and other First Nations of coastal British Columbia used the warm and luxurious pelts as chiefs' regalia. Sea otter pelts were given in potlatches to mark coming-of-age ceremonies, weddings, and funerals. The Aleuts carved sea otter bones for use as ornaments and in games, and used powdered sea otter baculum as a medicine for fever.\nAmong the Ainu, the otter is portrayed as an occasional messenger between humans and the creator. The sea otter is a recurring figure in Ainu folklore. A major Ainu epic, the \"Kutune Shirka\", tells the tale of wars and struggles over a golden sea otter. Versions of a widespread Aleut legend tell of lovers or despairing women who plunge into the sea and become otters. These links have been associated with the many human-like behavioral features of the sea otter, including apparent playfulness, strong mother-pup bonds and tool use, yielding to ready anthropomorphism. The beginning of commercial exploitation had a great impact on the human, as well as animal, populations. The Ainu and Aleuts have been displaced or their numbers are dwindling, while the coastal tribes of North America, where the otter is in any case greatly depleted, no longer rely as intimately on sea mammals for survival.\nSince the mid-1970s, the beauty and charisma of the species have gained wide appreciation, and the sea otter has become an icon of environmental conservation. The round, expressive face and soft, furry body of the sea otter are depicted in a wide variety of souvenirs, postcards, clothing, and stuffed toys.\nAquariums and zoos.\nSea otters can do well in captivity, and are featured in over 40 public aquariums and zoos. The Seattle Aquarium became the first institution to raise sea otters from conception to adulthood with the birth of Tichuk in 1979, followed by three more pups in the early 1980s. In 2007, a YouTube video of two sea otters holding paws drew 1.5\u00a0million viewers in two weeks, and had over 22\u00a0million views . Filmed five years previously at the Vancouver Aquarium, it was YouTube's most popular animal video at the time, although it has since been surpassed. The lighter-colored otter in the video is Nyac, a survivor of the 1989 \"Exxon Valdez\" oil spill. Nyac died in September 2008, at the age of 20. Milo, the darker one, died of lymphoma in January 2012.\nCurrent conservation.\nSea otters, being a known keystone species, need a humanitarian effort to be protected from endangerment through \"unregulated human exploitation\". This species has increasingly been impacted by the large oil spills and environmental degradation caused by overfishing and entanglement in fishing gear. Current efforts have been made in legislation: the international Fur Seal Treaty, The Endangered Species Act, IUCN/The World Conservation Union, Convention on international Trade in Endangered Species of Wild Fauna and Flora, Marine Mammal Protection Act of 1972. Other conservation efforts are done through reintroduction and zoological parks.\nInternational Fur Seal Treaty:\nThe Endangered Species Act:\nIUCN/The World Conservation Union: \nConvention on international Trade in Endangered Species of Wild Fauna and Flora: \nMarine Mammal Protection Act of 1972:", "categories": ["Category:All accuracy disputes", "Category:All articles containing potentially dated statements", "Category:Articles containing potentially dated statements from July 2022", "Category:Articles containing video clips", "Category:Articles with 'species' microformats", "Category:Articles with BNF identifiers", "Category:Articles with BNFdata identifiers", "Category:Articles with GND identifiers", "Category:Articles with J9U identifiers", "Category:Articles with LCCN identifiers"]}]}
